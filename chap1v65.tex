



\documentclass[leqno]{book}
\usepackage{amsmath,amssymb,amsthm, amscd}
\usepackage{hyperref}
\usepackage{etoolbox}
\usepackage{everysel}
\usepackage{titlesec}
\usepackage{marginnote}
\usepackage[a4paper, textwidth=39cm, margin=1.1in, vmargin=3cm, marginparsep=20pt, marginparwidth=.6in,]{geometry} 
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{float}
\input macros.tex

%%%%%%%%%%maring notes%%%%%%%%%%
%\usepackage{ragged2e}
%\renewcommand*{\raggedleftmarginnote}{\RaggedLeft}
%\renewcommand*{\raggedrightmarginnote}{\RaggedRight}
\newcommand\Marginnote[1]{\marginnote{\hspace{-12pt}\normalfont{#1}}}

%%%%put all marginnotes to the left margin%%%%%%%%%
\makeatletter
\patchcmd{\@mn@margintest}{\@tempswafalse}{\@tempswatrue}{}{}
\patchcmd{\@mn@margintest}{\@tempswafalse}{\@tempswatrue}{}{}
\reversemarginpar 
\makeatother

%%%%%%Reduce font size of chapter and section%%%%
\usepackage{titlesec}

\titleformat{\section}
  {\normalfont\fontsize{12}{12}\bfseries}{\thesection}{1em}{}

\titleformat{\chapter}
  {\normalfont\fontsize{14}{14}\bfseries}{Chapter \thechapter}{1em}{}

\newcommand{\lsec}{\titleformat{\section}
  {\normalfont\fontsize{12}{12}\bfseries}{Section \thesection}{1em}{}}
 
\setlength{\parskip}{.2em}
\titlespacing*{\section}{0pt}{3ex plus 1ex minus .2ex}{1ex plus .1ex}

\newcommand\secstore{}
\newcommand\mythesection{\arabic{chapter}.}

%%%%%%%%makes equation numbers bold%%%%%%%%%%%%%
\renewcommand\theequation{\thesection.\arabic{equation}}
\newenvironment{boldequation}{\renewcommand\theequation{\textbf{\thesection.\arabic{equation}}}\equation}
   {\endequation}

%%%%%create theroem environment%%%%%%%%
\newtheoremstyle{dotless}{}{}{\itshape}{}{\bfseries}{}{ }{}
\swapnumbers
\theoremstyle{definition}%{no italic}
\numberwithin{equation}{section}
\newtheorem{note}[equation]{}
\newtheorem{definition}[equation]{}
\newtheorem{example}[equation]{}
\newtheorem{examples}[equation]{}
\newtheorem{remarks}[equation]{}
\newtheorem{thm}[equation]{}

\theoremstyle{theorem} %{italic}
\newtheorem{lemma}[equation]{}
\newtheorem{proposition}[equation]{}
\newtheorem{corollary}[equation]{}
\newtheorem{theorem}[equation]{}
\newtheorem{thrm}[equation]{}
 
\renewenvironment{proof}{\no \emph{proof.}}{}

%%%%%%%%Font style%%%%%%%%%
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\renewcommand{\rmdefault}{ptm}
\usepackage[scaled=0.98]{helvet}
 
%%%%%%%%%%%Headers and footers%%%%%%%%%%%%
\pagestyle{fancy}% Set default page style to fancy
\renewcommand{\headrulewidth}{0pt}% Remove header rule
\fancyhead{}% Remove all header contents
\cfoot{\thepage}
 
%%%%%%%%%%%\crossreferences%
\makeatletter
\DeclareRobustCommand*\Cal{\@fontswitch\relax\mathcal}
\makeatother
\usepackage{xr}


     \externaldocument{chap1v65}
     \externaldocument{chap2v43}
     \externaldocument{chap3v51}
     \externaldocument{chap4v49}
     \externaldocument{chap5v54}
     \externaldocument{newchap6v9}
     \externaldocument{newchap7v9}
     \externaldocument{newchap8v3}
%     \externaldocument{chap9v22}

     
\begin{document}


\chapter{PLANE CURVES}\MMM{planecurves} \label{planecurves}
 
\no
version 64
\no


	\ref{affineplane}  \;  {\bf The Affine Plane}  
	
	\ref{projplane} \;  {\bf The Projective Plane} 

        \ref{projcurve} \; {\bf Plane Projective Curves} 

	\ref{tanlines} \;  {\bf Tangent Lines} 
	
	\ref{nodes} \; {\bf  Nodes and Cusps} 
	
	\ref{transcdeg} \;  {\bf Transcendence Degree}
	
	\ref{dualcurve} \;  {\bf  The Dual Curve}

	\ref{resultant} \;  {\bf Resultants}
	
	\ref{coverline} \; {\bf  Coverings of the Projective Line}
	
	\ref{genus} \;  {\bf Genus}

	\ref{bezoutthm} \;  {\bf B\'ezout's Theorem} 

       \ref{plucker}  \; {\bf The Pl\"ucker Formulas}

\ms \#\#change coordinates $t,u=t^{-1}$ for $\bbp^1$ to $u,v=u^{-1}$
throughout\#\#

\#\# affine blowing up is only in this chapter
redefined in Chap 3 for projection, not used, i think
\#\#

\bsno Plane curves were the first algebraic varieties to be studied.
They provide examples that are helpful for understanding varieties
of higher dimension, so we begin with them.


\section{The Affine  Plane} 
\label{affineplane} \Marginnote{affineplane}[-.6cm]

\msno The
$n$-dimensional {\it affine space} $\bba^n$ is the space of
$n$-tuples of complex numbers.  The
{\it affine plane} $\bba^2$ is the two-dimensional affine space.


If $f(x_1,x_2)$ is an irreducible polynomial in two variables with
complex coefficients, the set of points $X$ of the affine plane at
which $f$ vanishes, the {\it locus of zeros} of $f$, is called a {\it plane
curve}, or an {\it affine plane curve}.  Using vector notation
  $x=(x_1,x_2)$,
\begin{equation}
X \;=\; \{x \,|\, f(x)=0\}  \Marginnote{affcurve}
	\label{affcurve}
\end{equation}
 
\no
The {\it degree} of the curve $X$ is the degree of its
irreducible defining polynomial. 

$$figure$$



\ms
\begin{note}{\bf Note.}  \Marginnote{polyirred}
In contrast with polynomials in one variable, most complex polynomials
in two or more variables are irreducible -- they cannot be factored.
This can be shown by a method called ``counting constants''.  For
instance, quadratic polynomials in $x_1,x_2$ depend on the
coefficients of the six monomials in $x_1,x_2$ of degree at most two.
Linear polynomials $ax_1\!+\!bx_2\!+\!c$ depend on three coefficients,
but the product of two linear polynomials depends on only five
parameters, because a scalar factor can be moved from one of the
linear polynomials to the other.  So the quadratic polynomials cannot
all be written as products of linear polynomials.  This reasoning is
fairly clear.  It can be justified formally in terms of {\it
  dimension}, which will be discussed in Chapter \ref{zarstr}.\qed
\label{polyirred}\end{note}

As this chapter progresses, we will get some understanding of the
geometry of a plane curve. Here we mention just one important point.
A plane curve is called a curve because it is defined by one
equation in two variables.  Its {\it algebraic} dimension is one.  But
because our scalars are complex numbers, it will be a surface,
geometrically.  This is analogous to the fact that the {\it affine
  line} $\bba^1$ is the plane of complex numbers.

One can see that a plane curve is a surface by inspecting its
projection to the affine line.  To do this, one writes its defining
polynomial $f$ as a polynomial in $x_2$ whose coefficients are
polynomials in $x_1$:
$$f(x_1,x_2) = c_0(x_1)x_2^d + c_1(x_1)x_2^{d-1} + \cdots + c_d(x_1)$$

\no Let's suppose that $f$ isn't a polynomial in $x$ alone, so that
$d$ is positive.  The {\it fibre} of a map $X \ar Z$ over a point $q$
of $Z$ is defined to be the inverse image of $q$, the set of points of
$X$ that map to $q$.  The fibre of the projection $X \ar \bba^1$ over
a point $x_1 = a$ is the set of points $(a,b)$ such that $b$ is a root
of the one-variable polynomial $$f(a,x_2) = c_0(a)x_2^d +
c_1(a)x_2^{d-1} + \cdots + c_d(a)$$ There will be finitely many points
in the fibre, and the fibre won't be empty unless $f(a,x_2)$ is a
constant.  So $X$ covers most of the $x_1$-line, a complex plane,
finitely often.

\begin{boldequation}
\Marginnote{planecoords}\hspace{-9.5cm} \textbf {changing coordinates}
	\label{planecoords}
\end{boldequation}


When classifying plane curves, one allows linear
changes of variable and translations.  If we write $x$ as the column
vector $(x_1,x_2)^t$, the coordinates $x'= (x_1',x_2')^t$ after such a
change of variable will have the form

\begin{equation}
Qx'+a=x \Marginnote{chgcoord}
	\label{chgcoord}
\end{equation}

\no where $Q$ is an invertible $2\times 2$ matrix with complex
coefficients and $a= (a_1,a_2)^t$ is a complex translation vector.
This changes a polynomial equation $f(x)=0$, to $\,f(Qx'+a) = 0$.  One
may also multiply a polynomial $f$ by a (nonzero) complex scalar without
changing the locus $\{f=0\}$.  
Using these operations, all {\it
  lines}, plane curves of degree $1$, become equivalent.


\ms An {\it affine conic} is a plane curve of degree two.  Every equation
$q(x_1,x_2)=0$ in which $q$ is an irreducible quadratic polynomial is
equivalent by a change of coordiantes  to one of the two equations
 
\begin{equation}
x_1^2 - x_2^2 -1=0\quad\text{or}\quad 
x_1^2-x_2=0 
\end{equation} 

\no The proof of this is similar to the one used to classify real conics.
The loci of solutions of the two equations might be called a complex
'hyperbola' and 'parabola', respectively.  The complex 'ellipse'
$x_1^2+x_2^2-1=0$ becomes the hyperbola when one multiplies $x_2$ by
$i$.

 On the other hand, there are infinitely many inequivalent
cubic curves.  Cubic polynomials in two variables depend on the
coefficients of the ten monomials in $x_1,x_2$ of degree at most $3$.
Linear operators, translations, and scalar multiplication give us only
seven parameters to work with, leaving three essential parameters.

 
\section{The Projective Plane}\label{projplane}\Marginnote{projplane}[-.6cm]

 \msno The $n$-dimensional {\it projective space} $\bbp^n$ is the set
 of equivalence classes of {\it nonzero} vectors $x= (x_0,x_1,...,x_n)$,
 the equivalence relation being

\begin{equation}(x_0',...,x_n') \sim (x_0,...,x_n)\;\;\;\;\text{if}\;\;\;\; 
(x_0',...,x_n') = (\lambda x_0,...,\lambda
    x_n)\MMM{equivrel}\label{equivrel}
\end{equation}
 for some nonzero
complex number $\lambda$.  The equivalence classes are the {\it
  points} of $\bbp^n$, and one often refers to a point by a particular
vector in its class.  
 Points of $\bbp^n$  correspond
bijectively to one-dimensional subspaces of $\bbc^{n+1}$.
If $x$ is a nonzero vector, the vectors $\lambda x$, together with the
zero vector, form the one-dimensional subspace of the complex vector
space $\bbc^{n+1}$ spanned by $x$. 

The {\it projective plane} is the two-dimensional projective space.

\begin{boldequation}
\Marginnote{projline}\hspace{-10cm} \textbf {the projective line}
	\label{projline} 
\end{boldequation}


Points of the {projective line} $\bbp^1$ are equivalence classes of
nonzero vectors $(x_0,x_1)$.  If $x_0$ isn't zero, we may multiply by
$\lambda = x_0^{-1}$ to normalize the first entry of a point
$(x_0,x_1)$ to $1$, and write the point it represents in a unique way
as $(1,u)$, with $u=x_1/x_0$.  There is one remaining point, the one
represented by the vector $(0,1)$.  The projective line $\bbp^1$ can
be obtained by adding this point, called the {\it point at infinity},
to the affine $u$-line (which is a complex plane).
Topologically, the projective line is a two-dimensional sphere.

\begin{boldequation}
\Marginnote{projpl}\hspace{-8.5cm} \textbf {lines in  projective space}
	\label{projpl} 
\end{boldequation}


\no
  A {\it line} $L$ in  projective space $\bbp^n$ can be described in terms of
  a pair of distinct points $p$ and $q$, as the set of points
  $\{rp+sq\}$, with $r,s$ in $\bbc$ not both zero.  The points of this
  line correspond bijectively to points of the projective line $\bbp^1$,
by
\begin{equation} rp+sq \quad\longleftrightarrow\quad
  (r,s)\; \Marginnote{pline}
\label{pline}\end{equation}

\no
The definition of a line in a projective space of any dimension is the same.

Points of the projective plane $\bbp^2$ are equivalence classes of
nonzero vectors $(x_0,x_1,x_2)$.
 A line in $\bbp^2$ can also be described as
the locus of solutions of a homogeneous
linear equation
\begin{equation}	
s_0x_0+s_1x_1+s_2x_2 =0 \Marginnote{eqline}
	\label{eqline}
\end{equation}





 \begin{lemma}{\text{\bf Lemma.}} \Marginnote{linesmeet}\;\,
Two distinct lines in the projective plane 
have exactly one point in common, and a pair of distinct points is
contained in exactly one line.  \qed 
\label{linesmeet} \end{lemma}


\begin{boldequation}
 \hspace{-8cm} \textbf{the standard affine cover of $\bbp^2$}
\label{standcov} \Marginnote{standcov}
\end{boldequation}

 
\msno If the first entry $x_0$ of a point $p = (x_0,x_1,x_2)$ of
$\bbp^2$ isn't zero, we may normalize it to $1$ without changing the
point: $(x_0,x_1,x_2) \sim (1,u_1,u_2)$, where $u_i =x_i/x_0$.  We did
the analogous thing for $\bbp^1$ above.  The representative vector
$(1,u_1,u_2)$ is uniquely determined by $p$, so points with $x_0\neq
0$ correspond bijectively to points of an affine plane $\bba^2$ with
coordinates $u$:
$$(x_0,x_1,x_2) \sim (1,u_1,u_2) \quad \longleftrightarrow \quad
(u_1,u_2)$$ We regard the affine plane as a subset of $\bbp^2$ by this
correspondence, and we denote that subset by $\bbu^0$.  The points of
$\bbu^0$, those with $x_0\neq 0$, are the {\it points at finite
  distance}.  The {\it points at infinity} of $\bbp^2$, those of the
form $(0,x_1,x_2)$, are on the {\it line at infinity} $L^0$, the locus
$\{x_0=0\}$. The projective plane is the union of the two sets
$\bbu^0$ and $L^0$, so when a point is given, we can assume that
its first coordinate is either $1$ or $0$.

When looking at a point of $\bbu^0$, we may simply set $x_0=1$,
and write the point as $(1,x_1,x_2)$.  To write $u_i = x_i/x_0$ makes sense
only when a particular  vector $(x_0,x_1,x_2)$ has 
been given.

There is an analogous correspondence between points $(x_0,1,x_2)$
and points of an affine plane $\bba^2$, and between points
$(x_0,x_1,1)$ and points of $\bba^2$.  We denote the subsets
$\{x_1\neq 0\}$ and $\{x_2\neq 0\}$ by $\bbu^1$ and $\bbu^2$,
respectively.  The three sets $\bbu^0,\bbu^1,\bbu^2$ form the {\it
  standard covering} of $\bbp^2$ by three {\it standard affine open
  sets}.  Since the vector $(0,0,0)$ has been ruled out, every point
of $\bbp^2$ lies in at least one of these sets.  Points whose three
coordinates aren't zero lie in all three.


\bs\centerline{\it figure}
\bs


\msno \begin{note}{\bf Note.} \Marginnote{pointatinfinity}\;\, Which
  points of $\bbp^2$ are at infinity depends on which of the standard
  affine open sets is taken to be the one at finite distance.  When
  the coordinates are $(x_0,x_1,x_2)$, I like to normalize $x_0$ to
  $1$, as above.  Then the points at infinity are those of the form
  $(0,x_1,x_2)$.  But when coordinates are $(x,y,z)$, I may
  normalize $z$ to $1$.  Then the points at infinity are the points
  $(x,y,0)$.  I hope this won't cause too much confusion. \qed
\label{pointatinfinity}\end{note}


\begin{boldequation}
\hspace{-8.0cm} \textbf{aside: the real projective plane}
\label{realprojplane}
 \Marginnote{realprojplane}
 \end{boldequation}

The {\it real projective plane} $\bbrp^2$ is the set of equivalence
classes of nonzero real vectors $(x_0,x_1,x_2)$, the equivalence
relation being $(x') \sim (x)$ if $(x') = \lambda (x)$ for some real
number $\lambda$.  It can be thought of as the space of
one-dimensional subspaces of the real vector space of dimension three.


Let $V$ denote the real vector space $\bbr^3$, and let $U$ be
the plane $\{x_0=1\}$ in $V$.  This plane is analogous to the open subset $\bbu^0$ of the complex
projective plane $\bbp^2$. 

We can project $V$ from the origin $o$ to $U$, sending a point
$(x_0,x_1,x_2)$ of $V$ to the point $(1,u_1,u_2)$, with $u_i=x_i/x_0$.
Looking
from the origin, $U$ becomes a ``picture plane''.

\ms
\centerline{figure}

\msno


\ms
\centerline{\it D\"urer drawing of perspective}

\no The projection to $U$ is undefined at the points $(0,x_1,x_2)$.
Lines through the origin that are orthogonal to the $x_0$-axis don't
meet $U$. They correspond to the points at infinity of $\bbrp^2$.



\ms The history of the real projective plane is complicated.  The
projection from $3$-space to a picture plane goes back to the the early
16th century, the time of Desargues and D\"urer.  Bot projective
coordinates were introduced 200 years later, by M\"obius.

\begin{boldequation}
\hspace{ - 6.0cm} \textbf{changing coordinates in the projective
  plane}
\label{chgcoordssec}
 \Marginnote{chgcoordssec}
 \end{boldequation}

\no An invertible $3\times 3$ matrix $P$ determines a linear change
of coordinates in $\bbp^2$.
With $x=(x_0,x_1,x_2)^t$ and $x'=(x_0',x_1',x_2')^t$
represented as column vectors, the coordinate change is given by
\begin{equation}Px' = x  \Marginnote{chg} \label{chg}\end{equation} 


\no As the next proposition shows, four special points, the three
points $e_0=(1,0,0)^t,e_1=(0,1,0)^t,e_2=(0,0,1)^t$ and the point
$\epsilon=(1,1,1)^t$ determine the coordinates.



\begin{proposition}{\text{\bf Proposition.}}\Marginnote{fourpoints}\;\,
Let $p_0,p_1,p_2,q$
be four points of $\bbp^2$, no three of which lie on a line.  There
is, up to scalar factor, a unique linear coordinate change $Px'=x$
such that   $Pp_i = e_i$ and $P q =\epsilon$.
\label{fourpoints}\end{proposition}

 \begin{proof} 
We represent the points by specific vectors.  The statement that
$p_0,p_1,p_2$ don't lie on a line means that those three vectors are
independent.  They span $\bbc^3$. So $q$ will be a combination
$c_0p_0+c_1p_1+c_2p_2$, and because no three points lie on a line,
the coefficients $c_i$ will be nonzero.  We can {\it scale} the
vectors $p_i$ (multiply them by nonzero scalars) to make $q =
p_0\!+\!p_1\!+\!p_2$.  Next, the columns of $P$ can be an arbitrary
set of independent vectors.  We let them be $p_0,p_1,p_2$.  Then $Pe_i
= p_i$, and $P\epsilon = q$.  The matrix $P$ is unique up to scalar
factor, as is verified by looking the reasoning over.  \qed\end{proof}

\begin{boldequation}
\hspace{-11cm} \textbf{conics}\
\Marginnote{projconics}\label{projconics}
 \end{boldequation}

 A polynomial $f(x_0,x_1,x_2)$ is {\it homogeneous, of degree} $d$, if
 all monomials that appear with nonzero coefficient have degree $d$.
 For example, $x_0^3+x_1^3-x_0x_1x_2$ is a homogeneous cubic
 polynomial.  

A {\it conic} is the locus of zeros of an irreducible homogeneous
quadratic polynomial, a
combination of the six monomials $$x_0^2,\, x_1^2,\, x_2^2,\,
x_0x_1,\, x_1x_2,\, x_0x_2$$


\begin{proposition}{\bf Proposition.} 
\Marginnote{classifyconic}\label{classifyconic} For any conic $C$,
there is a choice of coordinates so that $C$ becomes the locus
$$x_0x_1+x_0x_2+x_1x_2 = 0$$
\end{proposition}

\begin{proof} 
Since the conic $C$ isn't a line, it will contain three points that
aren't colinear.  Let's leave the verification of this fact as an
exercise.  We choose three non-colinear points, and adjust coordinates
so that they become the points $e_0,e_1,e_2$.  Let $f$ be the
quadratic polynomial in those coordinates whose zero locus is
$C$. Then $f(1,0,0) = 0$, and therefore the coefficient of $x_0^2$ in
$f$ is zero.  Similarly, the coefficients of $x_1^2$ and $x_2^2$ are
zero.  So $f$ has the form $$f = ax_0x_1+bx_0x_2+cx_1x_2$$Since $f$ is
irreducible, $a,b,c$ aren't zero.  By scaling the variables
appropriately, we can make $a=b=c=1$.  We will be left with the
polynomial $x_0x_1+x_0x_2+x_1x_2$.\qed\end{proof}

\section{Plane  Projective Curves} 
\label{projcurve}\Marginnote{projcurve}

\msno Algebraic geometry studies the loci in projective space that are
defined by systems of {\it homogeneous} polynomial equations.
Homogeneity is required because the vectors $(a_0,...,a_n)$ and
$(\lambda a_0,...,\lambda a_n)$ represent the same point of $\bbp^n$.
One wants to know that if $f(x)=0$ is a polynomial equation, and if
$f(a)=0$, then $f(\lambda a) = 0$ for every $\lambda \neq 0$.  As we
verify now,  this will be true if and only if $f$ is homogeneous.

A polynomial $f$ can be written as a sum of its {\it homogeneous
  parts}:
\begin{equation}
f = f_0+f_1+ \cdots + f_d \Marginnote{homparts}
	\label{homparts}
\end{equation}

\no
where $f_0$ is the constant term,  $f_1$ is the linear part, etc., and
$d$ is the degree of $f$.

 \begin{lemma}{\text{\bf Lemma.}}\label{hompartszero}
\Marginnote{hompartszero}\;\, Let $f$ be a polynomial of degree $d$,
and let $x = (x_0,...,x_n)$.  Then $f(\lambda x) = 0$ for every
nonzero complex number $\lambda$ if and only if $f_i(x)$ is zero for
all $i = 0,...,d$.
\end{lemma}

\begin{proof}
$f(\lambda x_0,...,\lambda x_n) = 
f_0 + \lambda f_1(x) + \lambda^2f_2(x) +\cdot +
\lambda^df_d(x)$. When we evaluate at a
given vector $x$, the right side of this equation becomes a
polynomial of degree at most $d$ in $\lambda$.  Since a nonzero
polynomial of degree at most $d$ can have at most $d$ roots,
$f(\lambda x)$  will not be zero for {\it every} $\lambda$ unless
that polynomial is zero -- unless
$f_i(x)=0$ for every $i$.   \qed\end{proof}

\begin{boldequation}
\hspace{-9cm} \textbf{loci in the projective line}
\Marginnote{locipone}\label{locipone}
\end{boldequation}

 Before going  to plane curves, we  describe
 the zeros  in $\bbp^1$ of a homogeneous
polynomial in two variables.

 \begin{lemma}{\text{\bf Lemma.}} \Marginnote{factorhompoly}\;\,
Every nonzero homogeneous polynomial $f(x,y) = a_0x^d+a_1x^{d-1}y+
\cdots + a_dy^d$ with complex coefficients is a
product of homogeneous linear polynomials that are unique up to scalar factor.
\label{factorhompoly}\end{lemma}


\no To prove this, one factors the one-variable complex polynomial
$f(x,1)$ into linear factors, substitutes $x/y$ for $x$, and
multiplies the result by $y^d$.  When one adjusts scalar factors, one
will obtain the expected factorization of $f(x,y)$.  For instance, to
factor $f(x,y) = 2x^2-3xy+y^2$, substitute $y=1$: $2x^2-3x+1 =
2(x-1)(x-\frac 1 2)$.  Substitute $x = x/y$ and multiply by $y^2$:\,
$f(x,y) = 2(x-y)(x-\frac 1 2 y)$.  The scalar $2$ can be distributed
arbitrarily among the factors.  For instance, $f(x,y) = (x-y)(2x-y)$.
\hfill\qed

\ms Adjusting scalar factors, we may write a homogeneous polynomial as
a product
\begin{equation}\MMM{factorpolytwo}\label{factorpolytwo}
f(x,y) = (v_1x-u_1y)^{r_1} \cdots (v_kx-u_ky)^{r_k}
\end{equation}

\no
where no factor $v_ix-u_iy$ is a constant multiple of another, and
where $r_1+\cdots + r_k$ is the degree $d$ of $f$.
The exponent $r_i$ is  the {\it multiplicity}
of the linear factor $v_ix-u_iy$.

A linear polynomial $vx-uy$ corresponds to the point $(u,v)$ in the
 projective line $\bbp^1$, the unique {\it zero} of that polynomial,
 and changing the polynomial by a scalar factor doesn't change its zero.
 Thus the linear factors of the homogeneous polynomial
 (\ref{factorpolytwo}) determine points of $\bbp^1$, the {\it zeros}
 of $f$.  As with the roots of a one-variable polynomial, we can
 assign multiplicities to those zeros.  The points $(u_i,v_i)$ are
 zeros of {\it multiplicity} $r_i$.

The zero $(u_i,v_i)$ of $f$ corresponds to a root $x=u_i/v_i$ of
multiplicity $r_i$ of the one-variable polynomial $f(x,1)$, except
when the zero is the point $(1,0)$.  This happens when the coefficient
$a_0$ of $f$ is zero, and $y$ is a factor of $f$.  One
might say that $f(x,1)$ has a root at infinity in that case.

This sums up the information contained in an algebraic locus in the
projective line.  It will be a finite set of points with
multiplicities.

\begin{boldequation}
\hspace{-9cm} \textbf{intersections with a line}
\Marginnote{intersectline}\label{intersectline}
\end{boldequation}


\bs Let $Z$ be the zero locus in $\bbp^n$ of a homogeneous polynomial
$f(x_0,...,x_n)$ of degree $d$, and let $L$ be a line in $\bbp^n$
(\ref{pline}).
Say that $L$ is the set of points $rp+sq$, where $p=(a_0,...,a_n)$ and
$q = (b_0,...,b_n)$, so that $L$ corresponds to the projective line
$\bbp^1$ by $rp+sq \leftrightarrow (r,s)$.  Let's also assume that $L$
isn't a subset of $Z$.  Then the intersection $Z \cap L$ corresponds
to a subset of $\bbp^1$ that is obtained as follows: We substitute
$rp+sq$ into $f$, obtaining a homogeneous polynomial $\tf(r,s)$ of
degree $d$ in $r,s$.  For example, if $n=2$ and if $f =
x_0x_1\!+\!x_0x_2\!+\!x_1x_2$, then $\tf$ is the following quadratic
polynomial in $r,s$:

\ms
\centerline{$\tf(r,s) = f(rp+sq) = (ra_0+sb_0)(ra_1+sb_1) +
(ra_0+sb_0)(ra_2+sb_2) + (ra_1+sb_1)(ra_2+sb_2)$}

\ms
\centerline{\quad\quad\quad\quad$ = (a_0a_1\!+\!a_0a_2\!+\!a_1a_2)r^2 +
\big(\sum_{i\neq j}a_ib_j\big)rs + (b_0b_1\!+\!b_0b_2\!+\!b_1b_2)s^2 $}

\msno
The
zeros of $\tf$ in $\bbp^1$ correspond to the points of $Z\cap
L$, and with multiplicities as described above, there will be $d$ of
them.  \qed

\ms
\begin{definition}{\bf Definition}
\MMM{intersectlinetwo}\label{intersectlinetwo}
With notation as above, the {\it intersection multiplicity} of $Z$ and
$L$ at a point $p$ is the multiplicity of zero of the polynomial 
$\tf$. \end{definition}


\begin{corollary}{\bf Corollary.}\MMM{XcapL}\label{XcapL}
Let $Z$ be the zero locus in $\bbp^n$ of a homogeneous polynomial $f$,
and let $L$ be a line in $\bbp^n$ that isn't contained in $Z$. When
counted with multiplicity, the number of intersections of $Z$ and $L$
is equal to the degree of $f$.\qed\end{corollary}


\begin{boldequation}
\hspace{-8.5cm} \textbf{loci in the projective plane}
\Marginnote{lociptwo}\label{lociptwo}
\end{boldequation}


\msno If a homogeneous polynomial $f$ is a product, say $f = f_1f_2$,
then the locus $\{f = 0\}$ is the union of the two loci $\{f_1=0\}$
and $\{f_2=0\}$.  This is rather obvious.  What  isn't obvious is that
homogeneous polynomials $f$ and $g$ with no common factor have
finitely many common zeros.  This is proved below, in Proposition
\ref{fgzerofinite}.


\begin{corollary}{\bf Corollary.}\MMM{pointscurves}\label{pointscurves}
Any locus in $\bbp^2$ defined by a system of
homogeneous polynomial equations is a finite union of points and
curves.  \qed\end{corollary}

The most interesting loci in the projective plane are
the zero sets of single irreducible homogeneous polynomial equations.
When $f$ is an irreducible homogeneous polynomial, the locus $\{f=0\}$
is called a {\it (projective) plane curve}.   The {\it degree} of a plane
curve is  the degree of its irreducible defining
polynomial.



As is true for curves in the affine plane, a plane projective curve
will have geometric dimension two.  The case of a line, which is
homeomorphic to the two-dimensional sphere $\bbp^1$ illustrates this.


\ms The zero locus of a reducible homogeneous polynomial may be
called a {\it reducible curve}.  To keep track of multiple factors of
a reducible polynomial $f$, one can associate an integer combination of curves, called a
{\it divisor}, to it.  One writes $f$ as a product
of irreducible polynomials, say
\begin{equation}f= g_1^{r_1}\cdots g_k^{r_k},
\Marginnote{factorf}\label{factorf}\end{equation} 
where $g_i$
are irreducible polynomials and where $g_j$ 
isn't a scalar
multiple of $g_i$ if $i\neq j$. If $C_i$ is the plane curve
$\{g_i=0\}$, the associated {\it divisor} is defined to be the
integer combination
\begin{equation} Z = r_1C_1 + \cdots + r_kC_k
\Marginnote{divisoroff}\label{divisoroff}
\end{equation}


\begin{proposition}{\bf Proposition.}
\MMM{fgzerofinite}\label{fgzerofinite} Homogeneous polynomials
$f_1,...,f_r$ in $x,y,z$ whose greatest common divisor is $1$ have
 finitely many common zeros.\end{proposition}

We make a small digression before proving the proposition.  
The ring $\bbc[x,y]$ embeds into its field of fractions $F= \bbc(x,y)$, the
field of rational functions in $x,y$, and one may study the polynomial
ring $\bbc[x,y,z]$ as a subring of the one-variable polynomial ring
$F[z]$.  This is a useful method because $F[z]$ is a principal ideal
domain.  Its algebra is simpler.

\begin{lemma}{\bf Lemma.}\MMM{relprime}\label{relprime}
Let $f_1,...,f_k$ be homogeneous polynomials in $x,y,z$ with no common
factor.  Their greatest common divisor in $F[z]$ is $1$, and
therefore there is an equation of the form $\sum g'_if_i=1$ with
$g_i'$ in $F[z]$.\end{lemma}

\begin{proof}
Let $\tilh$ be an element of $F[z]$ that divides $f_1,...,f_k$, say
$f_i = \tu_i\tilh$, and suppose that $\tilh$ isn't a unit (an element
of $F$).  The elements $\tu_i$ and $\tilh$ are polynomials in $z$
whose coefficients are in $F$.  When we clear denominators from the
coefficients, we will obtain equations of the form $d_if_i = u_ih$,
where $d_i$ are polynomials in $x,y$ and $u_i,h$ are polynomials in
$x,y,z$.  Since $\tilh$ isn't in $F$, $\tilh$ and $h$ have positive
degree in $z$.  

Let $s$ be an irreducible factor of $h$ of positive degree in
$z$. Then $s$ divides $d_if_i$ but doesn't divide $d_i$ which has
degree zero in $z$, so $s$ divides $f_i$ for all $i$.  This
contradicts the hypothesis that $f_1,...,f_k$ have no common
factor.\qed\end{proof}


\msno
{\it proof of the proposition.}  The lemma tells us that 
we may write $\sum g_i'f_i=1$, with $g_i'$ in $F[z]$.
Clearing denominators
from $g_i'$ gives us an equation of the form
$$\sum g_if_i=d$$ where $d$ is a polynomial in $x,y$ and $g_i$ are
polynomials in $x,y,z$.  Taking suitable homogeneous parts of $g_i$
and $d$ produces an equation $\sum g_if_i=d$ in which all terms are
homogeneous.   

Lemma \ref{factorhompoly} tells us that $d$ is a product of linear
polynomials, say $d=\ell_1\cdots \ell_k$.  A common zero of $f_i$ is
also a zero of $d$, and therefore it is a zero of $\ell_j$ for some
$j$.  It suffices to prove that for each $j$, the polynomials
$f_1,...,f_k,\ell_j$ have finitely many common zeros.  Since
$f_1,...,f_k$ have no common factor, there must be at least one $f_i$
that isn't divisible by $\ell_j$. Corollary \ref{XcapL} shows that
$f_1$ and $f_i$ have finitely many common zeros.\qed



%  The analogue of this statement for
%non-homogeneous polynomials in two variables is also true, and the
%proof is similar.

\ms
The next corollary is a special case of the Strong Nullstellensatz
that will be proved in the next chapter.

\begin{corollary}{\text{\bf Corollary.}}\Marginnote{idealprincipal}\;\,
Let $S$ be an infinite set of points of $\bbp^2$, and let $f$ be an
irreducible homogeneous polynomial that vanishes on $S$.  If another
homogeneous polynomial $g$ vanishes on $S$, then $f$ divides $g$.
Therefore, if an irreducible polynomial vanishes on an infinite set
$S$, that polynomial is unique up to scalar factor.
\label{idealprincipal} \end{corollary}

\begin{proof} If the irreducible polynomial $f$ doesn't divide $g$,
then $f$ and $g$ have no common factor, and therefore they have 
finitely many common zeros.\qed\end{proof} 


\ms
\begin{boldequation}
\hspace{-9.0cm} \textbf{the classical  topology}
\label{classicaltopology}
 \Marginnote{classicaltopology}
 \end{boldequation}


 \msno The usual topology on the affine plane $\bba^2$ will be called
 the {\it classical topology}.  A subset $U$ of $\bba^2$ is open in
 the classical topology if, whenever $U$ contains a point $p$, it
 contains all points sufficiently near to $p$.  We call this the
 classical topology to distinguish it from another topology, 
 the {\it Zariski topology}, that will be described in the next chapter.

The projective plane also has a classical topology.  A subset
$U$ of $\bbp^2$ is open if, whenever a point $p$ of $U$ is represented
by a vector $(x_0,x_1,x_2)$, all vectors $(x'_0,x_1',x_2')$ with
$x_i'$ sufficiently near to $x_i$ represent points of $U$. 


\begin{boldequation}\Marginnote{isopts}
\hspace{-10.5cm} \textbf{isolated points}
\label{isopts}\end{boldequation}

 A point $p$ of a topological space $X$ is {\it isolated}
 if both $\{p\}$ and its complement $X\!-\!\{p\}$ are closed sets.
If $X$ is a subset of $\bba^n$ or $\bbp^n$, a point
 $p$ of $X$ is isolated (in the classical topology) if $X$
 doesn't contain points $p'$ distinct from, but arbitrarily close
 to, $p$.

\begin{proposition}{\bf Proposition}
\MMM{noisolatedpoint}\label{noisolatedpoint} Let $n$ be an integer $>
1$.  The zero locus of a polynomial in $\bba^n$ or $\bbp^n$ contains
no isolated points.
\end{proposition}

The proof is below.

\begin{lemma}{\bf Lemma.}\MMM{polyfunction}\label{polyfunction}
A formal polynomial, an element $f(x_1,...,x_n)$ of the polynomial
ring $\bbc[x_1,...,x_n]$, is determined by the function that it
defines on $\bbc^n$.
\end{lemma}

This lemma shows that  we needn't be careful to distinguish formal
polynomials from polynomial functions.


\begin{proof} 
To  show that formal polynomials $f$ and $g$ which define the
same function are equal, we replace $f$ by $f-g$.  Then what we must
show is that if the function defined by a formal polynomial $f$ is
identially zero, then $f$ is the zero polynomial.  If $f$ defines the
zero function, its partial derivatives are zero too. The partial
derivatives are the functions defined by the formal partial
derivatives of $f$.  Since the partials have degree $d-1$, we may use
induction on the degree to conclude that the formal partial
derivatives are zero.  This implies that $f$ is a constant, and if $f$
defines the zero function, that constant is zero.\qed\end{proof}


\begin{lemma}{\bf Lemma.}\MMM{polymonic}\label{polymonic}
Let $f$ be a polynomial of degree $d$ in the
variables $x_1,...,x_n$. There is a linear change of variable $
Px'=x$, where $P$ is an invertible $n\ktimes n$matrix, such that 
$f(Px')$ is a monic polynomial of degree $d$ in $x_n'$.
\end{lemma}

\begin{proof} We write  $f = f_0+f_1+\cdots + f_d$, where $f_i$ is the 
homogeneous part of $f$ of degree $i$, and we choose a point $p$ of
$\bba^n$ at which $f_d$ isn't zero.  We change variables so that $p$
becomes the point $(0,...,0,1)$, and we call the new variables
$x_1,..,.x_n$.  With this change of variable, $f_d(0,...,0,x_n) =
cx_n^d$ for some nonzero constant $c$.  We can adjust $x_n$ by a
scalar factor to make $c=1$.  Then $f$ will be monic.\qed\end{proof}


\msno {\it proof of Proposition \ref{noisolatedpoint}.}  The
proposition is true both for loci in affine space and for loci in
projective space.  We look at the affine case.  Let $f(x_1,...,x_n)$
be a polynomial with zero locus $Z$, and let $p$ be a point of $Z$.
We adjust coordinates so that $p$ is the origin $(0,...,0)$ and $f$ is monic
in $x_n$.  We relabel $x_n$ as $y$, so that the variables are
$x_1,...,x_{n-1},y$ and $f$ has the form
$$f = y^d + a_{d-1}(x)y^{d-1} + \cdots + a_0(x)$$ where
$x=x_1,...,x_{n-1}$.  When we fix $x$, $a_0(x)$ is the product of the
roots of $f(x,y)$, considered as a polynomial in the variable $y$.
Since $p$ is the origin and $f(p)=0$, $a_0(0)=0$.  So $a_0(x)$ will
tend to zero with $x$.  Then at least one root $y$ of $f(x,y)$ will
tend to zero.  This gives us points $(x,y)$ of $Z$ that are
arbitrarily close to $p$.  \qed

\begin{corollary}{\text{\bf Corollary.}}\Marginnote{functioniszero}\;\,
Let $U$ be the complement of a finite set of points in a plane curve
$C$.  A continuous function $g$ on $C$ that
is zero at every point of $U$ is identically zero.
\qed \label{functioniszero}\end{corollary}

\section{Tangent Lines} \label{tanlines} \Marginnote{tanlines}[-.6cm]

\vspace{-0.5cm}
\begin{boldequation}
\hspace{-7cm} \textbf{homogenizing and dehomogenizing}
\Marginnote{homdehomone}\label{homdehomone}
\end{boldequation}

\ms We will often want to inspect a projective curve $C : \{f(x)=0\}$
in a neighborhood of a particular point $p$.  To do this we may adjust
coordinates so that $p$ is the point $(1,0,0)$ and look in the
standard affine open set $\bbu^0$.  The intersection $C^0$ of $C$ with
$\bbu^0$ will be the zero locus of the non-homogeneous polynomial
$f(1,x_1,x_2)$, and $p$ will be the origin in the affine
$x_1,x_2$-plane.  We call $f(1,x_1,x_2)$ the {\it dehomogenization} of
$f$.  Proposition \ref{foneirred} below asserts that the
dehomogenization of an irreducible polynomial is irreducible.


A simple procedure called {\it homogenization} inverts 
dehomogenization.  Its description will be clear
when we describe dehomogenization again, in a way that is obviously
invertible.

Let $f$ be a homogeneous polynomial of degree $d$, and let $u_i =
x_i/x_0$, so that $u_0=1$.  To dehomogenize $f$, we divide $f$ by
$x_0^d$, we put one copy of $x_0$ under each $x_i$ as it appears in
the polynomial, and we replace $x_i/x_0$ by $u_i$.  For example,
suppose that $f = 2x_0^3+ x_0^2x_1+ x_2^3$.  We divide by $x_0^3$:

$$(2x_0^3+x_0^2x_1+x_2^3)/x_0^3 = 2u_0^3+ u_0^2u_1 + u_2^3 = 2+u_1+u_2^3 =
  f(1,u_1,u_2)$$ 
The result is the dehomogenized polynomial $F$, except
  that the variables $x_i$ have been replaced by $u_i$.

Now suppose given a non-homogeneous polynomial $F(x_1,x_2)$ of degree
$d$.  To {\it homogenize} $F$, we invert this process.  We replace the
variables $x_i$ by $u_i = x_i/x_0$, and then multiply by $x_0^d$.
Since $u_i$ has degree zero in $x$, so does $F(u_1,u_2)$.  The result
will be a homogeneous polynomial of degree $d$, and it won't be
divisible by $x_0$,

Let $\Cal N$ denote the space of non-homogeneous polynomials in
$u_1,u_2$, and let $\Cal H$ denote the space of homogeneous
polynomials in $x_0,x_1,x_2$ that aren't divisible by $x_0$.
Homogenization and dehomogenization are inverse functions
$$\Cal N \longleftrightarrow \Cal H$$ 

Homogenization and
dehomogenization will be discussed again in Chapter \ref{affine}.


\begin{proposition}{\bf Proposition.}\MMM{foneirred}\label{foneirred}
A homogeneous polynomial $f(x_0,x_1,x_2)$ that isn't divisible by
$x_0$ is irreducible if and only if its dehomogenization
$f(1,x_1,x_2)$ is irreducible.\end{proposition}


\ms
\begin{proof} Let's
 denote  $f(1,x_1,x_2)$  by $F(x_1,x_2)$.  
When $f$ isn't
 divisible by $x_0$, the degrees of $F$ and $f$ will be equal.
 Suppose that $f$ is a product $gh$ of (nonconstant) homogeneous
 polynomials.  Then $F = GH$, where $G = g(1,x_1,x_2)$ and $H =
 h(1,x_1,x_2)$.  Since $f$ isn't divisible by $x_0$, neither are $g$
 or $h$, so $G$ and $H$ have the same degrees as $g$ and $h$.
Therefore $F$ isn't irreducible.
Conversely, if $F= GH$, then when we homogenize, we obtain
an equation $f=gh$, so $f$ isn't irreducible.
\qed\end{proof}

\begin{boldequation}\Marginnote{smsingpts}
\hspace{-7.5cm} \textbf{smooth points and singular points} 
\label{smsingpts}\end{boldequation}


\ms Let $C$ be the plane curve defined by an irreducible homogeneous
polynomial $f(x_0,x_1,x_2)$, and let $f_i$ denote the partial
derivative $\frac {\partial f}{\partial x_i}$.  A point of $C$ at
which the partial derivatives $f_i$ aren't all zero is called a {\it
  smooth point} of $C$, and a point at which all partial derivatives
are zero is a {\it singular point}.

 A curve  is  {\it smooth}, or {\it nonsingular}, if it
contains no singular point; otherwise it is a {\it singular} curve.
The {\it Fermat curve} \Marginnote{fermatcurve}
\begin{equation} x_0^d+x_1^d+x_2^d=0 
\label{fermatcurve}
\end{equation} is smooth because the only common zeros of the
 partial derivatives $\,dx_0^{d-1},dx_1^{d-1},dx_2^{d-1}$, $(0,0,0)$,
 doesn't represent a point of $\bbp^2$.  

The cubic curve
 $x_0^3+x_1^3-x_0x_1x_2=0$ is singular at the point $(0,0,1)$.

\ms The meaning of smoothness is explained by the Implicit Function
Theorem.  Let $p$ be a point of $C$ in the standard affine open set
$\bbu^0:x_0\neq 0$.
We set $x_0=1$ and inspect the locus
$f(1,x_1,x_2)=0$ in $\bbu^0$. If $\frac {\partial f}{\partial
  x_2}$ isn't zero at $p$, the Implicit Function Theorem tells us
that we can solve the equation $f(1,x_1,x_2)=0$ for $x_2$ locally as
an analytic function $\varphi$ of $x_1$.  Sending $x_1$ to
$(1,x_1,\varphi)$ inverts the projection from $C$ to the affine
$x_1$-line $X$.  So at a smooth point, $C$ is locally homeomorphic to $X$.

\ms \centerline{figure: node, cusp,
  tacnode}\MMM{somesingpts}\label{somesingpts}



\msno {\bf A Note about figures.} In algebraic geometry, dimensions
are too big to allow realistic figures.  Even with a plane curve, one
is dealing with a locus in the space $\bbc^2$, which is
four-dimensional.  In some cases, such as in the figures shown above,
depicting the real locus can be helpful., but  In most cases one must
make do with a schematic figure.  The one below is an example.  My
students tell me that all of my figures look more or less like this:

$$figure$$\qed




 \begin{thm}{\bf Euler's Formula.}\Marginnote{eulerformula}\;\,
Let $f$ be a homogeneous polynomial of degree $d$ in the variables
$x_0,...,x_n$.  
Then
\label{eulerformula}
$$\sum_i x_i\textstyle{\frac{\partial f}{\partial x_i}} = d\,f.$$
\end{thm}

\no It is enough to check this formula for monomials, which is
easy.  For instance, when $f = x^2y^3z$, $$\;xf_x + y f_y + zf_z =
x(2xy^3z) + y(3x^2y^2z) + z(x^2y^3) = 6x^2y^3z = 6\,f$$ 
\hspace{-0.7cm}\qed

 \begin{corollary}{\text{\bf Corollary.}}\Marginnote{singpointoncurve}\;\,

\no {\bf (i)} If all partial derivatives of a homogeneous polynomial
$f$ are zero at a point $p$ of $\bbp^2$, then $f$ is zero at $p$, and
therefore $p$ is a singular point of the curve or divisor it defines.

\no {\bf (ii)} The partial derivatives of an irreducible polynomial
have no common (nonconstant) factor.

\no
{\bf (iii)} A curve has  finitely many singular points.
\label{singpointoncurve}\end{corollary}

\begin{proof} {\bf (ii,iii)}  
Euler's Formula shows that a common factor of the partial derivatives
divides $f$.  If $f$ is an irreducible polynomial of degree $d$, it
can have no factor in common with its partial derivatives, which have
degree $d\!-\!1$.  Therefore the partial derivatives have no common
factor.  Proposition \ref{fgzerofinite} shows that the partials  have
finitely many common zeros.  \qed\end{proof}

\ms One can use the same definition for the divisor $Z$ defined by a
reducible polynomial $f=g_1^{r_1}\cdots g_k^{r_k}$, so that $Z=
r_1C_1+\cdots + r_kC_k$ (see (\ref{divisoroff})).  A {\it singular
  point} of $Z$ is one at which all of the partial derivatives $f_i$
are zero.  But if some $r_j$ is
greater than $1$, $g_j$ will divide all of the partial
derivatives of $f$.  Then every point of $C_j$ will be a singular
point of  $Z$.


\begin{boldequation}\Marginnote{tangent} 
\hspace{-8.5cm} \textbf{tangent lines and flex points} 
\label{tangent}\end{boldequation}


\ms Let $C$ be the plane curve defined by an irreducible homogeneous
polynomial $f$ of degree at least $2$, A line $L$ is {\it tangent} to
$C$ at a smooth point $p$ if the intersection multiplicity of $C$ and
$L$ at $p$ is at least $2$, and a smoth point
 $p$ is a {\it flex point} of
$C$ if the intersection multiplicity at $p$ of $C$ with its tangent
line is at least $3$ (see (\ref{intersectlinetwo})).  We will see that
there is a unique tangent line at a smooth point.

\ms Let $L$ be a line through a point $p$ and let $q$ be a point of
$L$ distinct from $p$.  We represent $p$ and $q$ by specific vectors,
and write a variable point of $L$ as $p+tq$.
We  expand the restriction of $f$ to $L$ in a Taylor's Series, 
Let $f_{i}= \frac {\partial f}{\partial x_i} $ and $f_{ij}=
\frac {\partial^2 f}{\partial x_i\partial x_j}$.  Then
\begin{equation}f(p+tq) \;=\; f(p) \; + \;\bigg(\sum_i f_i(p)\,q_i\bigg)t \;+\;
{\textstyle{\frac 1 2 }} \bigg(\sum_{i,j} q_i\,f_{ij}(p)\,q_j\bigg)t^2
\;+\; O(3)  \Marginnote{taylor}	\label{taylor}\end{equation}

\no
 The point $q$ is missing from this
parametrization of $L$, but this isn't important.

\begin{note}{\bf Notation.} \label{Onotation}\Marginnote{Onotation} The
symbol $O(3)$ stands for a polynomial or a power series in which all
terms have total degree at least $3$ in the variables that are are
involved.  The only variable in Formula \ref{taylor} is $t$.
\qed\end{note}

 The intersection multiplicity of $C$ and $L$ at $p$ is the lowest
 power of $t$ that has nonzero coefficient in $f(p+tq)$.  The term
 $f(p)$ in (\ref{taylor}) is zero if $p$ lies on $C$.  Then the
 intersection multiplicity is at least $1$.  If $p$ is as smooth point
 of $C$, $L$ is tangent to $C$ at $p$ if and only if $p$ lies on $C$
 and $\sum_i f_i(p)\,q_i$ is zero -- if and only if the intersection
 multiplicity is at least $2$.

Let   $s_i = f_i(p)$.  The equation of the tangent line is
\begin{equation}\MMM{eqtanline}\label{eqtanline}
s_0x_0+s_1x_1+s_2x_2 = 0
\end{equation}



\no {Note.}  Taylor's formula shows that the restriction of $f$ to
every line through a singular point $p$ has a multiple zero, but we
call $L$ a line a tangent only when it is tangent to $C$ at a smooth
point.

\ms Let $\nabla$ be the gradient vector $(f_0,f_1,f_2)$, and let $H$
be the {\it Hessian matrix} of second partial derivatives:
\begin{equation}
H \;=\; \begin{pmatrix} f_{00}&f_{01}&f_{02}\\
f_{10}&f_{11}&f_{12}\\f_{20}&f_{21}&f_{22}\end{pmatrix}
\Marginnote{hessianmatrix}	\label{hessianmatrix}
\end{equation}
Let $\nabla_p$ and $H_p$ be the evaluations of $\nabla$ and $H$,
respectively, at $p$.  Then, regarding $p$ and $q$ as column vectors,
Equation \ref{taylor} can be written as
\begin{equation}
 f(p+tq) = \;f(p) \;+\; \big( \nablap \,q\big)t \;+ \; \textstyle{\frac 1 2}
(q^tH_p\,q) t^2 \;+\; O(3) \Marginnote{texp}	\label{texp}
\end{equation}


\ms

In it, $\langle p , q \rangle$ denotes the symmetric form $v^tH_p\,w$
on $\bbc^3\times \bbc^3$.  It makes sense to say that this form
vanishes on a pair of points. because the formula $\langle
p,q\rangle = 0$ doesn't depend on the vectors that represent those
points.


\begin{proposition}{\text{\bf Proposition.}}\Marginnote{bilinform}\;\,
Let $p$ be a point of $\bbp^2$, let $q$ be a
point distinct from $p$, and let $L$ be the line defined by
\ref{eqtanline}.

\no {\bf (i)} $p$ is a point of $C$ if and only if $\,\langle p,p\rangle
= 0$.

\no
{\bf (ii)}  $L$  is a tangent at a smooth point $p$ of $C$ if and only if
$\,\langle p,p\rangle =\langle p,q\rangle =0$, and 

\no {\bf (iii)} A smooth point $p$ of $C$ is a flex point with tangent
line $L$ if and only if $\,\langle p,p\rangle = \langle p,q\rangle =
\langle q,q\rangle = 0$.\qed \label{bilinform}\end{proposition}

The proposition follows from the next lemma, which
is proved by applying
Euler's Formula to the entries of $\nabla$ and $H$. \qed



\begin{lemma}{\bf Lemma.}\MMM{applyeuler}\label{applyeuler}
Let $d$ be the degree of $f$.  Then 

\no
{\bf (a)} $p^tH_p =
(d-1)\nablap$, and  $\nablap p = d\,f(p)$.

\no {\bf (b)}
  $\,\langle
p,q\rangle = (d-1)\nablap q$, and $\,\langle p,p\rangle =
d(d-1)f(p)$.
\end{lemma}



\begin{theorem}{\text{\bf Theorem.}}\Marginnote{tangentline}\;\,
A smooth point $p$ of a curve $C:\{f=0\}$ is a flex point if and only
if the determinant of the Hessian matrix $H_p$ at $p$ is zero.
 \label{tangentline}\end{theorem}

\begin{proof}
If $\,\det H_p =0$, the form is degenerate, and there is a nonzero
null vector $q$.  Let $p$ be a smooth point of $C$, so that $\langle
p,p\rangle=0$.  Then $\nabla_p \neq 0$, and therefore $\langle
p,v\rangle = (d-1)\nabla_p v$ isn't identically zero
(\ref{applyeuler}).  So the null vector $q$ is distinct from $p$.
Then $\langle p,p\rangle=\langle p,q\rangle = \langle q,q\rangle = 0$,
so $p$ is a flex point.

Conversely, suppose that $p$ is a flex point and that $q$ is on the
tangent line at $p$, so that $\langle p,p\rangle = \langle p,q\rangle
= \langle q,q\rangle = 0$.  The restriction of the form to the
two-dimensional space $W$ spanned by $p$ and $q$ will be zero. A form
on a space $V$ of dimension $3$ that restricts to zero on a
two-dimensional subspace $W$ is degenerate.  If $(p,q,v)$ is a basis
with $p,q$ in $W$, the matrix of the form will 
look like this:
$$\begin{pmatrix} 0 & 0 & *\\
0 & 0 & *\\
* & * & *
\end{pmatrix}
$$ 
\hspace{-0.7cm}\qed\end{proof}


\begin{proposition}{\text{\bf Proposition.}}\Marginnote{hessnotzero}\;\,

\no {\bf (i)} Let $f(x,y,z)$ be an irreducible homogeneous polynomial
of degree $2$ or more.  The Hessian determinant isn't divisible by
$f$. In particular, it isn't identically zero.

\no
{\bf (ii)} A curve has finitely many flex points.
\label{hessnotzero}\end{proposition}


\begin{proof}  
{\bf (i)} Let $C$ be the curve defined by an irreducible polynomial
$f$.  If $f$ divides the Hessian determinant, then every smooth point
$p$ of $C$ will be a flex point.  We set $z=1$ and look on the
standard affine $\bbu^2$.  We may assume that $p$ is the origin and
that $\frac {\partial f}{\partial y} \neq 0$ at $p$.  The Implicit
Function Theorem tells us that we can solve the equation $f(x,y,1)=0$
for $y$ locally, say $y = \varphi(x)$.  The graph $\Gamma: \{y =
\varphi(x)\}$ will be equal to $C$ in a neighborhood of $p$ (see
(\ref{ifthm}) below.)  A point $q$ of $\Gamma$ is a flex point if and
only if $\frac {d^2\varphi}{dx^2}$ is zero at $q$.  If this is true
for all points near to $p$, then $\frac {d^2\varphi}{d x^2}$ will be
identically zero, which implies that $\varphi$ is linear: $y=ax$.
Then $y=ax$ solves $f=0$, and therefore $y\!-\!ax$ divides $f(x,y,1)$
(see \ref{ifthm} below).  But since $f(x,y,z)$ is irreducible, so is
$f(x,y,1)$ (\ref{foneirred}).  Therefore $f(x,y,1)$ and $f(x,y,z)$ are
linear.

\msno
{\bf (ii)}  This follows from {\bf (i)} and Proposition \ref{fgzerofinite}.\qed\end{proof}

\msno \begin{note}{\bf Review.}\MMM{ifthm}\label{ifthm} ({\it about
    the Implicit Function Theorem}) 

Let $f(x,y)$ be a polynomial, and suppose that $\frac{df}{dy}$ isn't
zero at the origin $(0,0)$.  The Implicit Function Theorem tells us
that there is a unique analytic function $\varphi(x)$, defined for
small $x$, such that $\varphi(0)=0$ and $f(x,\varphi(x))$ is
identically zero.  

We'll make two further remarks.  First, let $\Cal R$ be the ring of
analytic functions of $x$.  In the ring ${\Cal R}[y]$ of polynomials
in $y$ with coefficients in $\Cal R$, $y-\varphi(x)$ divides
$f(x,y)$.  To see this, we divide $f$ by the monic polynomial
$y-\varphi(x)$:
\begin{equation}\MMM{divrem}\label{divrem}
f(x,y) = (y-\varphi(x))q(x,y) + r(x)
\end{equation}
 The quotient $f(x,y)$ is in ${\Cal R}[y]$, and the remainder $r(x)$ is in
 $\Cal R$ because it has degree zero in $y$.  Setting $y=\varphi(x)$
 in the equation shows that the remainder is zero.

Next, let $\Gamma$ be the graph of $\varphi(x)$ in a suitable
neighborhood of the origin in $x,y$-space.  Since $f(x,y) =
(y-\varphi(x))q(x,y)$, the locus $f(x,y)=0$ has the form $\Gamma\cup
\Delta$, where $\Delta$ is the zero locus of the quotient $q(x,y)$.
We differentiate, finding that $q(0,0) = \frac{\partial f}{\partial
  y}(0,0)$.  So $q(0,0)\neq 0$.  Then $\Delta$ doesn't contain the
origin while $\Gamma$ does.  This implies that $\Delta$ is disjoint
from $\Gamma$, locally (in a neighborhood of $p$).  Therefore, in a
sufficently small neighborhood of $p$, the locus of zeros of $f$ is
equal to $\Gamma$.  \qed
\end{note}


 \section{Nodes and Cusps} \label{nodes}\Marginnote{nodes}

\msno We take a look here at nodes and cusps, the simplest
singularities of curves.


\ms Let $C$ be the projective curve defined by a homogeneous
polynomial $f(x,y,z)$ of degree $d$.  We choose coordinates so that
the point we wish to inspect is $p=(0,0,1)$, and we set $z=1$.  This
gives us an affine curve $C_0$ in $\bba^2_{x,y}$, the zero set of the
polynomial $\tf(x,y) = f(x,y,1)$, and $p$ becomes the origin $(0,0)$.  We
write
\begin{equation}
 \tf(x,y) = f_0(x,y) + f_1(x,y) + f_2(x,y) + \cdots,\Marginnote{seriesf}
	\label{seriesf}
\end{equation}
where $f_i$ is the homogeneous part of $\tf$ of degree $i$. Then
$f_i$,unless it is zero, is also the coefficient of $z^{d-i}$ in the
polynomial $f(x,y,z)$.  If the origin $p$ is a point of $C_0$, the
constant term $f_0$ will be zero.  Then the linear term $f_1$ will
define the tangent direction to $C_0$ at $p$, If $f_0$ and $f_1$ are
both zero, $p$ will be a singular point of $C$.

\begin{boldequation}\Marginnote{singmult} 
\hspace{-7cm} \textbf{the multiplicity of a singular point}
\label{singmult}\end{boldequation}

  To describe the singularity
of $C$ at the origin $p$, one looks first at the part of
$\tf$  of lowest degree.  The smallest integer $r$ such
that $f_r(x,y)$ isn't zero is  the {\it multiplicity} of $p$.
If $p$ is a point of multiplicity $r$, the
polynomial that defines $C_0$ will have the form
\begin{equation}
 \tf(x,y) = f_r(x,y) + f_{r+1}(x,y) + \cdots \Marginnote{multr}
 	\label{multr}
\end{equation}


Let $L$ be
a line $\{vx=uy\}$ through $p$.  The interesection multiplicity of
$C$ and $L$ at $p$ will be $r$ unless $f_r(u,v)$ is zero.  If
$f_r(u,v)=0$, the intersection multiplicity will be greater than $r$.
In that case, we call $L$ a {\it special line}.  The special
lines at $p$ correspond to the zeros of $f_r$ in $\bbp^1$. There will
be at most $r$ special lines, because $f_r$ has degree $r$.

\begin{boldequation}\Marginnote{dpt} 
\hspace{-10.5cm} \textbf{double points}
\label{dpt}\end{boldequation}

\ms
Suppose that $p$ is a {\it double point}, a point of multiplicity $2$,
and let the quadratic part of $f$ be
\begin{equation}
 f_2= ax^2+bxy+cy^2\Marginnote{quadraticterm}
 \label{quadraticterm}
\end{equation} 


\no The double point $p$ is called a {\it node} if
$f_2$ has distinct zeros in $\bbp^1$.  There will be two special lines
at a node.  A node is the simplest singularity that a curve can have.

\ms If the discriminant $b^2-4ac$ of $f_2$ is zero, $f_2$ will be a
square and there will be just one special line at $p$.  Suppose that
$b^2-4ac =0$.  We may arrange coordinates so that $c\neq 0$.  Then
\begin{equation}\label{discrzero}\Marginnote{discrzero}
(bx+2cy)^2 = 4c(ax^2+bxy+cy^2)
\end{equation}
The unique special line at $p$ is the line $\{bx+2cy=0\}$.  The
point $p$ is called a {\it cusp} if the multiplicity of intersection
of $C$ and $L$ at $p$ is $3$. This will be true if and only if
$bx+2cy$ doesn't divide $f_3(x,y)$.

When the discriminant is zero, one can adjust coordinates to make $f_2
= y^2$.  Then the special line is the line $\{y=0\}$, and $p$ is a a
{cusp} if the coefficient of the monomial $x^3$ in $f_3$ isn't zero.
The {\it standard cusp} is the locus $y^2=x^3$.


\ms
The simplest example of a double point that isn't a node or cusp is
a {\it tacnode}, a point at which two smooth branches of a curve intersect
with the same tangent direction (see Figure \ref{somesingpts}).


\begin{boldequation}
\Marginnote{blowupnodecusp} \hspace{-8.5cm} 
\textbf{blowing up nodes and cusps}
	\label{blowupnodecusp}
\end{boldequation}

\ms One way to analyze a singular point of a curve is to see
what happens when one blows up the plane.  We use an affine
blowing up here.  Let $U$ be the $x,y$-plane, and let $V$ be a second
affine plane, with coordinates $x,\tee$.  The map $V
\stackrel{\pi}{\longrightarrow} U$ defined by $x=x$, and
$y=x\tee$: $$\pi(x,\tee) = (x,x\tee)$$ is the {\it affine blowing up} of the
origin $p=(0,0)$ in $U$.

\no To describe the geometry of the blowing up, we inspect the fibres
of $\pi$.  When $x\neq0$, the fibre of $\pi$ over the point $(x,y)$
consists of a single point $(x,\tee)$ with $t=x^{-1}y$.  When
$(x,y)=(0,y)$ and $y\neq0$, the fibre is empty.  The most interesting
fibre is the one over the origin $(0,0)$.  It is the line
$$\TEE :\{x=0\}$$ in $V$, whose points correspond to tangent
directions at $p$ in a way that is explained below.  The map $\pi$ is
called a {blowup} because the origin in $U$, a point, is 'blown up'
into a line in $V$.

\ms
\centerline{figure}

\ms Suppose that the origin $p$ is a point of multiplicity $r$ of an
affine curve $C_0$, so that the polynomial that defines $C_0$ has the
form (\ref{multr}).  We choose coordinates so that the part $f_r$ of
degree $r$ isn't divisible by $x$, we substitute $y=x\tee$ into $\tf$,
and pull out powers of $x$:
 $$ \tf(x,x\tee) = x^rf_r(1,\tee) + x^{r+1}f_{r+1}(1,\tee) + \cdots$$
Let $g$ be quotient $\tf(x,x\tee)/x^r$.  So

\begin{equation}
g(x,\tee) = f_r(1,\tee) + x\, h(x,\tee)  \Marginnote{blowupcusptwo}
	\label{blowupcusptwo}
\end{equation}
where
$$h = f_{r+1}()1,t)+ xf_{r+2}(1,t) + \cdots$$.  
The curve $C_1 :\{g=0\}$
in $V$ is the {\it blowup} of $C_0$.

The points of $C_1$ that lie over $p$ are its intersections with the
fibre $\TEE$.  We set $x=0$ to compute those intersections: $g(0,\tee)
= f_r(1,\tee)$.  The intersections are the points $\tee=\alpha$, where
$\alpha$ is a root of this polynomial. They correspond to the zeros of
$f_r(x,y)$ in $\bbp^1_{x,y}$\,.


\ms \centerline{figure}\ms

\ms A smooth point of $C_0$ has multiplicity one: $f_1 \neq 0$.
Suppose that this is so, and that $f_1 = ax-by$.  The tangent line $L$
at $p$ isthe line $ax-by=0$. Then $f_1(1,\tee) = a-b\tee$, and
since$f_1$ isn't divisible by $x$, $b\neq 0$.  The only intersection
of $C_1$ with $\TEE$ is the point $\tee= a/b$, and $a/b$ is the slope
of the tangent line $L$ at $p$.  In this way, points of
$\TEE$ correspond to tangent directions.

\ms
If $p$ is a double point of $C_0$.  Then
$
 \tf(x,y) = f_2(x,y) + f_{3}(x,y) + \cdots 
.$
 The intersections of $C_1$ with $\TEE$ are determined by the
 two roots of $f_2(1,\tee)$,  corresponding to the two zeros of
 $f_2(x,y)$ in $\bbp^1_{x,y}$.

\begin{proposition}{\text{\bf Proposition.}}\Marginnote{blowupcusp}\;\,
With assumptions and notation as above:

\no {\bf (i)} The multiplicity of the point $p$ is equal to the number
of intersections, counted with multiplicity, of the blowup curve $C_1$
with the line $\TEE$.

\no
{\bf (ii)} A double point $p$ is a node
or a cusp if and only if the blowup $C_1$ is smooth at the points
that lie over $p$.  If $C_1$ is smooth at those points, then

 {\bf (a)}\; $p$ is a node if $f_2(x,y)$ has distinct zeros in $\bbp^1$,  and

 {\bf (b)}\;  $p$ is a cusp if $f_2(x,y)$ has a double zero.
\label{blowupcusp} \end{proposition}


\begin{proof}  {\bf (ii)}
Suppose that $p$ is a double point of $C$. Recall that coordinates have
been chosen so that the quadratic polynomial $f_2$ isn't divisible by
$x$.  So $C_1\cap \TEE$ consists of two points of multiplicity one or
one point of multiplicity two.  If $f_2(x,y)$ has two zeros in
$\bbp^1$, $p$ is a node (\ref{quadraticterm}).  Then $f_2(1,\tee)$ has
two roots, say $\alpha_1,\alpha_2$, and is a scalar multiple of
$(\tee-\alpha_1)(\tee-\alpha_2)$.  The partial derivative
$\frac{\partial g}{\partial \tee}$ isn't zero at the points
$(0,\alpha_1)$ and $(0,\alpha_2)$, so they are smooth points
of $C_1$.  Conversely, if $C_1\cap \TEE$ consists of two smooth points
of $C_1$, those points correspond to zeros of multiplicity $1$ of
$f_2$.

Suppose that $C_1\cap \TEE$ consists of a single point of multiplicity
two.  We may choose coordinates so that $f_2 = y^2$, and then
$g(x,\tee) = \tee^2 + xh(x,\tee)$.  The curve $C_1$ will be smooth at
$p_1$ if and only if the linear term of $g$, which is $xh(0,0)$, isn't
zero.  The constant coefficient $h(0,0)$ of $h$ is $f_3(1,0)$, which
is the coefficient of $x^3$ in $f_3(x,y)$.  So $C_1$ is smooth over
$p$ if and only if the coefficient of $x^3$ is nonzero \,--\, if and
only if $p$ is a cusp.  \qed\end{proof}


\ms A singularity more complicated than a node or cusp can be
``resolved'' (made smooth) by repeating the blowing up process a
finite number of times.  For example, the curve $C_0$: $y^2=x^4+x^5$
has a tacnode at the origin.  Blowing up, we obtain the curve $C_1$:
$t^2 = x^2+x^3$, a nodal curve.  A second blowing up resolves the
singularity.

\section{Transcendence degree} 
\label{transcdeg}
\Marginnote{transcdeg}[-.6cm] 

\#\#$[K:F] < \infty$ implies same tr deg\#\#


\msno Let $F\subset K$ be a field extension.  A set $\alpha =
\{\alpha_1,...,\alpha_n\}$ of elements of $K$ is {\it algebraically
  dependent} over $F$ if there is a nonzero polynomial
$f(x_1,...,x_n)$ with coefficients in $F$, such that $f(\alpha)=0$.
If $f(\alpha)\neq 0$ for every nonzero polynomial $f$ with
coefficients in $F$, then $\alpha$ is {\it algebraically independent}
  over $F$.  An infinite set is called algebraically independent if
every finite subset is algebraically independent -- if
there is no polynomial relation among any finite set of elements of
$\alpha$.

The set consisting of a single element $\alpha_1$ of $K$ is
algebraically dependent if and only if $\alpha_1$ is algebraic over
$F$, and is {\it transcendental} over $F$ if it isn't algebraic over
$F$.  So $\alpha_1$ is transcendental when the set $\{\alpha_1\}$ is
algebraically independent.

A set $\alpha = \{\alpha_1,...,\alpha_n\}$ is a {\it transcendence
  basis} for $K$ over $F$ if it a maximal algebraically independent
set   -- if it isn't contained in a larger algebraically independent
set. 
  If $K$ has a finite transcendence basis, the number
of elements in a transcendence basis is the {\it transcendence degree}
of the field extension $K$ of $F$. Lemma \ref{trdeg} below shows that this
number doesn't depend on  the transcendence basis.

 For example, let $K=F(x_1,...,x_n)$ be the field of rational
 functions in $n$ variables.  The variables form a
 transcendence basis of $K$ over $F$, and the transcendence degree of
 $K$ over $F$ is $n$.

\ms We use the customary notation $F[\alpha_1,...,\alpha_n]$ or
$F[\alpha]$ for the algebra generated by a set $\alpha$, and if
$F[\alpha]$ is a domain, a nonzero (commutative) ring with no zero
divisors, we may denote its field of fractions by
$F(\alpha_1,...,\alpha_n)$ or $F(\alpha)$.

\ms By the way, in these notes the word {\it ring} means {\it
  commutative ring}, i.e., multiplication is required to be a
commutative law of composition.



\begin{lemma}{\text{\bf Lemma.}}\Marginnote{algindtrivialities}\;\,
Let $K/F$ be a field extension, let $\alpha =
\{\alpha_1,...,\alpha_n\}$ be an algebraically independent subset of
$K$ over $F$.  

\no {\bf (i)} Every element of the field $F(\alpha)$ that is not in $F$
is transcendental over $F$.


\no {\bf (ii)} If $\beta$ is another element of $K$, the
set $\alpha \cup \{\beta\}$ is algebraically dependent if
and only if $\beta$ is algebraic over the field $F(\alpha)$.

\no {\bf (iii)} The set $\alpha$ is a transcendence basis 
 if and only if every element of $K$ is algebraic over $F(\alpha)$.
\label{algindtrivialities}\end{lemma}

\begin{proof}{\bf (i)} 
Suppose that a rational function $z$ is written as a fraction
$p(\alpha)/q(\alpha)$, where $p$ and $q$ are relatively prime
polynomials, and that $z$ satisfies a nontrivial polynomial relation
$c_0z^n + c_1z^{n-1} + \cdots + c_n =0$, with $c_i$ in $F$.  We may
assume that $c_0 \neq 0$, and we normalize $c_0$ to $1$.  Multiplying
the relation by $q^n$ gives us an equation $$p^n = -q(c_1p^{n-1} +
\cdots + c_nq^{n-1})$$ This equation shows that $q$ divides $p^n$,
which contradicts the hypothesis that $p$ and $q$ are relatively
prime.\qed\end{proof}
 

\begin{lemma}{\text{\bf Lemma.}}\Marginnote{trdeg}\;\,
Let $K/F$ be a field extension.  If $K$ has a finite transcendence
basis, then all algebraically independent subsets of $K$ are finite,
and all transcendence bases have the same number of elements.
\label{trdeg} \end{lemma}

\begin{proof} We show that  if $K$ is algebraic over a
subfield $F(\alpha_1,...,\alpha_s)$ and if
$\beta=\{\beta_1,...,\beta_r\}$ is an algebraically independent
subset, then $r \leq s$.  The fact that all transcendence bases have
the same order will follow: If both $\alpha$ and $\beta$ are
transcendence bases, then $r\leq s$ and, since we can interchange
$\alpha$ and $\beta$, $s\leq r$.

The proof proceeds by reducing to the trivial case that $\beta$ is a
subset of $\alpha$.  
Suppose that some element of $\beta$, say
$\beta_r$, isn't in the set $\alpha$.  The set $\beta' =
\{\beta_1,...,\beta_{r-1}\}$ isn't a transcendence basis, so $K$ isn't
algebraic over $F(\beta')$.  Since $K$ is algebraic over $F(\alpha)$,
there is at least one element of $\alpha$, say $\alpha_s$, that isn't
algebraic over $F(\beta')$.  Then $\gamma = \beta'\cup \{\alpha_s\}$
will be an algebraically independent set of order $r$, and it will
contain more elements of the set $\alpha$ than $\beta$ does. Induction
shows that $r\leq s$. \qed\end{proof}


 \section{The Dual Curve} \label{dualcurve}\Marginnote{dualcurve}[-.6cm]


\begin{boldequation}
\Marginnote{dualplanesect}\hspace{-10.5cm} \textbf {the dual plane}
	\label{dualplanesect} 
\end{boldequation}


 Let $\bbp$ denote the projective plane with coordinates
$x_0,x_1,x_2$, and let $L$ be the line with an equation
\begin{equation}s_0x_0+s_1x_1+s_2x_2 =0. \Marginnote{lineequation}  
\label{lineequation} \end{equation} 
The solutions of this equation determine the coefficients $s_i$ only
up to a nonzero scalar factor, so $L$ determines a point
$(s_0,s_1,s_2)$ that we denote by $L^*$ in another projective plane
$\bbp^*$, the {\it dual plane}.  Moreover, a point $p=(x_0,x_1,x_2)$ in
$\bbp$ determines a line $p^*$ in the dual plane, the line with the
equation (\ref{lineequation}), when $s_i$ are regarded as the
variables and $x_i$ as the scalar coefficients.  The equation exhibits
a duality between $\bbp$ and $\bbp^*$.  A point $p$ of $\bbp$ lies on
a line $L$ if and only if the equation is satisfied, and this means
that, in $\bbp^*$, the point $L^*$ contains the line $p^*$.

\begin{boldequation}
\Marginnote{dualcurvetwo}\hspace{-10.5cm} \textbf {the dual curve}
	\label{dualcurvetwo} 
\end{boldequation}

 Let $C$ be a plane projective curve defined by an irreducible
 homogeneous polynomial of degree $d\geq 2$, and let $U$ be the set of
 its smooth points.  Since $C$ has finitely many singular points, $U$
 is the complement of a finite set.  We define a
 map $$U\stackrel{\lct}{\longrightarrow}\bbp^*$$ as follows: Let $p$
 be a point of $U$, a smooth point of $C$, and let $L$ be the tangent
 line to $C$ at $p$.  We define $\lct(p)=L^*$, where $L^*$ is the
 point of the dual plane $\bbp^*$ that corresponds to $L$.  We don't
 try to define this map at the singular points of $C$.  The degree of
 $C$ is assumed to be at least two because, if $C$ were a line, $U^*$
 would be a point.

 The tangent line
$L$ at a smooth point $p = (x_0,x_1,x_2)$ of $C$ has the equation
$s_0x_0+s_1x_1+s_2x_2=0$, where $s_i$ is the partial derivative
$f_i(x) = \frac{\partial f}{\partial x_i}$.  Therefore $L^*$ is the
point
\begin{equation}(s_0,s_1,s_2) = \big(f_0(x),f_1(x),f_2(x)\big)
\Marginnote{ellstarequation}\label{ellstarequation}\end{equation} 

Let $U^*$ denote the image of $U$ in $\bbp^*$.
Points of  $U^*$ of $U$ correspond to tangent lines at
smooth points of $C$.  

$$??figure??$$


\begin{lemma}{\bf Lemma.} \MMM{phizerogzero}\label{phizerogzero}
A polynomial $\varphi(s_0,s_1,s_2)$ is identically zero on $U^*$ if
and only if $g(x)=\varphi(f_0(x),f_1(x),f_2(x))$ is identically zero
on $U$, and this is true if and only if $f$ divides $g$.
\end{lemma}

\no
See Corollary \ref{functioniszero}.\qed


\begin{theorem}{\text{\bf Theorem.}}\Marginnote{dualcurvethm}\;\,
Let $C$ be the plane curve defined by an irreducible polynomial $f$ of
degree $d\geq 2$.  With notation as above, the closure $C^*$ of $U^*$
in $\bbp^*$ is a curve in the dual space, the {\bf dual curve}.
\label{dualcurvethm} \end{theorem}


\msno
\begin{proof} If an irreducible
homogeneous polynomial $\varphi(s_0,s_1,s_2)$ vanishes on $U^*$, it
will be unique up to scalar factor (Corollary \ref{idealprincipal}).
Its zero locus will be the dual curve.

We show first that there is a nonzero polynomial $\varphi$, not
necessarily irreducible or homogeneous, that vanishes on $U^*$.  The
field $\bbc(x_0,x_1,x_2)$ has transcendence degree $3$ over $\bbc$.
Therefore the four polynomials $f_0,f_1,f_2$, and $f$ are
algebraically dependent.  There is a nonzero polynomial
$\psi(s_0,s_1,s_2,t)$ such that $\psi(f_0,f_1,f_2,f)=0$.  We can
cancel factors of $t$, so we may assume that $\psi$ isn't divisible by
$t$.  Let $\varphi(s_0,s_1,s_2) = \psi(s_0,s_1,s_2,0)$.  This
polynomial isn't zero when $t$ doesn't divide $\psi$.  If $x$ is a
point of $U$, then $f(x)=0$, and therefore $\varphi(f_0,f_1,f_2) =
\psi(f_0,f_1,f_2,f)=0$.  Lemma \ref{phizerogzero} tells us that
$\varphi(s)$ vanishes on $U^*$.

The homogeneous parts of $\varphi$ vanish on $U^*$
(\ref{hompartszero}), so we may assume that $\varphi$ is homogeneous,
say of degree $r$.  Then the polynomial $g(x) =
\varphi(f_0(x),f_1(x),f_2(x))$ is also homogeneous, of degree
$r(d-1)$.  It will vanish on $U$, and therefore on $C$
(\ref{functioniszero}).  So $f$ will divide $g$.  Finally, if
$\varphi(s)$ factors, then $g(x)$ factors accordingly, and because $f$
is irreducible, it will divide one of the factors of $g$.  The
corresponding factor of $\varphi$ will vanish on $U^*$
(\ref{phizerogzero}).  So we may replace the polynomial $\varphi$, now
homogeneous, by one of its irreducible factors.
\qed\end{proof}


\ms It can be painful to determine the defining polynomial of a dual
curve explicitly.  Several points of the dual curve $C^*$ may
correspond to a singular point of $C$ and vice versa, and the degrees
of $C$ and $C^*$ are often different.  However, the computation is
simple for a conic.

 \begin{example}{\bf Example.}\Marginnote{exampledualone}
\;\label{exampledualone}({\it the dual of a conic})\;
 Let $C$ be the conic $f =0$, with $f = x_0x_1+x_0x_2+x_1x_2$ (see
 Proposition \ref{classifyconic}), and let $(s_0,s_1,s_2) = (f_0,f_1,f_2) =
 (x_1\!+\!x_2,x_0\!+\!x_2,x_0\!+\!x_1)$.  Then
\begin{equation}s_0^2+s_1^2+s_2^2 - 2(x_0^2+x_1^2+x_2^2) \;= 2f\quad\;\;
\text{and}\quad\;  s_0s_1+s_1s_2+s_0s_2 - (x_0^2+x_1^2+x_2^2) \; = 3f
\Marginnote{exampledualtwo}\label{exampledualtwo} 
\end{equation}
 Setting $f=0$ gives us the equation  of the dual curve:
 \begin{equation}
 (s_0^2+s_1^2+s_2^2) - 2(s_0s_1+s_1s_2+s_0s_2) =
   0\Marginnote{equationdualthree}
 	\label{equationdualthree}
\end{equation}
It is another conic.\qed
\end{example}

\begin{boldequation}
\Marginnote{equationofcstar}\label{equationofcstar}
 \hspace{-7.5cm} 
\textbf{a local equation for the dual curve}
\end{boldequation}

 We label the coordinates in $\bbp$ and $\bbp^*$ as $x,y,z$ and
 $u,v,w$, respectively, and we work in a neighborhood of a smooth point $p$
 of the curve $C$ defined by a polynomial $f(x,y,z)$.  We choose
 coordinates so that $p = (0,0,1)$, and that the tangent line $L$ at
 $p$ is the line $\{y=0\}$.

 Let $\tf(x,y) = f(x,y,1)$.  In the affine $x,y$-plane, the point $p$
 becomes $\tp = (0,0)$.  So $\tf(0,0)=0$, and since the tangent line
 is horizontal, $\frac {\partial \tf}{\partial y}(0,0) \neq 0$.  This
 allows us to solve the equation $\tf=0$ for $y$ as an analytic
 function $y(x)$ for small $x$, with $y(0)=0$.  Let $y'(x)$ denote
 the derivative $\frac {dy}{dx}$.  Then $y(0) = y'(0) =0$.

Let $\tp_1 = (x_1,y_1)$ be a point of $C_0$ near to $\tp$, and let
$y_1$ and $y_1'$ denote $y(x_1)$  and $y'(x_1)$, respectively. The
tangent line $L_1$ at $\tp_1$ has the equation
\begin{equation}
  y-y_1= y'_1(x-x_1)\Marginnote{localtangent}	
  \label{localtangent}
\end{equation}

So the point $L_1^*$ of the dual plane that corresponds to $L_1$, in
projective coordinates, is $(-y_1',1,y_1'x_1-y_1)$.  Let's drop the
subscript $1$.  Then as $x$ varies,
\begin{equation}
(u,v,w) = (-y',1,y'x-y),
\Marginnote{projlocaltangent}
	\label{projlocaltangent}
\end{equation}
traces out $C^*$ near the point $L^*$ (see (\ref{ifthm})). \qed

\bs
\begin{boldequation}
\Marginnote{bidualone}\label{bidualone}
 \hspace{-11cm} 
\textbf{the bidual}
\end{boldequation}


The {\it {bidual}} $C^{**}$ of a curve $C$ is the dual of
the curve  $C^*$.

\begin{theorem}{\text{\bf Theorem.}} \Marginnote{bidualC}\;\,
A plane curve of degree at least $2$ is equal to its bidual $C^{**}$.
\label{bidualC} \end{theorem}

\begin{lemma}{\bf Lemma.}\Marginnote{vopen}\;
The set $V$ of points $p$ such that $C$ is smooth at $p$ and $C^*$ is
smooth at $\lct(p)$ is the complement of a finite subset of $C$.
\label{vopen}\end{lemma}

\begin{proof}   
The points of $V$ are the points of $U$ that aren't in the inverse
images of the finitely many singular points of $C^*$.  When we show
that the fibres of the map $U \ar U^*$ are finite sets it will follow
that $V$ is the complement of a finite set.

Let $s=(s_0.s_1,s_2)$ be a point of $C^*$.  We may suppose that one of
the coordinates, say $s_0$, is equal to $1$.  If $s$ is the image of a
smooth point $x$ of $C$, then $(f_0(x),f_1(x),f_2(x))= \lambda
(1,s_1,s_2) $, which means that $\lambda = f_0(x)$, $f_1(x) =
s_1f_0(x)$ and $f_2(x) = s_2f_0(x)$.  Then at the point $x$, $f=0$ and
$g_i = f_i-s_if_0 = 0$ for $i=1,2$.  The polynomials $g_1,g_2$ can't
both be identically zero (see (\ref{singpointoncurve}){\bf (ii)}).
Say $g_1\neq 0$.  Then there are finitely many points $x$ at which $f$
and $g_1$ are zero, because the irreducible polynomial $f$ and the
lower degree polynomials $g_1$ have no common factor
(\ref{fgzerofinite}).  So the inverse image of $s$ is
finite.\qed\end{proof}

\msno {\it proof of Theorem \ref{bidualC}.} Let $V$ be as in Lemma
\ref{vopen}, and let $V^*$ be its image $t(V)$.  If $L$ is the tangent
line to $C$ at a point $p$ of $V$, then $\lct(p) = L^*$ is a smooth point of
$V^*$.  We will show that

\begin{equation}
\label{tangenttangent}\Marginnote{tangenttangent}
\text{\it The line $p^*$ is tangent to $C^*$ at the point $L^*$.}
\end{equation}

\msno Assume that this is shown.  Let $U^*$ denote the set of smooth
points of $C^*$, and let $U^* \stackrel {t^*}\rrr \bbp^{**}$ be the
map analogous to the map $t$. Then $t^*(L^*)$ is the point $(p^*)^*$
of $\bbp$, and therefore $p^{**} = p$.  So for all points $p$ of $V$,
$t^*t(p) = t^*(L^*) = p$.  Therefore the restriction of $t$ to $V$ is
injective.  It defines a bijective map from $V$ to its image $V^*$,
whose inverse function is $t^*$.  So $V \subset C^{**}$.  Since $V$ is
dense in $C$ and $C^{**}$ is closed, $C\subset C^{**}$.  Since $C$ and
$C^*$ are curves, $C=C^{**}$.\qed

\msno To prove (\ref{tangenttangent}), we choose a second point $p_1$
of $V$, and we let it approach $p$.  Let $L_1$ be the tangent line
to $C$ at $p_1$.  Because the image of $p_1$ is $L_1^* =
(f_0(p_1),f_1(p_1),f_2(p_1))$, and because the partial derivatives
$f_i$ are continuous, $\limp L_1^* = (f_0(p),f_1(p),f_2(p)) = L^*$.

\begin{lemma}{\text{\bf Lemma.}}\Marginnote{qapproachesp}\;\,
With notation as above, let $q$ be intersection $L_1\cap L$.  Then
$\limp q = p$.
\label{qapproachesp}\end{lemma}


$$figure$$

\no
Let's assume the lemma for a moment.  In the dual space $\bbp^*$,
$q^*$ is the line through the two points $L^*_1$ and $L^*$.  Since
$\limp L_1^* = L^*$, $q^*$ approaches the tangent line to $C^*$
at $L^*$.  On the other hand, the lemma tells us that $q^*$
approaches $p^*$.  Therefore the tangent line at $L^*$ is
$p^*$. \qed


\msno {\it proof of Lemma} \ref{qapproachesp}. We work analytically in
a neighborhood of $p$.  We choose coordinates so that $p =
(0,0,1)$ and that $L$ is the line $\{y=0\}$.  Let $(x_q,y_q,1)$ be
the coordinates of $q = L\cap L_1$.  Since $q$ is a point of
$L$, $y_q=0$, and $x_q$ can be obtained by substituting $x=x_q$ and
$y=0$ into the equation (\ref{localtangent}) for $L_1$:
$$x_q \;= \; x_1 - y_1/y'_1.$$ Now: When a function has an $n$th order
zero at a point, i.e, when it has the form $y = x^nh(x)$, where $n>0$
and $h(0) \neq 0$, the order of zero of its derivative at that point
is $n\!-\!1$.  This is verified by differentiating $x^nh(x)$.  Since the
function $y(x)$ is zero at $p$, $\limp y_1/y'_1 = 0$.
It follows that $\limp x_q  = 0$ and that  $\limp q = (0,0,1) = p$. \qed

\begin{corollary}{\bf Corollary.}
\Marginnote{cstarisimage}\label{cstarisimage}
If $C$ is a smooth curve, the map $C \stackrel t \rrr C^*$, which is
defined at all points of $C$, is a surjective map.\end{corollary}

\begin{proof}  Let $W$ denote the image of $C$ in $C^*$.
  The map $C^* \stackrel{t^*}\longrightarrow C$ is defined at the
  smooth points of $C^*$, and it inverts $t$ at those points.
  Therefore $W$ contains the smooth points of $C^*$.  So $C^* = W \cup
  S$ where $S$ is a finite set.  Because $C$ is  compact, its
  image $W$ is compact, and therefore closed in $C^*$.  Then
  $S$ is open.  And since it is a finite set, it is
  closed.  Therefore $S$ consists of isolated points
  of $C^*$.  Since a curve has no isolated points
  (\ref{noisolatedpoint}), $S$ is empty.\qed\end{proof}

\begin{boldequation}
\Marginnote{singdual}\label{singdual}
 \hspace{-8cm} 
\textbf{singularities of the dual curve}
\end{boldequation}


Let $C$ be a plane curve.  A tangent line $L$ at a
smooth point $p$ of $C$ is an {\it ordinary tangent} if $p$ isn't a flex
point, and a flex point $p$ is {\it ordinary} if the the intersection
multiplicity of the curve and its tangent line at $p$ is precisely
$3$.  A {\it bitangent} to a curve $C$ is a line $L$ that is tangent
to $C$ at distinct smooth points $p$ and $q$. A bitangent is {\it
  ordinary} if neither $p$ nor $q$ is a flex point, $L$ isn't tangent
to $C$ at a third point, and $L$ doesn't contain a singular point of
$C$. 




\begin{proposition}{\text{\bf Proposition.}}\Marginnote{dualcusp}\;\,
Let $p$ be a smooth point of a curve $C$, and let $L$ be the tangent
line at $p$.  Suppose that $L$ doesn't contain a singular point of $C$.

\no {\bf (i)} If $L$ is an ordinary tangent at $p$ and not a bitangent,
 $L^*$ is a smooth point of $C^*$.

\no {\bf (ii)} If $p$ is an ordinary flex point and not a bitangent,
 $L^*$ is a cusp of $C^*$.

\no {\bf (iii)} If $L$ is an ordinary bitangent, 
$L^*$ is a node of $C^*$.
\label{dualcusp}\end{proposition}



\begin{proof}  We set $z=1$ and
 choose affine coordinates so that $p$ is the origin and the tangent
 line $L$ at $p$ is  the line $\{y=0\}$.  Let $\tf(x,y)=f(x,y,1)$.  We solve
 $\tf = 0$ for $y = y(x)$ as analytic function of $x$ near zero, as
 before.  The tangent line $L_1$ to $C$ at  nearby points
 $p_1=(x,y)$ has the equation (\ref{localtangent}), and $L_1^*$ is
 the point $(u,v,w) =
 (-y',1,y'x-y)$ of $\bbp^*$ (\ref{projlocaltangent}).


If $L$ is an ordinary tangent line, $y(x)$ will have a zero of order
$2$ at $x=0$.  Then $u = -y'$ will have a simple zero there.  The
Implicit Function Theorem solves for $x$ as a function of $u$.  Then
$w$ becomes a function of $u$, and since $y'$ has a simple zero, $C^*$
is smooth at the origin.

If $L$ is an ordinary bitangent, tangent to $C$ at two points $p$
and $q$, the reasoning given for an ordinary tangent shows that the
images in $C^*$ of small neighborhoods of $p$ and $q$ in $C$ will be
smooth at $L^*$.  Their tangent lines $p^*$ and $q^*$ will
be distinct.  Therefore the blowup of $C^*$ at $L^*$ consists of
two smooth points, and $L^*$ is a node (see Proposition
\ref{blowupcusp}).

Suppose $p$ is an ordinary flex.  Then $y$ has a triple zero at $x=0$,
say $y = cx^3 + O(4)$ with $c\neq 0$.  Then in
(\ref{projlocaltangent}),
$u= -3cx^2+
O(3)$ has a zero of order $2$, and  $w= 2cx^3+O(4)$
 has a zero of order $3$.  We
blow up $C^*$, substituting $u=u$ and $w=ut$. Then $t$ has a zero of
order $1$, so $u$ is a function of $t$ near zero.  Therefore the
blowup $C_1^*$ is smooth at the point $(u,t) = (0,0)$. Proposition
\ref{blowupcusp} shows that $L^*$ is a cusp. \qed\end{proof}

\begin{corollary}{\text{\bf Corollary.}}\Marginnote{finitebitangents}\;\,
A plane curve has
finitely many bitangents.
\label{finitebitangents} \end{corollary}

\no This is true whether or not the bitangents are ordinary, and it
This follows from the fact that the dual curve $C^*$ has finitely many
singular points (\ref{singpointoncurve}).  If $L$ is any bitangent,
$L^*$ will be a singular point of $C^*$.  \qed


 \begin{example}{\bf Example.}\Marginnote{cuspcubic}\;
({\it the dual of a cuspidal cubic}) It is painful to compute the
   equation of the dual of a smooth cubic.  We will see in a while
   that a smooth cubic curve has has $9$ flex points
   (\ref{nineflexes}), so its dual  has $9$ cusps.  We will also
   see that the degree of the dual curve is $6$ (\ref{classofcurve} {\bf
     (ii)}).

   We compute the dual of a cubic with a cusp instead.
   The curve $C$ defined by the irreducible polynomial $f = y^2z+x^3$
   has a cusp at $(0,0,1)$ as its only singularity.  The Hessian
   matrix of $f$ is
$$H \;=\; \begin{pmatrix} 6x & 0 & 0\\ 0 & 2z & 2y\\ 0 & 2y & 0
\end{pmatrix}$$ 
and the Hessian determinant $h$ is $-24 xy^2$.  The common zeros of $f$
and $h$ are the cusp point $(0,0,1)$ and a single flex point
$(0,1,0)$.  We can guess the result.  The dual curve $C^*$ will have
a flex and a cusp  that  correspond to the cusp and the flex of $C$,
respectively.  It is probably  another cuspidal cubic.


The proof of Theorem \ref{dualcurvethm} gives us a method for finding
a polynomial that vanishes on $C^*$.  That is to find a relation among
$f_x,f_y,f_z,f$, and then set $f=0$.

We scale the partial derivatives of $f$ to simplify notation.  Let $u
= x^2 = f_x/3$, \,$v= yz = f_y/2$, and \,$w = y^2 = f_z$.  
Then
$$f^2 = y^4z^2 + 2x^3y^2z + x^6 = v^2w + 2uv(xy) + u^3$$ Working
modulo $f$, \; $v^2w+u^3 = - 2uv(xy)$.  Squaring both sides, $$
v^4w^2 + 2u^3v^2w + u^6= 4u^2v^2(x^2y^2) = 4u^2v^2(uw)$$ or \, $(v^2w -
u^3)^2 = 0$.  The  zero locus of the irreducible polynomial
$v^2w-u^3$ is the dual curve. \qed\label{cuspcubic} \end{example}


 \section{Resultants}
\label{resultant}\Marginnote{resultant}[-.6cm]

\ms Let $F$ and $G$ be monic polynomials
with variable coefficients,

\begin{equation}
F(x) = x^m+a_1x^{m-1}+\cdots + a_m \quad \text{and}\quad G(x) = x^n+
 b_1x^{n-1}+\cdots + b_n\Marginnote{polys}\label{polys}
\end{equation}  

\no

The resultant $\,\res(F,G)\,$  of $F$ and $G$ is a polynomial in the
coefficients $a_i,b_j$.  Its important property is that, when the
coefficients of are in a field, the resultant is zero if and
only if $F$ and $G$  have a common factor.


The formula for the resultant is nicest when one allows leading
coefficients different from $1$.  We work with homogeneous polynomials
in two variables to prevent the degree from dropping when a leading
coefficient happens to be zero.

\ms   Let $f$ and $g$ be homogeneous
polynomials with complex coefficients, say
\begin{equation}
f(x,y) = a_0x^m+a_1x^{m-1}y+ \cdots + a_my^m,\quad g(x,y) = b_0x^n
+ b_1x^{n-1}y + \cdots + b_ny^n\Marginnote{hompolys}\label{hompolys}
\end{equation} 

\no If these polynomials have a common zero $(u,v)$ in $\bbp^1$, then
$vx-uy$ will divide both $f$ and $g$ (see \ref{locipone}).  So the
polynomial $h= fg/(vx\!-\!uy)$ of degree $m\!+\!n\!-\!1$ will be
divisible by $f$ and $g$, say $h = pf = qg$, where $p$ and $q$ are
homogeneous polynomials of degrees $n\!-\!1$ and $m\!-\!1$,
respectively.  Then $pf$ will be a linear combination of the
polynomials $x^iy^jf$, with $i\!+\!j=n\!-\!1$, and it will also be a
linear combination $qg$ of the polynomials $x^ky^\ell g$, with
$k\!+\!\ell =m\!-\!1$.  This implies that the $m\!+\!n$ polynomials of
degree $m\!+\!n\!-\!1$,
\begin{equation}
 x^{n-1}f,\;x^{n-2}yf,...,\,y^{n-1}f\;;\;x^{m-1}g,\;x^{m-2}yg,
...,\,y^{m-1}g \Marginnote{mplusnpolys}\label{mplusnpolys}
\end{equation} 

\no
will be dependent.  For example, when $m=3$ and $n=2$, the polynomials

\bs

$ xf =\quad \; a_0x^4+a_1x^3y+a_2x^2y^2+a_3 xy^3 \quad $

$ yf =\quad \;\quad\quad \;\;\;\;a_0x^3y+a_1x^2y^2+a_2 xy^3 + a_3y^4$

$ x^2g =\quad b_0x^4+b_1x^3y+b_2x^2y^2 \quad \quad $

$ xyg =\quad \quad\quad \;\;\;\; b_0x^3y+b_1x^2y^2+b_2 xy^3 \quad $

$ y^2g =\quad \quad \quad\quad\quad\quad \quad \quad bx^2y^2+b_1 xy^3+b_2y^4$

\bsno
will be dependent.   
Conversely, if the
polynomials (\ref{mplusnpolys}) are dependent, there will be an
equation of the form $pf = qg$, with $p$ of degree $n\!-\!1$ and $q$
of degree $m\!-\!1$.  Then at least one zero of $g$ must be a zero of
$f$.

Let $r \!=\!m\!+\!n\!-\!1$.  We form a square matrix $\Cal R$, the
{\it resultant matrix}, whose columns are indexed by the $m\!+\!n$
monomials $x^r,x^{r-1}y,...,y^r$ of degree $r=m\!+\!n\!-\!1$, and
whose rows list the coefficients of those monomials in the polynomials
(\ref{mplusnpolys}).  The matrix is illustrated below for the cases
$m,n=3,2$ and $m,n = 1,2$, with dots representing entries equal to
zero:
\begin{equation}
\Cal R = \begin{pmatrix}
    a_0&a_1&a_2&a_3&\cdot \\ \cdot&a^{}_0&a_1&a_2&a_3
    \\ b_0&b_1&b^{}_2&\cdot&\cdot\\ \cdot&b_0&b^{}_1&b^{}_2&\cdot\\ \cdot&\cdot&
    b^{}_0&^{}b_1&b_2 \end{pmatrix} 
 \quad \text{or} \quad 
 \Cal R = \begin{pmatrix} a_0&a_1&\cdot\\ \cdot& a_0&a_1\\ b_0&b_1
    &b_2 \end{pmatrix}
\Marginnote{resmatrix}
\label{resmatrix}
\end{equation}

\no By definition, the determinant of $\Cal R$ is the the {\it
  resultant} of $f$ and $g$:

\begin{equation}
\,\res(f,g) = \det \Cal R\Marginnote{resequalsdet}
\label{resequalsdet}
\end{equation}
The coefficients of the polynomials can be in any ring.


 The {resultant} $\res(F,G)$ of the 
monic, one-variable polynomials $F(x) =
 x^m\!+\!a_1x^{m-1}\!+\!\cdots \!+\! a_m$ and $G(x) = x^n\!+\!
 b_1x^{n-1}\!+\!\cdots \!+\! b_n$ is the determinant of the matrix
 $\Cal R$, with $a_0 = b_0 =1$.

\begin{corollary}{\text{\bf Corollary.}}\Marginnote{homogresult}\;\,
 Let $f$ and $g$ be homogeneous polynomials in two variables,
or monic polynomials in one variable, with coefficients in a field.
The resultant $\res(f,g)$ is zero if and only if $f$ and $g$ have a
common factor.
\qed
\label{homogresult}\end{corollary}

\begin{boldequation}
\Marginnote{weights}\label{weights}
 \hspace{-10cm} 
\textbf{weighted degree}
\end{boldequation}

\ms When defining the degree of a polynomial, one may assign an
integer called a {\it weight} to each variable.  If one assigns weight
$w_i$ to the variable $x_i$, the monomial $x_1^{e_1}\cdots x_n^{e_n}$
gets a {\it weighted degree}, which is 
$$e_1w_1+\cdots + e_nw_n$$

\no
 For example, it is natural to assign weight $k$ to the coefficient
 $a_k$ of the polynomial $f(x) = x^n-a_1x^{n-1}+a_2x^{n-2} - \cdots
 \pm a_n$.  The reason is that, if $f$ factors into linear factors, $f(x) =
 (x-\alpha_1)\cdots(x-\alpha_n)$, then $a_k$ will be the $k$th elementary
 symmetric function in $\alpha_1,...,\alpha_n$.  When written as a
 polynomial in $\alpha$, the degree of $a_k$ will be $k$.

We leave the proof of the next lemma as an exercise.

\begin{lemma}{\text{\bf Lemma.}}\Marginnote{degresult}\;\,
Let $f(x,y)$ and $g(x,y)$ be homogeneous polynomials of degrees $m$
and $n$ respectively, with variable coefficients $a_i$ and $b_i$, as
in (\ref{hompolys}).  Assigning weight $i$ to $a_i$ and $b_i$, the
resultant $\res(f,g)$ is a weighted homogeneous polynomial of degree
$mn$\, in the variables
$\{a_i,b_j\}$.\qed \label{degresult}\end{lemma}



\begin{proposition}{\text{\bf Proposition.}}\Marginnote{resroots}\;\,
Let $F$ and $G$ be 
products of monic linear polynomials, say $F = \prod_i(x-\alpha_i)$ and
$G = \prod_j(x-\beta_j).$ Then
$$\res(F,G) \quad=\quad \prod_{i,j}(\alpha_i-\beta_j) \quad=\quad
\prod_i G(\alpha_i)$$
\label{resroots}\end{proposition}


\begin{proof} 
The equality of the second and third terms is obtained by
substituting $\alpha_i$ for $x$ into the formula $G = \prod
(x-\beta_j)$.  We prove that the first and second terms are equal.

Let the elements $\alpha_i$ and $\beta_j$ be variables, and let $R$ be
the resultant $\res(F,G)$ and let $\Pi$ be the product
$\prod_{i.j}(\alpha_i-\beta_j)$.  When we write the coefficients of
$F$ and $G$ as symmetric functions in the roots $\alpha_i$ and
$\beta_j$, $R$ will be homogeneous.  Its (unweighted) degree in
$\alpha_i,\beta_j$ will be $mn$, the same as the degree of $\Pi$
(Lemma \ref{degresult}). To show that $R = \Pi$, we choose $i,j$ and
divide $R$ by the polynomial $\alpha_i-\beta_j$, considered as a monic
polynomial in $\alpha_i$:
$$R = (\alpha_i-\beta_j)q + r,$$ where $r$ has degree zero in
$\alpha_i$.  The resultant $R$ vanishes when we substitute $\alpha_i =
\beta_j$.  Looking at the displayed equation, we see that the
remainder $r$ also vanishes when $\alpha_i = \beta_j$.  On the other
hand, the remainder is independent of $\alpha_i$.   It doesn't change
when we set $\alpha_i = \beta_j$.  Therefore the remainder is zero, and
this is true for all $i$ and $j$.  So $R$ is divisible by $\Pi$, and
since these two polynomials have the same degree, $R = c\Pi$ for some
scalar $c$.  To show that $c=1$, one computes $R$ and $\Pi$ for some
particular polynomials.  We suggest using $F = x^m$ and $\,G = x^n-1$.
\qed\end{proof}

\begin{corollary}{\text{\bf Corollary.}}
\MMM{restrivialities}\label{restrivialities} Let $F,G,H$ be monic
polynomials and let $c$ be a scalar.  Then

  \no {\bf (i)} \; $\res(F,GH) = \res(F,G)\res(F,H)$, \; and 

\no {\bf (ii)} \; $\,\res(F(x\!-\!c),G(x\!-\!c)) =
\res(F(x),G(x))$.
\qed\end{corollary}

\begin{proposition}{\bf Proposition.}
\Marginnote{leadcoeffnotzero}\label{leadcoeffnotzero} Let $f$ and $g$
be homogeneous polynomials (\ref{hompolys}) in $x,y$, with complex
coefficients.  Then $\res(f,g) =0$ if and only if $f$ and $g$
have a common zero.  \qed
\end{proposition}

\no When both $a_0$ and $b_0$ are zero, the point $(1,0)$ of $\bbp^1$
will be a zero of $f$ and of $g$.  In this case, $f$ and $g$ have a
common zero at infinity.

\begin{boldequation}\Marginnote{discrimsect} 
\hspace{-10cm} \textbf{the discriminant} 
\label{discrimsect}\end{boldequation}

 The {\it discriminant} $\discr(F)$ of a
polynomial $F = a_0x^m+a_1x^{n-1} + \cdots a_m $ is the resultant
of $F$ and its derivative $F'$:

\begin{equation}\label{discrdef}
\discr(F) =\res(F,F')\Marginnote{discrdef}
\end{equation} 
The computation of the discriminant is made using the formula for the resultant of a
polynomial $F$ of degree $m$.  The definition makes sense when
the leading coefficient $a_0$ is zero, though the discriminant is zero in
that case.

\ms
 When the coefficients of $F$ are complex numbers, the discriminant
 is zero if and only if either $F$ has a double root,
 which happens when $F$ and $F'$ have a common factor, or else $F$ has
 degree less than $m$ (see (\ref{leadcoeffnotzero})).

\ms
The discriminant of the quadratic polynomial
$\;F(x)=ax^2+bx+c\;$ is
\begin{equation}
\det  \begin{pmatrix} a & b & c\\ 2a & b & \cdot\\
\cdot & 2a & b\end{pmatrix} \; = \;
 -a(b^2-4ac). 
\Marginnote{discrquadr} \label{discrquadr}
\end{equation}


\begin{proposition}{\text{\bf Proposition.}}\Marginnote{discrnotzero}\;\,
Let $K$ be a field of characteristic zero.  The discriminant
$\discr(F)$ of an irreducible polynomial $F$ with
coefficients in $K$ isn't zero.  Therefore an irreducible polynomial
$F(x)$ with coefficients in $K$ has no multiple root.
\label{discrnotzero}\end{proposition}

\begin{proof} When  $F$ is
irreducible, it cannot have a factor in common with the lower degree
polynomial $F'$.  
\qed \end{proof}

\msno This proposition is false when the characteristic of $K$ isn't
zero.  In characteristic $p$, the derivative $F'$ might be the zero
polynomial.


\begin{proposition}{\text{\bf Proposition.}}
\Marginnote{discrformulas}\;\,
Let  $F = \prod (x-\alpha_i)$ be a
polynomial that is a product of monic linear factors.  Then
$$\discr(F) = \prod_{i} F'(\alpha_i)= \pm \prod_{i<j}
(\alpha_i-\alpha_j)^2
$$
\label{discrformulas}\end{proposition}

\begin{proof}
The fact that $\discr(F) = \prod F'(\alpha_i)$ follows from
Proposition \ref{resroots}.  So it suffices to show that $F'(\alpha_i)
= \prod_{j, j\neq i}(\alpha_i-\alpha_j)$.
  By the product rule for
differentiation,
$$F'(x) = \sum_j (x-\alpha_1)\cdots \widehat{(x-\alpha_j)} \cdots
(x-\alpha_n)$$ where the hat $\;\widehat{}\;$ indicates that the term
is deleted.  Substituting $x=\alpha_i$, all terms in the sum
except the one with $i=j$ become zero.  \qed\end{proof}


\begin{proposition}{\text{\bf Proposition.}}\Marginnote{discrprop}\;\,
If $F(x)$ and $G(x)$ are monic polynomials, 

$$\discr(FG) = 
\pm \discr(F)\discr(G)\!\res(F,G)^2$$
\label{discrprop}\end{proposition}

\begin{proof} This proposition follows
from Propositions \ref{resroots} and \ref{discrformulas} for
polynomials with complex coefficients.  It is true for
polynomials with coefficients in any ring because it is an
identity. \qed\end{proof}



\begin{boldequation}
\Marginnote{hensel} \hspace{-10cm} 
\textbf{Hensel's Lemma}
	\label{hensel}
\end{boldequation}
 
  The resultant matrix (\ref{resmatrix})  arises in a second
context that we explain here.  
Suppose given a product $P=FG$ of two polynomials, say
\begin{equation}
(c_0x^{m+n}+c_1x^{m+n-1}+\cdots + c_{m\!+\!n}) \;=\;
\big(a_0x^m+a_1x^{m-1}+ \cdots + a_m\big)\big(b_0x^n + b_1x^{n-1} +
\cdots + b_n\big)\Marginnote{multiplypolys}
\label{multiplypolys}
\end{equation} We call the equations
among the coefficients that are implied by this polynomial equation the
{\it product equations}.  The product equations are
$$c_i = a_ib_0+a_{i-1}b_1+\cdots + a_0b_i$$


\no
for $i=0,...,m\!+\!n$.   For instance, when $m=3$ and $n=2$, they
are


\msno
\begin{thm}{} \Marginnote{prodeqns}

$\phantom{xxxxxxxxxxxxxxxxxxxxxxxxxxxx}c_0 = a_0b_0$

$\phantom{xxxxxxxxxxxxxxxxxxxxxxxxxxxx}c_1 = a_1b_0 + a_0b_1$

$\phantom{xxxxxxxxxxxxxxxxxxxxxxxxxxxx}c_2 = a_2b_0+a_1b_1+ a_0b_2$

$\phantom{xxxxxxxxxxxxxxxxxxxxxxxxxxxx}c_3 = a_3b_0+a_2b_1+a_1b_2$

$\phantom{xxxxxxxxxxxxxxxxxxxxxxxxxxxx}c_4 = \phantom{a_3b_0+\;\,}a_3b_1+a_2b_2$

$\phantom{xxxxxxxxxxxxxxxxxxxxxxxxxxxx}c_5 = \phantom{a_3b_0+a_2b_1+\;\,}a_3b_2$
\label{prodeqns}		\end{thm}

\ms


Let $J$ denote the Jacobian matrix of partial derivatives of 
$c_1,...,c_{m+n}$ with respect to the variables
$b_1,...,b_n$ and $a_1,...,a_m$, holding $a_0,b_0$ and $c_0$ constant.  When
$m,n = 3,2$,
\begin{equation}
 {J}=
\frac{\partial(c_{i})}{\partial(b_{j},a_{k})} =
 \begin{pmatrix} a_0 & .  & b_0 & .
& .\\ a_1 & a_0 & b_1 & b_0 & .\\ a_2 & a_1 & b_2 & b_1 & b_0\\ a_3 &
a_2 & .  & b_2 & b_1\\ .  & a_3 & .  & .  & b_2 \end{pmatrix}
\Marginnote{prodjacob}
	\label{prodjacob}
\end{equation}

\begin{lemma}{\bf Lemma.}\MMM{jacres}\label{jacres}
The Jacobian matrix $J$ is the transpose of the resultant matrix
$\Cal R$ (\ref{resmatrix}).\qed\end{lemma}

\begin{corollary}{\text{\bf Corollary.}}\Marginnote{jacobiannotzero}\;\,
Let $F$ and $G$ be polynomials with complex coefficients.  The
Jacobian matrix is singular if and only $F$ and $G$
have a common root, or $a_0=b_0 = 0$.
\label{jacobiannotzero} \end{corollary}

\no
This follows from Corollary \ref{leadcoeffnotzero}.\qed


\bs  Corollary \ref{jacobiannotzero} has an application to polynomials with
analytic coefficients.
 Let
\begin{equation}
 P(t,x) = c_0(t)x^d+ c_1(t)x^{d-1} + \cdots + c_d(t) 
\Marginnote{polyforhensel}
	\label{polyforhensel}
\end{equation}
be a polynomial in $x$ whose coefficients $c_i$ are analytic
functions, defined for small values of $t$, and let $\oP = P(0,x) =
\oc_0x^d + \oc_1x^{d-1} + \cdots + \oc_d$ be the evaluation of $P$ at
$t=0$, so that $\oc_i = c_i(0)$.  Suppose given a factorization $\oP =
\oF \,\oG$, where $\oF = x^m+ \oa_1x^{m-1} +\cdots + \oa_m$ is a monic
polynomial and $\oG = \ob_0x^n + \ob_1x^{n-1} + \cdots + \ob_n$ is
another polynomial, both with complex coefficients.  We ask whether
this factorization of $\oP$ is induced by a factorization of $P$.  Are
there polynomials $F(t,x) = x^m+ a_1x^{m-1} +\cdots + a_m$ and $G(t,x)
= b_0x^n + b_1x^{n-1} + \cdots + b_n$, with $F$ monic, whose
coefficients $a_i$ and $b_i$ are analytic functions defined for small
$t$, such that $P = FG$, $F(0,x) = \oF$, and $G(0,x)= \oG$?


 \begin{lemma}\text{\bf Hensel's Lemma.}\Marginnote{hensellemma}\;\,
With notation as above, suppose that 
 $\oF$ and $\oG$ have no common root.
Then $P$ factors, as above.
\label{hensellemma} \end{lemma}

 \begin{proof} Since $F$ is supposed to be monic, we set $a_0=1$. The first
product equation tells us that $b_0(t)=c_0(t)$.  Corollary
\ref{jacobiannotzero} tells us that the Jacobian matrix for the
remaining product equations is nonsingular at $t=0$, so according to
the Implicit Function Theorem, the product equations have a unique
solution  in analytic functions
$a_i(t),b_j(t)$ for small $t$.\qed\end{proof}

\msno
Note that $P$ isn't assumed to be monic.  If $\oc_0=0$, the degree of
$\oP$ will be less than the degree of $P$.  In that case, $\oG$ will
have lower degree than $G$.

\ms
 \centerline{figure}


\begin{example}{\bf Example.}\MMM{henselex}\label{henselex}
Let $P = c(t)x^2+c_1(t)x+c_2(t)$, and suppose that $\oP = \oc
x^2+\oc_1x+\oc_2$ has a root $\oa$.  Then $\oP$ is a product
$(x-\oa)(\oc x+\ob)$, with $\oc_1 = \ob - \oc\oa$ and $\oc_2=-\oa\ob$.
The Jacobian matrix (\ref{prodjacob}) at $t=0$ is
$$\begin{pmatrix}
\phantom{-}1 & \oc\\
-\oa & \ob
\end{pmatrix}
$$ Its determinant $\od = \ob +\oc\oa$, is nonzero if and only if the
two factors of $\oP$ are relatively prime.

The single variable Jacobian criterion allows us to solve the equation
$P(t,x) =0$ for $x$ as function of $t$, provided that $\frac{\partial
  P}{\partial x}$ isn't zero at $(t,x) = (0,\oa)$.  It won't be
surprising that $\frac{\partial P}{\partial x}(0,\oa) = 2\oc\oa +
\oc_1$ is equal to the Jacobian determinant
$\ob+\oc\oa$.\qed\end{example}







\section{Plane Curves as Coverings of the Projective Line}
\label{coverline}\Marginnote{coverline}[-.6cm]

When $f$ and $g$ are polynomials in several variables, including $z$,
we denote by $\res_z(f,g)$ and $\discr_z(f)$ the resultant and the
discriminant, computed with respect to the variable $z$.  They will be
polynomials in the remaining variables.

\begin{lemma}{\bf Lemma.}\Marginnote{firroverK}\label{firroverK}
Let $f(x,y,z)$ be an irreducible polynomial in $\bbc[x,y,z]$ that
isn't a linear polynomial in $x,y$.  Let $K$ be the rational function
field $\bbc(x,y)$.

\no{\bf (i)}  $f$ is an irreducible element of $K[z]$.

\no {\bf (ii)} The discriminant $\discr_z(f)$ of $f$ with respect to
the variable $z$ is a nonzero polynomial in $x,y$.
\end{lemma}

\begin{proof}
{\bf (i)} First, if $f$ were an irreducible polynomial in $x,y$, it
would have to be linear (\ref{factorhompoly}).  Since that case has been
ruled out, $f$ has positive degree in $z$.  Say that $f(x,y,z)$
factors in $K[z]$, $f = g'h'$, where $g'$ and $h'$ are polynomials of
positive degree in $z$, with coefficients in $K$.  The coefficients of
$g'$ and $h'$ have denominators that are polynomials in $x,y$.  When
we clear those denominators, we obtain an equation in $\bbc[x,y,z]$ of
the form $df=gh$, where $g$ and $h$ are polynomials in $x,y,z$ of
positive degree in $z$ and $d$, a common denominator of the
coefficients of $g'$ and $h'$, is a polynomial in $x,y$.  Since $g$
and $h$ have positive degree in $z$, neither of them divides $d$. Then
$f$ must be reducible.

\msno {\bf (ii)} This follows from {\bf (i)}, together with
Proposition \ref{discrnotzero}.
\qed\end{proof}

\bs Let $\pi$ denote the {\it projection} $\bbp^2 \longrightarrow
\bbp^1$ that drops the last coordinate, sending a point $(x,y,z)$ to
$(x,y)$.  This projection is defined at all points of $\bbp^2$ except
at the point $q= (0,0,1)$, which is called the {\it center
  of projection}.  The fibre of $\pi$ over a point $\tp=(x_0,y_0)$ of
$\bbp^1$ is the line $L_{pq}$ through the points $p=(x_0,y_0,0)$ and
$q=(0,0,1)$, with the point $q$ omitted -- the set of points
$(x_0,y_0,z_0)$.

$$figure$$

Let $C$ be a plane curve defined by an irreducible homogeneous
polynomial $f(x,y,z)$ of degree $d$.
  We write $f$ as a polynomial in $z$:
\begin{equation}
f = a_0z^d+a_1z^{d-1} + \cdots + a_d\Marginnote{polyinztwo}
\label{polyinztwo}
\end{equation} 
with $a_i$ homogeneous, of degree $i$ in $x,y$.
 The 
  fibre of $C$ over a point $\tp = (x_0,y_0)$ of $\bbp^1$ is the
intersection of $C$ with the line $L_{pq}$.  It
consists of the points $(x_0,y_0,\alpha)$ such that $\alpha$ is a root
of the one-variable polynomial
\begin{equation}
f_{\tp}(z) = f(x_0,y_0,z)\,.\Marginnote{effp}	\label{effp}
\end{equation} 

Suppose that $q$ is a point of multiplicity $r$ of $C$, and let $k =
d-r$.  The coefficients $a_0,...,a_{r-1}$ will be zero, and $f$ will have
the form 
$$f = a_rz^k + a_{r+1}z^{k-1}+\cdots +a_d$$ with $k = d-r$ (see
(\ref{singmult})).  The discriminant $\discr_z(f_{\tp})$ of $f_{\tp}$
can be obtained by evaluating the discriminant of $f$ at $\tp$, and
because $\discr_z(f)$ isn't zero, $\discr_z(f_{\tp})$ will be nonzero
for all but finitely many points $\tp$ of $\bbp^1$.  If
$\discr_z(f_{\tp})$ isn't zero, $f_{\tp}$ will have $k$ roots, and if
$\discr_z(f_{\tp})$ is zero, $f_{\tp}$ will have a multiple root.  A
multiple root occurs when $L_{pq}$ is tangent to $C$ at a smooth point
distinct from $q$, or $L_{pq}$ passes through a singular point
distinct from $q$, or $L_{pq}$ is a special line at $q$ (\ref{dpt}).
 Because all but finitely may fibres consist of $k$ points, $C$
is called a $k$-{\it sheeted branched covering} of $\bbp^1$.  The {\it
  branch points} are the points $\tp$ of $\bbp^1$ at which the
discriminant $\discr_z(f)$ is zero -- those such that the fibre over
$\tp$ has fewer than $k$ points.

\ms The most important case is that the plane curve $C :\{f=0\}$ of
degree $\,d\,$ doesn't pass through $q$.  Then the projection $\pi$
will be defined everywhere on $C$, and it will present $C$ as a
$d$-sheeted branched covering of $\bbp^1$.  In this case, we will have
$f(0,0,1) = a_0$, and since $C$ doesn't contain $q$, the coefficient
$a_0$ will be a nonzero constant that we can normalize to $1$, so that
$f$ becomes a monic polynomial of degree $d$ in $z$,


Let's suppose that coordinates are chosen so
that $q = (0,0,1)$ is in general position.

 \begin{note}{\bf Note.}\Marginnote{generic}\label{generic} In
  algebraic geometry, the phrases {\it general position} and {\it
    generic} indicate an object (the point $q$ here) that has no
  special 'bad' properties.  Typically, the object will be
  parametrized somehow, and the word {\it generic} indicates that the
  parameter representing the particular object avoids a proper subset
  that may or may not be described explicitly.  For the Proposition
  \ref{discrimvanishing} below, we require that $q$ shall not lie on
  any of the following lines:

\vspace{-0.5cm}
\label{genericcond}\Marginnote{genericcond}\begin{equation}
\end{equation}
\vspace{-0.8cm}

bitangent lines and  flex tangent lines, 

tangent lines that pass
  through a singular point of $C$, 

lines that contain more than
  one singular point, and 

special lines through singular points (see (\ref{singmult})).
\end{note}

\begin{lemma}{\bf Lemma.}\MMM{finlines}\label{finlines}
 This is a list of finitely many
lines that $q$ must avoid. \end{lemma}

\begin{proof} 
Corollary \ref{finitebitangents} and Proposition \ref{hessnotzero}
tell us that there are finitely many bitangents and finitely many flex
points.  To show that there are finitely many tangent lines through
singular points, we project $C$ from a singular point $p$ and apply
Lemma \ref{firroverK}.  The discriminant isn't identically zero, so it
vanishes finitely often.  Finally, since there are finitely many
singular points, there are finitely many lines through pairs of
singular points and finitely many special lines
(\ref{multr}).\qed\end{proof}

We consider the projection $\bbp^2 \stackrel\pi\longrightarrow \bbp^1$
with center $q$.  Let $\op = (x_0,y_0)$ denote the image in $\bbp^1$
of the point $p= (x_0,y_0,z_0)$ of $\bbp^2$.

\begin{proposition}{\text{\bf Proposition.}}
\Marginnote{discrimvanishing}\label{discrimvanishing} Let $f(x,y,z)$
be a homogeneous polynomial with no multiple factors, let $C$ be the
(possibly reducible) plane projective curve $\{f = 0\}$, and suppose
that  $q$ is in general position. If $p$ is a smooth point of $C$ with
tangent line $L_{pq}$, the discriminant $\discr_z(f)$ has a simple
zero at $\op$.  If $p$ is a node of $C$, $\discr_z(f)$ has a double
zero at $\op$, and if $p$ is a cusp, $\discr_z(f)$ has a triple
zero at $\op$.
\end{proposition}


\begin{proof}
 We
set $x=1$, to work in the standard affine open set $\bbu$ with
coordinates $y,z$.  In affine coordinates, the projection is the map
$(y,z) \ar y$.  We may suppose that $p$ is the origin in $\bbu$.  Its
image $\op$  will be the point $y=0$ of the affine $y$-line, and the line
$L_{pq}$  in $\bbu$ will be the line $\{y=0\}$.

 Let's denote the defining polynomial of the curve $C$, restricted to
 $\bbu$ by $f(y,z)$ instead of $f(1,y,z)$.  In each of the three cases
 under consideration, the polynomial $\of(z) = f(0,z)$ will have a
 double zero at $z=0$.  We will have $\of(z) = z^2\oh(z)$, with
 $\oh(0) \neq 0$.  Since $z^2$ and $\oh(z)$ have no common root, we may
 apply Hensel's Lemma to write $f(y,z) = g(y,z)h(y,z)$, where $g$ and
 $h$ are polynomials in $z$ whose coefficients are analytic functions
 of $y$, defined for small $y$,  $g$ is monic, $g(0,z) = z^2$,
 and $h(0,z) = \oh$.  According to Proposition
 \ref{discrprop}, $$\discr_z(f) =
 \pm\discr_z(g)\discr_z(h)\res_z(g,h)^2$$ Since $q$ is in
 general position, $\oh$ will have simple zeros.  Then $\discr_z(h)$
 doesn't vanish at $y=0$.  Neither does $\res_z(g,h)$.  So the
 orders of vanishing of $\discr_z(f)$ and $\discr_z(g)$ are equal.  We
 replace $f$ by $g$, and doing so reduces us to the case that $f$ is a
 monic quadratic polynomial in $z$ with $f(0,z)=z^2$, say
$$f(y,z) = z^2+b(y)z+c(y)$$ whose coefficients $b$ and $c$ are
analytic functions of $y$.  We write these coefficients as series in
$y$:
$$b(y) = b_0+b_1y+ b_2y^2+\cdots\quad\;\text{and}\quad\; c(y) = c_0+c_1y+
c_2y^2+c_3y^3 +\cdots$$

\no
Since $f(0,z)=z^2$, the constant terms $b_0$ and $c_0$ are zero, and 
$$\discr_z(f) = -(b(y)^2-4c(y)) = 4c_1y + (4c_2-b_1^2)y^2 +
(4c_3-2b_1b_2)y^3 + O(4)$$

\no If $C$ is smooth at $p$, then $c_1 \neq 0$.  If so, then
$\discr_z(f) = 4 c_1y + O(2)$ has a zero of order one.  If $p$ is a
node, then $c_1=0$ and $4c_2-b_1^2 \neq 0$, so the discriminant has a
zero or order two.  If $p$ is a cusp, the discriminant of $f$ is
$(4c_3-2b_1b_2)y^3+ O(4)$, and $(2z+b_1y)^2 = 4(z^2+b_1yz+c_2y^2)$
(see \ref{discrzero}).  We substitute $z = -\frac {b_1}2 y$ into the
cubic term $f_3=b_2y^2z+c_3y^3$ of $f$, obtaining $\frac 1 2 (-b_1b_2
+ c_3)y^3$.  Since $p$ is a cusp, $2z+b_1y$ doesn't divide $f_3$, so
the result isn't zero.  The discriminant has a zero of order
$3$.\qed\end{proof}

\begin{corollary}{\bf Corollary.}\Marginnote{transres}\label{transres}
With notation as in Proposition \ref{discrimvanishing}, let $C:
\{f=0\}$ and $D:\{g=0\}$ be plane curves that intersect transversally
at a point $p = (x_0,y_0,z_0)$.  Then $\res_z(f,g)$ has a simple zero
at $(x_0,y_0)$. \end{corollary}

\no
Two curves are said to intersect {\it transversally} at a point $p$ if
they are smooth at $p$ and if their tangent lines there are distinct.


\begin{proof} 
Proposition \ref{discrimvanishing} applies to the product $fg$, whose
divisor is $C\cup D$.  It shows that the discriminant $\discr_z(fg)$
has a double zero at $\tp$.  We also know that $\discr_z(fg) = \pm
\discr_z(f)\discr_z(g)\res_z(f,g)^2$ (\ref{discrprop}).  Because
coordinates are in general position, $\discr_z(f)$ and $\discr_z(g)$
will not be zero at $\tp$.  Therefore $\res_z(f,g)$ has a simple zero
there.\qed\end{proof}

 
\section{Genus}
\label{genus}\Marginnote{genus}[-.6cm] 

\msno In this section, we describe the topological structure of smooth
plane curves. We defer the proof of one statement.


\begin{theorem}{\text{\bf Theorem.}}
\Marginnote{curveshomeomorphic}\;\,
The smooth plane
curves of degree $d$ in $\bbp^2$ are homeomorphic manifolds of
dimension two.  They are orientable,  and connected.
\label{curveshomeomorphic}\end{theorem}

\msno Unfortunately, the connectedness of a plane curve is a subtle
fact whose proof mixes topology and algebra.  I don't know a proof
that fits into our discussion here.  It will be proved later (see Theorem
\ref{curveconn}).

If one wants to have a proof now, one can begin by showing that the
Fermat curve $x^d+y^d+z^d=0$ is connected, by studying the projection
to $\bbp^1$ from the point $(0,0,1)$.  I propose this as an exercise.
Then one can show that every plane curve is connected by proving a
plausible fact: If a family $C_t$ of smooth plane projective curves of
degree $d$ is parametrized by $t$ in an interval of the real line, the
curves in the family are homeomorphic.  One can prove this using a
{\it gradient flow}.  This approach has two drawbacks: It
leads us far afield, and it applies only to plane curves.  If you are
interested in following it up, read about gradient flows.

\msno {\it orientability}: A two-dimensional manifold is orientable if
one can choose one of its two sides in a continuous, consistent way.
A smooth curve $C$ is orientable because its tangent space at a point
is a one-dimensional complex vector space, the affine line with the
equation (\ref{texp}).  Multiplication by $i$ orients the tangent
space by defining the counterclockwise rotation.  Then the right-hand
rule tells us which side of $C$ is ``up''.
 
\msno {\it compactness}: A plane projective curve is  compact because
it is a  closed subset of the compact space $\bbp^2$.

\ms The {\it Euler characteristic} $\,e\,$ of a   compact, connected,
orientable two-dimensional manifold $M$ is the alternating sum
$b^0-b^1+b^2$ of its Betti numbers.  It depends
only on the topological structure of $M$, and it can be computed in terms of
a {\it triangulation}, a subdivision of $M$ into topological
triangles, called {\it faces}, by the formula
\begin{equation}
 e \;=\;|{\text{vertices}}| - |{\text{edges}}| + |{\text{faces}}|
 \Marginnote{vef}
 	\label{vef}
\end{equation}

\no
For example, a tetrahedron is homeomorphic to a sphere.
It  has four vertices, six edges, and four
faces, so its Euler characteristic is $4-6+4 = 2$.
Any other topological triangulation of a sphere, such as
the one given by the icosahedron, yields the same Euler
characteristic.

\ms Every  compact, {connected}, orientable two-dimensional
manifold is homeomorphic to a sphere with a finite number of
``handles'', and its {\it genus} is the number of handles.  
A torus has one handle. Its  genus is one.  The
projective line $\bbp^1$, a sphere, has genus zero.  

$$Figure$$

The Euler
characteristic and the genus are related by the formula
\begin{equation}
e = 2-2g \Marginnote{genuseuler}
	\label{genuseuler}
\end{equation}
 The Euler characteristic of a torus is zero, and the Euler
 characteristic of $\bbp^1$ is two.

\ms To compute the the Euler characteristic  of a smooth curve $C$
of degree $d$, we analyze a generic projection $C
\stackrel{\pi}\longrightarrow \bbp^1$.

\bs
\centerline{\it figure}
\bs

\ms We choose generic coordinates $x,y,z$ in  $\bbp^2$ and
project form the point $q = (0,0,1)$.  When the defining
equation of $C$ is written as a monic polynomial in $z$, 
$$f = z^{d}+a_1z^{d-1} + \cdots + a_d$$ where $a_i$ is a
homogeneous polynomial of degree $i$ in the variables $x,y$, the
discriminant $\discr_z(f)$ with respect to $z$ will be a homogeneous
polynomial of degree $d^2-d$ in $x,y$.


The covering $C \stackrel\pi\longrightarrow \bbp^1$ will be branched
at a point $p$ of $C$ if the tangent line at $p$ is the line $L_{pq}$
through $p$ and $q$ (\ref{coverline}).  If so, $C$ and $L_{pq}$
will have $d-1$ intersections (\ref{genericcond}).  Proposition
\ref{discrimvanishing} tells us that the discriminant $\discr_z(f)$
has a simple zero at the image of a tangent line.  So there will be
$d^2-d$ points $\tp$ in $\bbp^1$ over which the fibre of the map has
order $d-1$.  They are the branch points of the covering.  All other
fibres consist of $d$ points.



We triangulate $\bbp^1$ in such a way that the branch points are among
the vertices, and we use the inverse images of the vertices, edges,
and faces to triangulate $C$.  Then $C$ will have $d$ faces and $d$
edges lying over each face and edge of $\bbp^1$, respectively.  And
there will be $d$ vertices of $C$ lying over a vertex $\tp$ of
$\bbp^1$ except when $\tp$ is one of the $d^2-d$ branch points. In
that case the the fibre will contain only $d-1$ vertices.  Therefore
the Euler characteristic of $C$ is
$$e(C) = d\,e(\bbp^1) - (d^2-d) = 2d - (d^2-d)= 3d-d^2.$$ 
This is the Euler
characteristic of any smooth curve of degree $d$, so we denote
it by $e_d$:
\begin{equation}
 e_d = 3d-d^2.  \Marginnote{equatione}	
 \label{equatione}\end{equation}
Formula (\ref{genuseuler}) shows that the genus $g_d$ of a smooth curve of degree $d$ is
\begin{equation}
g_d \;=\; \textstyle{\frac 1 2}(d-1)(d-2) =
\textstyle\binom{d-1}2.\Marginnote{equationg}
	\label{equationg}
\end{equation}
Thus smooth curves of degrees $1,2,3,4,5,6,...$ have genus
$0,0,1,3,6,10,...$, respectively.  A smooth plane curve cannot have
genus $2$.


 \section{B\'ezout's Theorem} \label{bezoutthm} 
\Marginnote{bezoutthm}[-.6cm]


\ms B\'ezout's Theorem counts intersections of plane curves.  We state
it here in a form that is ambiguous because it contains a term
``multiplicity'' that hasn't yet been defined.



 \begin{thm} {\bf B\'ezout's Theorem.}\Marginnote{bezoutone}\;\,
Let $C$ and $D$ be distinct curves of degrees $m$ and $n$,
respectively.  When intersections are counted with the appropriate
multiplicity, the number of intersections is eual to  $mn$.  Moreover,
the multiplicity at a point is $1$ if $C$ and $D$ intersect
transversally at that point.
\label{bezoutone}		\end{thm}


\no
As before, $C$ and $D$ intersect {transversally} at $p$ if they are
smooth at $p$ and their tangent lines there are distinct.


\begin{corollary}{\bf Corollary.} \Marginnote{bezoutline}
B\'ezout's Theorem is true when  one of the curves is a line.
\label{bezoutline} \end{corollary}

\no See Corollary \ref{XcapL}.  The multiplicity of intersection of a
curve and a line is the one that was  defined there.  \qed

\ms The proof in the general case requires some algebra that we would
rather defer.  It will be given later (Theorem \ref{bezoutrestated}).
It is possible to determine the intersections by counting the zeros of
the resultant with respect to one of the variables.  To do this, one
chooses coordinates $x,y,z$ so that neither $C$ nor $D$ contains the
point $(0,0,1)$, and one writes their defining polynomials $f$ and $g$
as polynomials in $z$ with coefficients in $\bbc[x,y]$.  The resultant
with respect to $z$ will be a homogeneous polynomial $R$ in $x,y$, of
degree $mn$.  It will have $mn$ zeros in $\bbp^1_{x,y}$, when
counted with multiplicity.  If $\tp=(x_0,y_0)$ is a zero of $R$, the
one-variable polynomials $f(x_0,y_0,z)$ and $g(x_0,y_0,z)$ have a
common root $z=z_0$, and then $p=(x_0,y_0,z_0)$ will be a point of $C
\cap D$. It is a fact that the multiplicity of the zero of the
resultant $R$ at the image $\tp$ is the (as yet undefined)
intersection multiplicity of $C$ and $D$ at $p$.  Unfortunately, this
won't be obvious.  However, one can prove the next proposition using this
approach.


\begin{proposition}{\text{\bf Proposition.}}
\Marginnote{nocommonfactor}\;\, Let $C$ and $D$ be distinct plane
curves of degrees $m$ and $n$, respectively.

\no {\bf (i)} The curves have at least one point of intersection, and
the number of intersections is at most $mn$.

\no
{\bf (ii)}  If all intersections are transversal, the number
of intersections is precisely $mn$.
\label{nocommonfactor}\end{proposition}

\msno It isn't obvious that two curves in the projective plane must
intersect.  If two curves in the affine plane, such as parallel lines,
have no intersection, their closures in the projective
plane meet on the line at infinity.


\begin{lemma}{\text{\bf Lemma.}}\Marginnote{resnotzero}\;\,
Let $f$ and $g$ be homogeneous polynomials in $x,y,z$ of degrees $m$
and $n$, repsectively, and suppose that the point $(0,0,1)$ isn't a
zero of $f$ or $g$.  If the resultant $\res_z(f,g)$ with respect
to $z$ is identically zero, then $f$ and $g$ have a common factor.
\label{resnotzero} \end{lemma}

\begin{proof} Let  the degrees of $f$ and $g$ be $m$ and $n$,
respectively, and let $K$ denote the field of rational functions
$\bbc(x,y)$.  If the resultant is zero, $f$ and $g$ have a
common factor in $K[z]$ (Corollary \ref{homogresult}).  There will be
polynomials $p$ and $q$ in $K[z]$, of degrees at most $n\!-\!1$ and
$m\!-\!1$ in $z$, respectively, such that $pf = qg$ (see
(\ref{hompolys})).  We may clear denominators, so we may assume that
the coefficients of $p$ and $q$ are in $\bbc[x,y]$.  Then $pf=qg$ is
an equation in $\bbc[x,y,z]$.  Since $p$ has degree at most $n\!-\!1$
in $z$, it isn't divisible by $g$, which has degree $n$
(\ref{polyinztwo}).  Since $\bbc[x,y,z]$ is a unique factorization
domain, $f$ and $g$ have a common factor.  \qed\end{proof}


\msno {\it proof of Proposition} \ref{nocommonfactor}.\; {\bf (i)} Let
$f$ and $g$ be irreducible polynomials whose zero sets are $C$ and
$D$, respectively.  Proposition \ref{fgzerofinite} shows that there
are finitely many intersections.  We project to $\bbp^1$ from a point
$q$ that doesn't lie on any of the finitely many lines through pairs
of intersection points.  Then a line through $q$ passes through at
most one intersection, and the zeros of the resultant $\res_z(f,g)$
that correspond to the intersection points will be distinct.  Since
the resultant has degree $mn$ (Lemma \ref{degresult}), there are at
most $mn$ zeros and there is at least one of them.  Therefore there
are at most $mn$ intersections and there is at least one.

\msno {\bf (ii)} Every zero of the resultant will be the image of an
intersection of $C$ and $D$.  To show that there are $mn$
intersections if all intersections are transversal, it suffices to
show that the resultant has simple zeros.  This is Corollary
\ref{transres}.\qed



\begin{corollary}{\text{\bf Corollary.}}\Marginnote{smoothirred}\;\,

\no {\bf (i)} If the divisor $X$ defined by a homogeneous polynomial
$f(x,y,z)$ is smooth, then $f$ is irreducible, and therefore $X$ is a
smooth  curve.

\noindent
{\bf (ii)} There exist irreducible
homogeneous polynomials in three variables, of arbitrary degree.
\label{smoothirred} \end{corollary}
 

\begin{proof} {\bf (i)} Suppose that $f= gh$, and let $p$ be a point of
intersection of the loci $\{g=0\}$ and $\{h=0\}$.  The previous
proposition shows that such a point exists.  The partial derivatives
$f_i$ vanish at $p$, so $p$ is a singular point of $X$.

\msno {\bf (ii)} The Fermat polynomial $x^d+y^d+z^d$ is irreducible
because its locus of zeros is smooth.  \qed\end{proof}

\begin{corollary}{\text{\bf Corollary.}}\Marginnote{numberofflexes}\;\,
{\bf (i)} Let $d$ be an integer $\geq 3$.  A smooth 
plane curve of degree $d$ has at least one flex point, and the
number of flex points is at most $3d(d\!-\! 2)$.

\no {\bf (ii)} If all flex points are ordinary, the number of flex
points is equal to $3d(d\!-\! 2)$.
\label{numberofflexes} \end{corollary}

\no
 Thus  smooth curves of degrees
$2,3,4,5,...$ have at most $0,9,24,45,...$ flex points, respectively.

\begin{proof} {\bf (i)} Let $C: \{f(x_0,x_1,x_2)=0\}$ be a
smooth curve of degree $d$.  The entries of the $3\times 3$ Hessian
matrix $H$ are the second partial derivatives $\frac
{\partial^2f}{\partial x_i\partial x_j}$.  They are homogeneous
polynomials of degree $d\!-\! 2$, so the Hessian determinant is
homogeneous, of degree $3(d\!-\! 2)$.  The flex points are
intersections of a curve $C$ with its {\it Hessian divisor} $D:\{\det
H=0\}$.  Propositions \ref{hessnotzero} and \ref{nocommonfactor} tell
us that there are at most $3d(d\!-\! 2)$ intersections.

\msno {\bf (ii)} Recall that a flex point is ordinary if the
multiplicity of intersection of the curve and its tangent line is $3$.
B\'ezout's Theorem asserts that the number of flex points is equal to
$3d(d\!-\! 2)$ if the intersections of $C$ with its Hessian divisor
$D$ are transversal, and therefore have multiplicity $1$.  So the next
lemma completes the proof.\end{proof}

\begin{lemma}{\text{\bf Lemma.}}\Marginnote{transversalH}\;\,
A curve $C: \{f=0\}$ intersects its Hessian divisor $D$ transversally
at a point $p$ if and only $p$ is an ordinary flex point of $C$.
\label{transversalH} \end{lemma}


 \begin{proof} 
We prove this by a computation.  Let $L$ be the tangent line to $C$ at
the flex point $p$.  The Hessian divisor $D$ will be transversal to
$C$ at $p$ if and only if it is transversal to $L$, and this will be
true if and only if the order of vanishing of the Hessian determinant,
restricted to $L$, is $1$.  Let's denote the restriction of the
Hessian determinant to $L$ by $h$.

We adjust coordinates $x,y,z$ so that the flex point is 
$p=(0,0,1)$ and the tangent line $L$ at $p$ is the line $\{y=0\}$.
We write the polynomial $f$ of degree $d$ as 
\begin{equation}
f(x,y,z) = \sum_{i+j+k=d}a_{ij}x^iy^jz^k ,\Marginnote{fwithcoeffs}
\label{fwithcoeffs}
\end{equation}
The restriction of $f$ to $L$ is the polynomial 
$$f(x,0,z) = \sum_i a_{i0}x^iz^k$$ Since $p$ is a flex point with
tangent line $L$, the coefficients $a_{00}, a_{10}$, and $a_{20}$ are
zero, and $p$ is an ordinary flex point if and only if the coefficient
$a_{30}$ is nonzero.  The first few terms of $f$ are:

$$f = a_{01}yz^{d-1}+a_{11}xyz^{d-2} + a_{02}y^2z^{d-2} + a_{30}x^3z^{d-3} + \cdots$$

The restriction to $L$ of the Hessian determinant, which we denote by
$h$, is obtained by substituting $y=0$ and $z=1$ into $\,\det H$.  We
are interested in the linear term of $h(x)$, for which the relevant
entries of the Hessian matrix $H$ have degree zero in $y$ and one in
$x$.  Then

\ms $\quad f_{xx}{(x,0,1)} =  6 a_{30} x +\cdots$

$\quad f_{xz}{(x,0,1)} =  0 +\cdots$

$\quad f_{yz}{(x,0,1)} = (d\!-\!1)a_{01}+(d\!-\!2)a_{11}x +\cdots$


$\quad f_{zz}{(x,0,1)} =  0 + \cdots$

\msno We won't need to compute $f_{xy}$ or $f_{yy}$.  Setting
$v=6a_{30}x$ and $w = (d\!-\!1)a_{10} + (d\!-\!2)a_{11}x$, the
resultant matrix has the form


\begin{equation} H_p(x,0,1) \; = \; \begin{pmatrix}
v & * & 0\\
* & * & w\\
0 & w & 0
\end{pmatrix}
\; + \; O(2) \end{equation} where $*$ are entries that don't affect
terms of degree $\leq 1$ in the determinant.  The determinant is
$$h = -vw^2 + O(2)= -6(d-1)^2a_{30}a_{01}^2x + O(2)$$ This determinant
has a zero of order $1$ at $x=0$ if and only if $a_{30}$ and $a_{01}$
aren't zero.  Since $C$ is smooth at $p$ and $a_{10}=0$, the
coefficient $a_{01}$ can't be zero.  Thus $C$ and $D$ intersect
transversally, and $C$ and $L$ intersect with multiplicity $3$, if and
only if $a_{30}$ is nonzero -- if and only if $p$ is an ordinary flex.
\qed\end{proof}

\begin{corollary}{\text{\bf Corollary.}}\Marginnote{nineflexes}\;\,
A smooth cubic curve contains exactly $9$ flex points.
\label{nineflexes} \end{corollary}

\begin{proof} Let $f$ be the
irreducible cubic polynomial whose zero locus is a smooth cubic $C$.  The
degree of the Hessian divisor $D$ is also $3$, so B\'ezout predicts at
most $9$ intersections of $D$ with $C$.  To derive the corollary, we
show that $C$ intersects $D$ transversally.  According to Proposition
\ref{transversalH}, a nontransversal intersection would correspond to
a point at which the curve and its tangent line intersect with
multiplicity greater than $3$.  This is impossible when the curve is a
cubic.  \qed\end{proof}


 \section{The Pl\"ucker Formulas}
\Marginnote{plucker}\label{plucker}

Let $C$ be a smooth plane curve.  As before (\ref{singdual}), a
bitangent $L$ is {\it ordinary} if both of its tangencies are ordinary
and if $L$ isn't tangent to $C$ at a third point.  A flex point $p$ is
{\it ordinary} if $C$ and its tangent line $L$ have a contact of order
precisely $3$ at $p$.  A plane curve $C$ is {\it ordinary} if it is
smooth, and if all of its bitangents and flex points are ordinary.
The {\it{Pl\"ucker
    formulas}} compute the number of flexes and bitangents of an
ordinary plane curve.

For the next proposition, we refer back to the notation of Section
\ref{coverline}.  Let $\pi: C \ar X$ be the projection of a plane
curve $C$ to the projective line $X$ from a generic point $q$.  The
covering $C$ will be branched at the points $\tp =
(x_0,y_0)$ of $X$ such that, with $p=(x_0,y_0,0)$, the line
$L_{pq}$ is a tangent line to $C$.  It will also be branched at the
images of singular points of $C$.

\begin{proposition}{\text{\bf Proposition.}} \Marginnote{classofcurve}
\label{classofcurve}  
Let $C$ be a plane curve, projected to $\bbp^1$ from a generic
point $q$ of the plane.   With notation as above:

\no {\bf (i)} The number $\beta$ of points $\tp$ such that line
$L_{pq}$ is tangent to $C$ at a smooth point is equal
to the degree of the dual curve $C^*$.


\no {\bf (ii)} If $C$ is a smooth curve of degree
$d$, the degree $d^*$ of the dual curve $C^*$ is $d^2-d$.
\end{proposition}

\begin{proof}  
{\bf (i)} The degree of the dual curve $C^*$ is the number of its
intersections with a line in the dual plane.  We count 
intersections with the line $q^*$.

Let $L$ be a line in $\bbp^2$ such
that $L^*$ is a point of $q^*\cap C^*$.  Then $L$ contains $q$, but
since $q$ is generic, Lemma \ref{finlines} shows that 
$L$ doesn't pass through a singular
point, and it isn't  a bitangent  or a  flex
tangent  (\ref{finlines}).  So  all points  $L^*$ of  $q^*\cap C^*$
are dual to ordinary tangent lines $L$ at smooth points of $C$.
Proposition \ref{dualcusp} tells us $C^*$ is
smooth at the point $L^*$, and that the tangent line to $C^*$ at $L^*$
is $p^*$.   Since $q^*\neq p^*$, $C^*$  intersects $q^*$ transversally
at $L^*$.   So the  degree of  $C^*$ is  equal to  the number  of 
intersections, which is $\beta$.

\msno {\bf (ii)} When we project a smooth curve $C$ from $q$, all
branch points are images of tangent lines.  The discriminant of the
defining polynomial $f$ with respect to the chosen variable $z$ will
have degree $d^2-d$ (see Section \ref{coverline}).  There will be
$d^2-d$ ordinary tangent lines through $q$, so $d^* =
d^2-d$. \qed\end{proof}


\bsno
{\bf Pl\"ucker Formulas. } Let $C$ be
an ordinary  curve of degree $d \geq 2$, and let $C^*$ be its dual curve.  Let
$f$ and $b$ denote the numbers of flex points and bitangents of $C$,
and let $\delta^*$ and $\kappa^*$ denote the numbers of nodes and
cusps of $C^*$, respectively.

\msno {\bf (i)} The dual curve $C^*$ has no flexes or bitangents.  Its
singularities are nodes and cusps.

\msno {\bf (ii)} $f = \kappa^* = 3d(d-2)$,\; and 
\; $b = \delta^* =  \textstyle{\frac 1 2}d(d-2)(d^2-9)$.
\label{plform}


\begin{proof}  {\bf (i)} 
A bitangent or a flex on $C^*$  would produce a
singularity on the bidual $C^{**}$, which is the smooth curve $C$.

\msno {\bf (ii)} B\'ezout's Theorem
counts the flex points (see (\ref{numberofflexes})).
The facts that $\kappa^*=f$ and $\delta^*=b$ are
dealt with in Proposition \ref{dualcusp}.    Thus $\kappa^* = f=
3d(d-2)$.

We project $C^*$ to $\bbp^1$ from a generic point $Q$.  Let $\beta^*$
be the number of branch points that correspond to tangent lines
through $Q$ at smooth points of $C^*$.  Since $C^{**}=C$, Proposition
\ref{classofcurve} tells us that $\beta^* = d$ and $d^* = d^2-d$.

Next, let $F$ be the defining polynomial for $C^*$.   The discriminant
$\discr_z(F)$ has degree
$d^{*2}-d^*$.  Proposition \ref{discrimvanishing} describes the order
of vanishing of the discriminant at the images of the tangent lines,
the nodes, and the cusps of $C^*$.  It tells us that
$$d^{*2}- d^* = \beta^* + 2\delta^* + 3\kappa^*$$  We substitute 
the known values of $d^*, \beta^*,\kappa^*$ into this formula:
$$(d^2-d)(d^2-d-1) = d +2\delta^* +9d(d-2)$$
This gives the formula for $\delta^*$:
$$2\delta^* = d^4 - 2d^3 -9d^2+18d = (d^2-2d)(d^2-9)$$
\qed\end{proof}

\no
{\bf Note.}  It isn't easy to count the number of bitangents directly.



\begin{examples}{\bf Examples.}\Marginnote{somepluckerformulas}\;\,

\no
{\bf (i)} All
curves of degree $2$ and all smooth curves of degree $3$ are ordinary.

\no
{\bf (ii)} A curve of degree $2$ has no flexes and
no bitangents. Its dual curve has degree $2$.

\no {\bf (iii)} A smooth curve of degree $3$ has $9$ flexes and no
bitangents.  Its dual curve has degree $6$.

\no
{\bf (iv)} An ordinary curve $C$ of degree $4$ has $24$ flexes and $28$
bitangents.  Its dual curve has degree $12$. \qed
\label{somepluckerformulas} \end{examples}

\newpage
\msno 
It is a famous fact that a quartic  curve as $28$
bitangents.  We will make use of this  in Chapter \ref{twentyseven}.
Aside from the case of a quartic, the complicated formula for the
number of bitangents is rarely used, though it could be useful to know
that a formula exists.

%\end{document}

\bs
\centerline{figure}

%\begin{center}
%\includegraphics[height=5cm]{cusp.pdf}
%\end{center}
%
%\begin{center}
%\includegraphics[height=5cm]{node.pdf}
%\end{center}

\end{document}

\newpage

\no
INDEX

\ms

\no
affine line  \ref{polyirred}

\no
affine plane \ref{affineplane}

\no
affine plane curve \ref{affineplane}

\no
affine space \ref{affineplane}

\no
algebraically dependent, independent  \ref{transcdeg}

\no
B\'ezout's Theorem \ref{bezoutone}

\no
bidual \ref{bidualone}

\no
bitangent \ref{singdual}

\no
branch point \ref{effp}

\no
branched covering \ref{effp}

\no
center of projection \ref{firroverK}

\no
classical topology \ref{zartop}

\no
closure of a set  \ref{opendense}

\no
commutative ring \ref{transcdeg}

\no
conic \ref{projconics}

\no
connected \ref{curveshomeomorphic}

\no
coordinates in the affine plane \ref{planecoords}

\no
coordinates in the projective plane \ref{chgcoordssec}

\no
counting constants  \ref{polyirred}

\no
cubic curve \ref{nineflexes}

\no
cusp \ref{nodes}, \ref{discrzero}


\no
cuspidal cubic \ref{cuspcubic}

\no
degree of a homogeneous polynomial  \ref{projconics}

\no
degree of a plane curve \ref{lociptwo}

\no
degree of an affine plane curve \ref{affineplane}

\no
dense subset  \ref{opendense}

\no
Desargues  \ref{realprojplane}

\no
discriminant \ref{discrimsect}

\no
divisor \ref{factorf}

\no
domain \ref{transcdeg}

\no
dual curve \ref{dualcurvetwo}

\no
dual plane \ref{dualplanesect}

\no
D\"urer  \ref{realprojplane}

\no
Euler characteristic \ref{vef}

\no
faces \ref{curveshomeomorphic}

\no
Fermat curve \ref{fermatcurve}

\no
Fermat polynomial \ref{smoothirred}

\no
fibre of a map \ref{polyirred}

\no
flex point \ref{tangent}

\no
general position \ref{generic}

\no
generic \ref{generic}

\no
genus \ref{genus}

\no
Hensel's Lemma \ref{hensel}

\no
Hessian determinant \ref{hessnotzero}

\no
Hessian divisor  \ref{numberofflexes}

\no
Hessian matrix \ref{eqtanline}

\no
homogeneous parts of a polynomial \ref{projcurve}

\no
homogeneous polynomial \ref{projconics}

\no
homogenizing and dehomogenizing \ref{homdehomone}

\no
Implicit Function Theorem \ref{ifthm}

\no
intersection multiplicity \ref{intersectlinetwo}

\no
irreducible polynomial \ref{polyirred}

\no
irreducible polynomial \ref{smoothirred}

\no
isolated point \ref{isopts}

\no
line in the projective plane \ref{projpl}

\no
loci in the projective line \ref{locipone}

\no
M\"obius \ref{realprojplane}

\no
multiplicity of a zero \ref{factorpolytwo}

\no
node \ref{nodes}, \ref{smsingpots}


\no
nonsingular curve \ref{smsingpots}

\no
ordinary bitangent \ref{singdual}, \ref{plucker}


\no
ordinary curve \ref{plucker}

\no
ordinary flex point \ref{singdual}, \ref{plucker}

\no
ordinary tangent \ref{singdual}, \ref{plucker}


\no
orientable \ref{curveshomeomorphic}

\no
picture plane \ref{realprojplane}

\no
Pl\"ucker Formulas \ref{plucker}

\no
point of projective space \ref{projplane}

\no
product equations \ref{prodeqns}

\no
projection to the line \ref{firroverK}

\no
projective line \ref{pline}

\no
projective plane curve \ref{lociptwo}

\no
projective space 
quartic curve \ref{somepluckerformulas}

\no
real projective plane \ref{realprojplane}

\no
reducible curve \ref{idealprincipal}

\no
resultant  \ref{resultant}

\no
resultant \ref{resequalsdet}

\no
resultant matrix \ref{mplusnpolys}

\no
ring \ref{transcdeg}

\no
singular point \ref{smsingpts}

\no
smooth curve \ref{smsingpts}

\no
smooth point \ref{smsingpts}

\no
standard affine cover (of projective space) \ref{standcov}

\no
tacnode \ref{smsingpts}

\no
tangent line  \ref{tanlines}, \ref{tangent}

\no
Taylor's expansion on a line \ref{taylor}

\no
topology:  coarser and finer \ref{opendense}

\no
transcendence degree \ref{transcdeg}

\no
transcendental  \ref{transcdeg}

\no
transversal intersection \ref{transres}

\no
triangulation \ref{curveshomeomorphic}

\no
weighted degree \ref{weights}

\no
Zariski closed set \ref{defzartop}

\no
Zariski topology  \ref{zartop}

\no
zeros \ref{factorpolytwo}


%\end{document}
\newpage
\section{\bf EXERCISES}

\bs Poncelet

\bs
frac lin transformations

\bs
plane curvve contains three non colinear points.

\bs
\begin{thm}Chapter 1 Exercises
\end{thm}
\Marginnote{exerchapone}\label{exerchapone}

\bs
degree $>2$ implies $C^*$ singular.
\bs
counting constants for Chapter 4
\bs


solve in series

\bs

 Suppose that $a_0$ and $b_0$ are not zero, and let
$\alpha_i$ and $\beta_j$ be the roots of $f(x,1)$ and $g(x,1)$,
respectively.  Then
$\res(f,g) = a_0^nb_0^m \prod(\alpha_i-\beta_j).$

\bs

Prove Lemma \ref{degresult}

\bs

Prove this lemma
If $f(x_0,x_1,x_2$ is an irreducible homogeneous polynomial, then
$f(1,x_1,x_2)$ is also irreducible.

\bs

A product $fg$ of polynomials 
is homogeneous if and only if the factors $f$ and $g$ are
homogeneous.\qed


\bs

Prove the formula 
$$\discr(F) = \prod_{i\neq j} (\alpha_i-\alpha_j)= \pm \prod_{i<j}
(\alpha_i-\alpha_j)^2
$$

\bs

Do affine case of {fgzerofinite}

\bs

Prove that by scaling the variables, the coefficients $a,b,c$ in the
equation $ax_0x_1+bx_0x_2+cx_1x_2$ can be eliminated.

\bs

Prove that $\res = \prod_{i=1}^m G(\alpha_i)\quad=\quad \pm
\prod_{i=1}^n F(\beta_i) .$

\bs

remove from text and put as exercise:
$\discr(F)  = \prod_j F'(\alpha_j)$

\bs

prove Lemma \ref{degresult}

\bs

classify quadrics in $\bbp^3$.
?Do conics by diagonalizing the form?

\bs

irreducibility of homogeneous polynomials in 3 variables 

\bs

Prove classification of conics by diagonalizing the quadratic form

\bs

classify quadrics in $\bbp^3$.

\bs

Make exercise about Hensel's lemma.

\bs

prove that the Fermat curve $C:\{x^d+y^d+z^d=0\}$ is connected by
studying its projection to $\bbp^1$ from the point $(0,0,1) $.




\bs

\msno \begin{thm} 
\Marginnote{exmostirreducible}\label{exmostirreducible}
Use counting constants to show that most polynomials $f(x,y)$  of degree $d$
are irreducible.\end{thm}

\bs
\msno \begin{thm}
\Marginnote{exinfpoints}\label{exinfpoints}
Prove that a plane curve contains  
infinitely many points.  \end{thm}


\bs\msno \begin{thm}
\Marginnote{exclassconics}\label{exclassconics}
Prove that all
affine conics can be put into one of the forms \ref{classconic} by
linear change of variable, translation, and scalar multiplication.\end{thm}


\bs
\msno \begin{thm}\Marginnote{exlinesdmeet}
\label{exlinesdmeet} Prove
that distinct points in the plane are
  contained in exactly one line, and that two distinct lines meet in
  exactly one point (Lemma \ref{linesmeet}).\end{thm}




\bs

\msno \begin{thm}  
\Marginnote{excoordtriangle}\label{excoordtriangle}
Describe the points
that lie in the interior of the coordinate triangle in the real
projective space.  \end{thm}



\bs
\msno \begin{thm} 
\Marginnote{exthreepoints}
\label{exthreepoints}
Let $f(x,y,z)$ be an irreducible homogeneous polynomial of degree $> 1$.
Prove that the locus $f=0$ in $\bbp^2$ contains three points that do
not lie on a line. \end{thm}

\bs

\msno \begin{thm}  
\Marginnote{exstaysirreducible}\label{exstaysirreducible}
 Let $f$ a
homogeneous polynomial in $x,y,z$, not the polynomial $z$.  Prove
that $f$ is irreducible if and only if $f(x,y,1)$ is irreducible.\end{thm}


\bs\msno \begin{thm}
\Marginnote{exsamelocus}\label{exsamelocus}  
Let $f$ and $g$ be irreducible homogeneous polynomials in $x,y,z$.
Prove that if the loci $\{f=0\}$ and $\{g=0\}$ are equal, then $g =
cf$.  \end{thm}


\bs
\msno \begin{thm}  
\Marginnote{XcapLclosed}\label{XcapLclosed}
 Let $X$ be
a Zariski closed subset of $\bbp^n$, and let $L$ be a line in
$\bbp^n$.  Prove that $X\cap L$ is a Zariski closed subset of the
one-dimensional projective space $L$.  \end{thm}


\bs
\msno \begin{thm}  
\Marginnote{exhessian}\label{exhessian}
Using Euler's formula, together with row
and column operations, show that the Hessian determinant is equal to
$\,a\,\det H'$, where $$ H' \;=\; \begin{pmatrix} cf & f_{1} &
f_{2}\\ f_{1} & f_{11} & f_{12}\\ f_{2} & f_{21} &
f_{22} \end{pmatrix}, \quad a = \textstyle{\big(\frac {d-1}{x_0}
\big)}^2 \quad\text{and}\quad c = \textstyle{\frac d{d-1}}.  $$ 
\end{thm}

\bs
\msno \begin{thm}  
\Marginnote{exchangecoordstanline}
\label{exchangecoordstanline}
{\bf (i)} How does
formula (\ref{texp}) depend on the point $q$ of $L$?

\no {\bf (ii)} Show
that a change of coordinates doesn't
effect the validity of part  Theorem \ref{tangentline}.

\no (iii) Prove  Theorem \ref{tangentline} in
the following way: Given a smooth point $p$ of $X$, choose
coordinates so that $p= (0,0,1)$ and the tangent line $L$ is the
line $\{x_1=0\}$.  Then compute $H_p$.  \end{thm}


\bs
\msno \begin{thm} {exsign} \Marginnote{exsign}\label{exsign}
  Proposition \ref{discrformulas} asserts that $\discr(F) = \pm
  \prod_{i<j} (\alpha_i-\alpha_j)^2.$ Determine the sign.  \end{thm}

\bs
\msno \begin{thm}  
\Marginnote{exresfg}\label{exresfg}
Let $f,g,$ and $h$ be
polynomials.  Prove that 

\no {\bf  (i)} $\res(f,gh) =
\res(f,g)\res(f,h)$.  

\no {\bf  (ii)} If the degree of $gh$ is less than or equal to the
degree of $f$, then $\res(f,g) = \res(f+gh,g)$.\end{thm}

\bs
\msno \begin{thm}
\Marginnote{etdegres}\label{etdegres}
 Let $f = a_0x^m+a_1x^{m-1}+ \cdots
a_m$ and $g = b_0x^n+b_1x^{n-1}+ \cdots b_n$, and let $R = \res(f,g)$
be the resultant of these polynomials. Prove that 

\no {\bf (i)} $R$
is a polynomial that is homogeneous in each of the sets of variables
$a$ and $b$, and  determine its degree.

\no {\bf (ii)} If one
assigns weighted degree $i$ to the coefficients $a_i$ and $b_i$, then
$R$ is homogeneous, of weighted degree $mn$, and 
determine its weighted degree.  \end{thm}

\bs
\msno \begin{thm}
\Marginnote{resexer}\label{resexer}
  Let $f(x,y)$ be a homogeneous polynomial of
degree $m$ with coefficients in a field, and let $f_x,f_y$ denote its
partial derivatives.  Prove that $\res(f(x,1),xf_x(x,1)) =
\res(f_y(1,y),yf_y(1,y))$, and explain what it means for these
resultants to be zero.  \end{thm}

\bs
\msno \begin{thm}
\Marginnote{exercresformula}  
\label{exercresformula}  
Verify
Proposition \ref{resroots} directly for the two polynomials $x^m$ and
$x^n-1$.  \end{thm}

\bs\msno \begin{thm}
\Marginnote{discrcyclot}\label{discrcyclot}
Complete
the proof of part {\bf (ii)} of Proposition \ref{discrformulas} by
computing $\prod_{i\neq j} (\zeta^i-\zeta^j)$ when $\zeta = e^{2\pi
i/n}$.  \end{thm}

\bs
\msno \begin{thm}
\Marginnote{genericordinary}\label{genericordinary}
  Prove that a generic curve
satisfies the conditions of (\ref{singordinary}).  \end{thm}

\bs
\msno \begin{thm} \Marginnote{indepcoord}\label{indepcoord} Consider a
  change of coordinates of the form $(x,y)^t = P(x',x')^t$.  where $P$
  is an invertible $2\times 2$ matrix.  Let $f'$ denote the
  homogeneous polynomial in $(x',y')$ obtained by substitution into
  $f(x,y)$.  Determine $\res(f',g')$ in terms of $\res(f,g)$.  Do the
  same for $\discr(f')$.\end{thm}

\bs
\msno \begin{thm}
\Marginnote{exlocalizeopen}\label{exlocalizeopen}
Prove Proposition \ref{localizisopensubspace}.\end{thm}

\bs\msno \begin{thm}
\Marginnote{mostvals}\label{mostvals}
 Let $f(x,y)= a_n(x)y^n + \cdots
+ a_0(x)$ be an irreducible homogeneous polynomial, where $a_i$ are
polynomials in $x$.  Prove that for most values $x=x^0$, the
polynomial $f(x^0,y)$ has distinct roots.\end{thm}



\bs
\msno \begin{thm} \Marginnote{infpoints}\label{infpoints} Prove that a
  plane curve contains infinitely many points. \end{thm}

\bs \begin{thm}
\Marginnote{projecthruq}\label{projectthruq}
 With notation as
in Section \ref{coverline}, what can be said about the projection of
a curve which passes through $q$?\end{thm}


\bs
\msno \begin{thm}  
\Marginnote{exequationcubic}\label{exequationcubic}
  Let $C$ be a
smooth projective cubic curve. 
Prove:

 \no {\bf (i)} With a
suitable choice of coordinates in $\bbp^2$, $C$ is the locus of zeros
of a polynomial of the form $$y^2z+x^3+axz^2+bz^3.$$

\no
{\bf (ii)} With a further change of coordinates, one of
the two parameters $a,b$ can be eliminated from the equation, and
that therefore smooth cubic curves depend on only one parameter.\end{thm}

\bs
\msno \begin{thm}
\Marginnote{generalline}\label{generalline}
  Prove that a general line
meets a plane projective curve of degree $d$ in $d$ distinct points.\end{thm}

\bs
\msno \begin{thm} \Marginnote{excontact}\label{excontact} With the
  notation of Proposition \rec{transversalH}, what can be said about
  the intersection of a curve $C$ and its Hessian divisor $D$ when $C$
  and $D$ have a contact of order $r > 3$?\end{thm}


\bs

\msno \begin{thm} 
\Marginnote{Phausdorff}\label{Phausdorff}
Prove that with its classical topology, $\bbp^n$ is a Hausdorff
space. \end{thm}

\bs
\msno \begin{thm}
\Marginnote{exPonesphere}\label{exPonesphere}
Prove that the
projective line $\bbp^1$ is homeomorphic to a two-dimensional sphere.\end{thm}

\bs
\msno \begin{thm}
\Marginnote{singularclosed}\label{singularclosed}
Prove Theorem
\ref{singclosed} directly, without appealing to Theorem
\ref{projectproper}.  \end{thm}


\bs
\msno \begin{thm}
\Marginnote{vanishingdiscr}  \label{vanishingdiscr}  
With notation as in
Proposition \ref{discrimvanishing}, show that if a line $L_{\op}$
has a contact of order $r$ with $C$, the discriminant has a zero of
order $r$ at $\op$.  \end{thm}


\bs\msno \begin{thm}
\Marginnote{exgenericordinary}\label{exgenericordinary}
 Prove that a generic plane curve is ordinary.  \end{thm}

\bs
\msno \begin{thm}
\Marginnote{excusptan}\label{excusptan}
 Let $p$ be a cusp of the curve
$C$ defined by the homogeneous polynomial $f$.  Prove that there is
just one line $L$ through $p$ such that the restriction of $f$ to
$L$ has as zero of order $> 2$, and that the order 
of zero for
this line is precisely $3$.  \#\#do for smooth curve \#\#
\end{thm}

\bs
\msno \begin{thm}  
\Marginnote{exdualnodalcubic}\label{exdualnodalcubic}
The polynomial $f=
3(x^2+y^2)z-x^3$ defines a cubic curve $C$ with a node at $(0,0,1)$.
Let $C^*$ be its dual curve.  Determine the degree of $C^*$ and the
numbers of flexes, bitangents, nodes, and cusps of $C$ and $C^*$.\end{thm}


\bs\msno \begin{thm}
\Marginnote{mostirred}\label{mostirred}
 Prove that most
nonhomogeneous polynomials in two or more variables are irreducible.\end{thm}

\bs
\msno \begin{thm}
\Marginnote{finbitan}\label{finbitan}
 Let $C$ be a plane
projective curve, let $L_0$ be an arbitrary line in $\bbp$, and
let $L_0^*$ be the corresponding point of the dual space $\bbp^*$.
Prove that in the classical topology, there is a neighborhood $V$ of
$L_0^*$ in $\bbp^*$ such if $L$ is a line distinct from
$L_0$, and if $L^*$ is in $V$, then $L$ is not a bitangent
line.  Conclude that $C$ has finitely many bitangents.  \end{thm}

\bs
\msno \begin{thm}
\Marginnote{blowuparbsing}\label{blowuparbsing}
Prove that there
exists an ordinary curve.\end{thm}

\bs
\msno \begin{thm}
\Marginnote{standardtwo}\label{standardtwo}
  Complete the
proof of Lemma \ref{standardform}.  \end{thm}

\bs

\msno \begin{thm}
\Marginnote{resolvecuspex}\label{resolvecuspex}
  Prove parts {\bf (ii)} and
{\bf (iii)} of Theorem \ref{resolvecusp}.  \end{thm}

\bs
\msno \begin{thm}
\Marginnote{resnodeex}\label{resnodeex}
Prove Theorem \ref{resnode}.\end{thm}



\bs
Think about Exercises for Pascal's Thm, Briancon's Thm, Poncelet's Thm


\newpage
\section{Chapter 2 Exercises.}\Marginnote{exchaptwo}\label{exchaptwo}

\ms Prove the assertion above (\ref{pointpair}), that that the
varieties in the affine plane $\bba^2$ are points, curves, and
the affine plane $\bba^2$ itself.

\ms

Let $C$ and $D$ be closed subsets of an affine variety $X=\spec A$.
Suppose that no component of $D$ is contained in $C$.  Then there is a
regular function $f$ that vanishes on $C$ and isn't identically zero
on any component of $D$.

\ms
If a noetherian ring contains just
one prime ideal, then that ideal is nilpotent. 


\ms
Let $I$ and $J$ be ideals in the
polynomial algebra $\bbc[x_1,\ldots ,x_n]$.

\no {\bf (i)} A polynomial $g$ vanishes at every point of $V(I)$ if
and only if it is in  $\;\rad I$.

\no {\bf (ii)} $V(I)= V(J)$ if and only if $\,\rad I = \rad J$, and
$\,V(I) \supset V(J)$ if and only if $\rad I \subset \rad J$, and  this is
true if and only if $I \subset \rad J$.  \qed
\label{zeroonV} 

\ms
(also \ref{subsofspecA})

\ms
prove corollary \ref{strongnullA}

\ms
deive version 2 from version 3.

\ms
prove example \ref{ztopdimone}

\ms
prove corollary \ref{powersgenerate}

\ms
How uniquely does the  formula \ref{ustarphi} determine the map $u$?


\msno 
One can use formula (\ref{pipaap}) to
  define the function associated to an element $\alpha$ of a
  finite-type algebra $A$, whether or not $A$ is a domain, but an
  element $\alpha$ may not be determined by the function.


show noetherian ring has  finitely many minimal prime ideals.


\msno

{\bf (i)} Find generators for the ideal of polynomials that vanish on
a pair of points of $\bba^2$.

\no
{\bf (ii)}  Do the same for a set of three points not on a line.



\begin{thm}\Marginnote{dimthree}\label{dimthree}
Classify algebras that are complex vector spaces of dimension three.
\end{thm}




\msno \begin{thm} 
\Marginnote{exfgequalsmd}\label{exfgequalsmd}
 Let $R$ be a unique factorization
domain, and let $f$ and $g$ be nonzero elements of $R[x]$.  Prove
that $f$ and $g$ have a greatest common divisor $d$ and a least
common multiple $m$, and that $fg = dm$.  \end{thm}


\msno \begin{thm}
\Marginnote{minprimes}\label{minprimes}
Prove that the
set of minimal prime ideals of a nonzero noetherian ring is finite and
nonempty.\end{thm}

\msno \begin{thm} \Marginnote{exinvertseries}\label{exinvertseries}
  Prove that, in the ring of formal power series, a power series
  $p(x_1,...,x_n)$ whose constant term is nonzero is
  invertible.\end{thm}


\msno \begin{thm}
  \Marginnote{constructlocaliz}\label{constructlocaliz} Let $A$ be a
  quoteint algebra of $\bbc[x_1,...,x_n]$, and let $g$ be a polynomial in
  $\bbc[x]$ whose residue is $s$.  The ring $A[s^{-1}]$ can be
  constructed explicitly as the quotient of a polynomal algebra $A[y]$
  modulo the principal ideal generated by $sy-1$.  Equivalently,
  $A[s^{-1}]$ may be constructed as a quotient of the polynomial
  algebra $\bbc[x_1,...,x_n,y]$ modulo the ideal $J$ generated by the
  elements $f_1,...,f_k$ and $gy-1$. \end{thm}

\msno \begin{thm}
\Marginnote{exfindimalg}\label{exfindimalg}
(Finite-Dimensional Algebras.)

\no
\no{\bf (i)}  
Let $A$ be an algebra that is a
finite-dimensional vector space. 
Prove that every prime ideal of $A$ is a
maximal ideal, and that there are finitely many maximal ideals.

\no
{\bf (ii)} A finite-type algebra is a
finite-dimensional vector space if and only if it satisfies the
descending chain condition on ideals.\end{thm}


\msno \begin{thm}
\Marginnote{exlocalizevariety}\label{exlocalizevariety}
 Suppose that $A$ is the coordinate ring of an affine variety $X$.
Describe the variety whose coordinate ring is $A[s^{-1}]$.\end{thm}


\msno \begin{thm} \Marginnote{mapofclosedx}\label{mapofclosedx}
  Suppose that $A = \bbc[x_1,\ldots,x_m]/I$ and $B =
  \bbc[y_1,\ldots,y_n]/J$.  Let $X = \spec \bbc[x]$ and $Y =\spec
  \bbc[y]$.  Describe the map of closed sets $V_Y(J) \longleftarrow
  V_X(I)$ defined by a ring homomorphism $A \ar B$.\end{thm}



\ms
How does $G$ operate on maximal ideals?

\msno
\begin{thm} Show that the affine curve $\spec A$, where
$A= \bbc[x,y]/(x^2+y^2-1)$ is isomorphic to the complement of the
  origin in the affine line $\bba^1$.
\end{thm}

\msno \begin{thm} \Marginnote{exspecAs}\label{exspecAs} Let $X_s$ be a
 localization of an affine variety $X$.  Prove that when $X_s$ is
  identified with a subset of $X$, its Zariski topology is the induced
  topology (Lemma \ref{specAs}{\bf (ii)}).
\end{thm}

\msno \begin{thm} \Marginnote{expandregfun}\label{expandregfun} Let
  $B$ be the coordinate algebra of an affine variety $Y$.  Prove that
  there are bijective correspondences between the following sets:

\sbull\; regular functions on $Y$, i.e.,  elements of $B$,

\sbull\; homomorphisms $\bbc[x]\stackrel{\varphi}{\longrightarrow}B$
from the one-variable polynomial algebra to $B$, and

\sbull\; morphisms $Y \stackrel{u}{\longrightarrow}\bba^1_{x}$ from
$Y$ to the affine line.\end{thm}

\msno \begin{thm}
\Marginnote{excuspnormx}\label{excuspnormx}
With notation as in (\ref{cuspnormx}, prove that the morphism $u$
 is a homeomorphism.
\end{thm}


\msno \begin{thm}
\Marginnote{spellout}\label{spellout}
 Explain what a morphism $\spec B \ar \spec A$
means algebraically, when  $A =
\bbc[x_1,\ldots,x_m]/(f)$, $f = f_1,\ldots,f_r$, and $B =
\bbc[y_1,\ldots,y_n]/(g)$, $g = g_1,\ldots,g_k$.\end{thm}

\msno \begin{thm}
\Marginnote{morhicontinx}\label{morhicontinx}
  Prove that the morphism
$\spec A \leftarrow B$ defined by a homomorphism $A \ar B$ of
finite-type algebras is continuous, both in the Zariski topology and
in the classical topology.\end{thm}

\msno \begin{thm} \Marginnote{acctonplanex}\label{acctonplanex}
  Determine the ring of invariant functions fore the operation of the
  cyclic group of order $n$ on $\bbc[x,y]$ by Do $\sigma(x) =
  \zeta^ix, \sigma(y)= \zeta^j y$.\end{thm}


\msno \begin{thm} \Marginnote{exffld}\label{exffld} Let $K$ and $L$ be
  fields of rational functions $\bbc(x)$ and $\bbc(y)$ in one
  variable, respectively.  Compare the tensor product $R= K\otimes_\bbc
  L$ with the field of fractions $\bbc(x,y)$ of $\bbc[x.y]$, and
  describe the prime ideals of $R$.
\end{thm}

\newpage

\section{Chapter 3 Exercises.}

\ms
??? Lemma \ref{firstpropmorph} gives us a way to describe a morphism
$Y \stackrel u \rrr X$ by morphisms of affine varieties.  If $u$ is
given, we may choose an open covering of $X$ by affine open sets
$X_j$, then cover each of their inverse images $Y_j$ by affine open
subsets $Y_{j\nu}$ of $Y$.  Let $X_{j\nu}$ be a copy of $X_j$ for each
$\nu$.  We reindex, writing $(j,\nu) = i$.  This
gives us a family of morphisms $Y_i\stackrel{u_i}\rrr X_i$ of affine
varieties that determines $u$.  Conversely, suppose that affine open
coverings $Y_i$ and $X_i$ of $Y$ and $X$ and morphisms $Y_i\stackrel
{u_i}\rrr X_i$ are given, and that the restrictions of $u_i$ and
$u_{i'}$ to morphisms $Y_i\cap Y_{i'} \ar X_i\cap X_{i'}$ are equal
for every pair of indices $i,i'$.  Then one obtains a morphism $u$.


  We must be a little
careful because the pullback needn't be defined for all rational
functions.  A homomorphism $A\stackrel \varphi\rrr
B$ won't extend to the fraction fields
unless its kernel is zero.


\ms
Let $U$ be an open subset of $\bbp^n$, and let $\alpha$ be a rational
function that is bounded on $U$.  Then it is
a constant.


\ms
explain $hom(dehom(\ci))$ and $dehom(hom(I))$


\ms
make exercise

 Let $Y$ be
  the cusp curve $\spec B$, where $B = \bbc[x,y]/(y^2-x^3)$.  We
  describe a map $Y \ar \bbp^1$.  The
  algebra $B$ embeds as subring into $\bbc[t]$, by
$$ x=t^2.\;\;y=t^3.$$ This gives us a map from the affine line $\spec
  \bbc[t]$ to $Y$.  Moreover,   because $t = y/x$ and $t^{-1} = y/x^2$, $B[x^{-1}]$ is isomorphic to $\bbc[t,t^{-1}]$.  The fraction field $K$ of
  $\bbc[t]$ is equal to that of $B$.

We define a morphism $Y \ar \bbp^1$ using the two vectors
$v_0=(x\!-\!1,y\!-\!1)$ and $v_1=(t\!+\!1,t^2\!+\!t\!+\!1)$.  These
vectors define the same point of $\bbp^1$ with values in $K$ because
$v_0 = (t\!-\!1)v_1$.
Because the vector $v_0$ has entries in $B$, it defines a morphism to
$\bbp^1$ wherever the two entries aren't both zero.  The relation
$y^2=x^3$ shows that if $x=1$, then $y=1$ too, so $v_0$
defines a morphism from the complement $Y^0$ of
the point $(1,1)$ to $\bbp^1$.  

 Next, the entries of $v_1$ aren't both zero anywhere.  So $v_1$
defines a morphism from $Y$ to $\bbp^1$ wherever its entries are
regular functions on $Y$.  Since $t = y/x$, this includes all points
where $x \neq 0$, which is to say, all points except the point $(0,0)$
of $Y$.  So $v_1$ defines a morphism from the complement $Y^1$ of the
origin in $Y$ to $\bbp^1$.  These two morphisms piece together to give
us a morphism $Y \ar \bbp^1$.\qed\label{maptoP} 


\msno
\begin{thm}\Marginnote{fdividesg}\label{fdividesg}
 Let $F,G$ be dehomogenizations of homogeneous polynomials
$f,g$.  Discuss the relation between the conditions $F|G$ and $f|g$.
\end{thm}

\msno
\begin{thm}\Marginnote{homogprimeconverse}\label{homogprimeconverse}
Let $\Cal P$ be a homgeneous ideal whose dehomogenizations $P_i$ are
prime ideals.  Is $\Cal P$ a prime ideal?
 \end{thm}


\msno
\begin{thm}\Marginnote{classquad}\label{classquad}
Classify  smooth quadrics in $\bbp^3$.
\end{thm}


\msno
\begin{thm}\Marginnote{complementWoneone}\label{complementWoneone}
  Describe the complement of $W_{11}$ in $G(2,4)$.  \ms
\end{thm}

\msno
\begin{thm}\Marginnote{vvzero}\label{vvzero}
Prove Lemma 3.3.4.\end{thm}

\msno
\begin{thm}\Marginnote{veronisom}\label{veronisom}
Show that the Veronese map (\ref{veroneseemb}) is an isomorphism onto
its image.\end{thm}


\msno
\begin{thm}\Marginnote{eqprod}\label{eqprod}
  What are the
defining equations for $X\ktimes Y$ as a subset of $\Pi$?
\end{thm}



\msno
\begin{thm}\Marginnote{exptsaffine}\label{exptsaffine}
 Extend Lemma \ref{pointsinaffine} to quasiprojective varieties.
\end{thm}

\msno
\begin{thm}\Marginnote{easykleiman}\label{easykleiman}
Prove that every finite subset $S$ of a quasiprojective variety $X$ is
contained in an affine open subset. \end{thm}

\msno
\begin{thm}\Marginnote{pointdouble}\label{pointdouble}
Let $X_1$ and $X_2$ be affine lines, and let $V_i$ be the complement
of the origin $p_i$ in $X_i$.  We may form an abstract variety $Y$ by
identifying $V_1$ and $V_2$, but ``forgeting'' to put glue at the two
origins in $X_1$ and $X_2$.  Then $Y$ is a line in which the origin is
replaced by the two points $p_1, p_2$.  A subset $U$ of $Y$ is open if
$U\cap X_i$ are open for $i=1,2$, and  a function is regular on an
open set $U$ if it is regular on $U\cap X_1$ and on $U\cap X_2$.
This defines the structure sheaf ${\co}_Y$.

\no
{\bf (i)} What are the global sections of $\co_Y$?

\no {\bf (ii)} Prove that there is a morphism from $Y$ to an affine
line $X$ that identifies the two points $p_i$.

\no
{\bf (iii)} Form a product variety $Y\ktimes Y$
as the union of the four open sets $X_i\times X_j$.
Prove that the diagonal $Y_\Delta$ in $Y\ktimes Y$ isn't closed.
\end{thm}



\msno
\begin{thm}\Marginnote{regfnconst}\label{regfnconst}
Let $V$ be an open subset of $\bbp$ whose complement $C$ doesn't
contain the locus of zeros of a nonconstant homogeneous polynomial
$g$. Prove that $\co_\bbp(V) = \bbc$.
?? maybe complement of a point??\end{thm}


\msno
\begin{thm}\Marginnote{bracketloc}\label{bracketloc}
 Let $f$ be a homogeneous polynomial of positive degree $r$, and
let $U_{\{f\}}$ denote the subset of $\bbp^n$ of points at which $f$
isn't zero.  Let ${\CR}_{\{f\}}$ denote the set of homogeneous
fractions of the form $h/f^k$, where $h$ has degree $rk$, together
with zero.  (The curly brackets around the subscript $f$ are there as
a reminder: This is {\bf not} a localization of ${\CR}$.)
Prove:

\no {\bf (i)} The set ${\CR}_{\{f\}}$ is a finite-type domain,
generated by the elements $m/f$, where $m$ runs through the monomials
of degree $r$.

\no {\bf (ii)} The ring of regular functions on $U_{\{f\}}$ is
${\CR}_{\{f\}}$.

\no {\bf (iii)} $U_{\{f\}}$ is an affine open subset of $\bbp^n$,
isomorphic to the affine variety $\spec {\CR}_{\{f\}}$.
\end{thm}

\msno
\begin{thm}\Marginnote{exgenrel}\label{exgenrel}
Let $f=x_0^2-x_1x_2$.  Determine generators and defining relations for
the ring ${\CR}_{\{f\}}$ of exercise \ref{bracketloc}.
\end{thm}

%\end{document}

\section{Morphisms to Projective Space}
\Marginnote{morphprojspace}\label{morphprojspace}


\ms\#\#this isn't very  clear\#\#

\msno \begin{proposition}{\bf Proposition.}
\marginnote{morphtop}\label{morphtop}
 Let $X$ be a variety
with function field $K$.

\no {\bf (i)} A morphism $X \stackrel{f}\longrightarrow \bbp^n$ from
$X$ to projective space determines a point of $\bbp^n$ with values in
$K$.

\no {\bf (ii)} Let $(\beta_0,...,\beta_n)$ be a point of $\bbp^n$ with
values in $K$, and let $V_i$ denote the largest open set on which all
of the functions $\beta_0/\beta_i,...,\beta_n/\beta_i$ are regular.
The point determines a  morphism $X \ar \bbp^n$ if and only if
$X = \bigcup V_i$.\end{proposition}

\begin{proof} {\bf (i)} Let $U_0= \spec R_0$
denote the standard affine open subset of $\bbp^n$, with $R_0 =
\bbc[u_1,...,u_n]$, $u_i = x_i/x_0$, and let $V = \spec B$ be a
nonempty affine open subset of $X$ whose image is contained in $U_0$.
We may restrict the morphism $f$, to obtain a morphism of varieties $V
\ar U_0$.  This morphism will be given by an algebra homomorphism $R_0
\ar B$, and we obtain a homomorphism $R_0 \ar K$ by composition.  The
images $\beta_i$ of $u_i$ in $B$ give us a point
$(\beta_1,...,\beta_n)$ of $U_0$ with values in $K$, and a point
$(1,\beta_1,...,\beta_n)$ of $\bbp^n$ with values in $K$.  This point
of projective space doesn't depend on the choice of the index $i=0$
and the affine open subset $V$, except that we must assume $f^{-1}U_i$
is nonempty, which will be true for at least one index.

\msno \no {\bf (ii)} We write the point with values in $K$ as
$(\gamma_0,...,\gamma_n)$, where $\gamma_j = \beta_j/\beta_i$ and
$\gamma_i=1$.  The functions $\gamma_j$ are regular on $V_i$, and they
define a morphism $V_i \ar \bbu^i \subset \bbp^n$.  Piecing these
morphisms together gives us a morphism $X\ar \bbp^n$
(\rec{enufopens}).  \qed\end{proof}



\msno To begin, let's suppose that $X$ is affine variety, say $X =
\spec A$.  Morphisms from $X$ to affine space $\bba^n$ are given by
$n$-tuples $\alpha = (\alpha_1,...,\alpha_n)$ of elements of $A$.
The morphism determined by $\alpha$ sends a point $p$ to the point
$(\alpha(p))$ of $\bba^n$ obtained by evaluation at $p$.

However, a morphism from an affine variety $X = \spec A$ to
projective space needn't be determined by a vector
$\alpha = (\alpha_0,...,\alpha_n)$ with $\alpha_i$ in $A$.
 If $p$ is a point of $X$, evaluation at $p$ determines a
point of $\bbp^n$ only if the values $\alpha_i(p)$ aren't all zero.
To determine a map, we must know that for any $p$, there is an $i$
such that $\alpha_i(p) \neq 0$, or that the intersection of the zero
sets of $\alpha_i$ in $X$ is empty.  If this is true, $\alpha$
defines a morphism to $\bbp^n$ by evaluation.

\ms But because points of $\bbp^n$ are
equivalence classes of vectors, there may be
morphisms $X \ar \bbp^n$ that cannot be defined by any single vector
$\alpha$.

\msno 
\begin{example}{\bf Example.}\Marginnote{maptoP}\label{maptoP}
 A map from a cusp curve to
$\bbp^1$.  Let $A = \bbc[x,y]/(y^2-x^3)$ and let $X$ be the cusp curve
 $\spec A$.  Recall that $A$
 embeds as subring into the polynomial ring $\bbc[t]$, by $x
\squig t^2$ and $y\squig t^3$, $t = y/x$.  Moreover, $A[x^{-1}]
\approx\bbc[t,t^{-1}]$ because $t = y/x$ and $t^{-1} = y/x^2$.
The fraction fields of $\bbc[t]$ and $A$ are equal.

We define a morphism $X \ar \bbp^1$, using the two vectors
$v_0=(t+1,t^2+t+1)$ and $v_1=(x-1,y-1).$ We note that $v_1 =
(t-1)v_0$, so these vectors  define
the same point of $\bbp^1$ with values in $K$.

The entries of $v_0$ are relatively prime polynomials.  They aren't
both zero at any point.  So $v_0$ defines a morphism to $\bbp^1$
wherever the two entries are regular.  Since $t = y/x$, this includes
all points at which $x$ isn't zero -- all points except the origin
$(0,0)$.  Let's denote the open complement of the origin in $X$ by
$X^0$.  Then $v_0$ defines a morphism $X^0\ar \bbp^1$.  

Next, the vector $v_1$ has entries in $A$, so it defines a morphism to
$\bbp^1$ wherever the two entries are not both zero.  The relation
$y^2=x^3$ shows that if $x=1$, then $y=1$ as well.  So $v_1$
defines a morphism the complement $X^1$ of
the point $(1,1)$ to $\bbp^1$.  

Putting these two morphisms together gives us a morphism $X \ar
\bbp^1$.\qed\end{example}

Exercise.  Prove that if the tangent lines to a curve $X$ in $\bbp^n$
pass through a single point, then $X$ is a line.


==============================================
\ms Let $K$ be a field that contains the complex numbers, and let $X =
\spec A$ be an affine variety.  A {\it point} of $X$ {\it with values
  in} $K$ is an algebra homomorphism $A \ar K$.

\ms The Substitution Principle tells us that algebra homomorphisms
$\bbc[x_1,...,x_n] \ar K$ are given by assigning the images $a_i$ of
$x_i$ arbitrarily.  So points of affine space $\bba^n$ with values in
$K$ correspond to arbitrary vectors $(a_1,...,a_n)$ with entries in
$K$.  If $A = \bbc[x]/(f)$, where $x=x_1,...,x_n$ and $f =
f_1,...,f_k$, then a point of $X= \spec A$ with values in $K$ is given
by a solution in $K$ of the equations $f=0$ (Proposition
\ref{mapbtoa}). 

\ms The concept of a {\it point} of projective space {\it with values
  in} a field $K$ is defined similarly, as an equivalence class of
nonzero vectors $(\alpha_0,...,\alpha_n)$ with $\alpha_i$ in
$K^{n+1}$.  The equivalence relation is that $(\alpha_0,...,\alpha_n)
\sim (\lambda\alpha_0,...,\lambda\alpha_n)$, where $\lambda$ can be
any nonzero element of $K$.  As with points with values in $\bbc$, one
can represent the point $\alpha$ uniquely by the vector
$(1,\alpha_1/\alpha_0,...,\alpha_n/\alpha_0)$, provided that
$\alpha_0$ is not zero.  A point of a projective variety
$X$ with values in $K$ is a point of $\bbp^n$ that solves the
homogeneous polynomial equations that define $X$.

\ms One defines a point of an affine variety $X$ with values in an
algebra $R$ in the same way, as an algebra homomorphism $A \ar R$, or
as a solution of the system of equations $f(x)=0$ in $R$.  A point of
$X$ with values in the polynomial ring $\bbc[t]$ is defined by
polynomials $x_i(t)$, $i=1,...,n$, such that $f(x(t))=0$.  It is a
{\it polynomial path} in $X$, a morphism $\bba^1 = \spec \bbc[t] \ar
X$.  But when $R$ is not a field, the fact that points of projective
space are equivalence relations may cause trouble.  One needs to be
more careful.  We explain this in the next section.

\newpage

\section{Chapter 4 Exercises.}\Marginnote{exchapfour}\label{exchap4}


\bs
  Let $K$ be the field of fractions of a normal finite-type domain
  $A$, let $L$ be a Galois extension of $K$ with Galois group $G$, and
  let $B$ be the integral closure of $A$ in $L$, a finite $A$-module.
Let $X=\spec A$ and $Y
=\spec B$. 
\no
{\bf (a)}  Show that $A$ is the algebra of invariants $B^G$. 

\no
{\bf (b)}  Show that the closed subvarieties of $Y$ that lie over a closed
subvariety $C$ of $X$ form a $G$-orbit.

\bs Let $F$ be a square-free poltnomial in $A = \bbc[x,y]$, and let $B
= \bbc[x,y,w]/(w^2-f)$.  Let $g$ be an irreducible element of the
polynomial algebra $A$, let $P$ be the principal prime ideal $gA$ of
$A$, and let $C$ be the curve of zeros of $g$ in the affine plane $X$.
Prove that there are three possibilities:

\no $\text{\bf{$P$ splits:}}$ $g$ doesn't divide $f$ and There are two
closed subvarieties of $Y$ that lie over $C$, and there are two prime
ideals of $B$ that lie over $P$.

\no $\text{\bf{$P$ remains prime:}}$ $g$ doesn't divide $f$ and there 
is one closed subvariety of $Y$ that lies over $C$.  The extended
ideal $PB=gB$ is the unique prime ideal that lies over $P$.

\no
 $\text{\bf{$P$ ramifies:}}$ $g$ divides $f$.  
There is one closed subvariety of
$Y$ that lies over $C$.  The extended ideal $gB$ is not a prime ideal,
but its radical $Q = (g,w)B$ is the unique prime ideal that lies over
$P$.

 
\bs With reference to \ref{quadrformula}, show that the map $Y
\stackrel \psi \rrr S$ extends to a morphism everywhere on  $Y$.

\bs Let $Y\ar X$ be an integral extension, and let $C'\subset C$ be
closed subvarieties of $X$.  Show that if $D$ is a closed subvariety $D$ of
$Y$ that lies over $C$, there is a closed subvariety $D'$ that lies
over $C'$, such that $D'\subset D$.


\bs
  A module $M$ over
a ring $B$ is {\it faithful} if, for every nonzero element $b$ of $B$,
scalar multiplication by $b$ isn't the zero operation on $M$.  Let $A$
be a domain, let $z$ be an element of its field of fractions, and let
$B$ be the ring generated by $z$ over $A$.  Suppose there is a
faithful $B$-module $M$ that is finitely generated as an $A$-module.
Prove that $z$ is integral over $A$.


\bs
  Let $A$ be a domain with fraction field $K$, and let $\alpha$ and
  $\beta$ be elements of $K$ such that $\alpha\beta = 1$, and suppose that
  $\alpha$ is integral over $A[\beta]$.  Prove that $\alpha$ is an
  element of $A[\beta]$, and that it is integral over $A$.


\bs
Derive Version 2 of the Nullstellensatz from Version 4, for
finite-type algebras over an algebraically closed field $k$.


\bs
  $A\subset B$ be an extension of finite-type algebras such that $B$
  is a finite $A$-module, and let $P$ be a prime ideal of $A$.  Prove
  that the number of prime ideals of $B$ that lie over $P$ is at most
  equal to the degree $[L:K]$ of the field extension.

\bs
  With reference to Example
\ref{goingdownfalse}, determine generators for the prime ideal $P$ of
$A$ such that $V_X(P) = C$.

\bs
 Let $Y$ be a closed
subvariety of projective space $\bbp^n$ with coordinates
$y_0,...,y_n$, let $d$ be a positive integer, and let $w_0,...,w_k$ be
homogeneous polynomials in $y$ of degree $d$ that have no
common zeros on $Y$.  Prove that sending a point $q$ of $Y$ to
$(w_0(q),...,w_k(q))$ defines a finite morphism $Y \stackrel u
\longrightarrow\bbp^k$.

\#ugh\# Do this first for linear coordinates, and $w = y_1,...,y_n$,
so that $u$ is defined by the projection $\bbp^n
\stackrel\pi\longrightarrow \bbp^{n-1}$.

\bs
Prove Lemma \ref{primesindplane}.

\bs
Prove Proposition \ref{onecoverfinite} for a finite morphism,
using the following outline:

\no
(a) It is enough to prove the lemma in the case that $X$ is affine,
$X= \spec A$, and that it is covered by localizations $X^i=X_{s_i}$
such that $Y^i = u^{-1}X^i$ is affine, $Y^i = \spec B_i$.

\no
(b) Let $B = \bigcup B_i$.  Then $B_{s_i} = B_i$.  


\no (c) $B$ is a finite $A$-module.


\no(d) $Y$ is isomorphic to $\spec B$.


\bs
Prove
 Proposition \ref{primesindplane} without using the results of Section 
\ref{prmint}.


\bs
Let $Y\ar
X$ be an affine double plane, and let $D$ be a curve in $Y$ whose
image in $X$ is a plane curve $C$.  Say that $C$ has degree $d$.
Define $\deg D$ to be $d$ if $C$ splits and $2d$ if $C$ remains prime
or ramifies.  Explain the curious point (\ref{curiouspoint}) with
reference to the degrees of $C$ and $D$.

\newpage

\section{Chapter 5 Exercises}\Marginnote{exchapfive}\label{exchapfive}


\bs
$A,B$ finite-type domains implies $A\otimes B$ is a f-t domain.


\ms
Prove Proposition \ref{extendidealtoloc} 


\ms In the four dimensional space $Z$  of $2\ktimes 2$ matrices, let $X$ be
the locus of idempotent matrices: $A^2=A$.  The general linear group
$GL_2$ operates on $X$ by conjugation.

(a) Decompose $X$ into orbits for the operation of $GL_2$, and prove
that the orbits are closed subsets of $Z$.

(b) Show that the orbits are smooth by verifying the Jacobian
criterion at a suitable point of each orbit.



  \ms on an affine curve, there
is a rational function with just one pole.  an open subset of an
affine curve is affine.

\ms
do nodes and cusps


\ms
prove twisted cubic is smooth both ways.

\ms
Bertini for pencil in $\bba^2$ or $\bbp^2$: Show that if $f(x,y)$ is
polynomial and if $d$ divides $f_x$ and $f_y$, then $f$ is constant on
the locus $d=0$.


\ms
quasiprojective and proper implies projective


\no {\bf (iii)} Every constructible set $S$ is a union
$L_1\cup\cdots\cup L_k$ of {\bf disjoint} locally closed sets $L_i =
C_i\cap U_i$, in which the closed sets $C_i$ are irreducible and
distinct.

Make exercise out of \ref{twistcubic}


\begin{corollary}{\text{\bf Corollary.}}
\Marginnote{localizationisdvr}\;\, Let $A$ be a normal finite-type
domain.  The localization $A_P$ of $A$ at a prime ideal $P$ of
codimension $1$ is a  valuation ring.
\label{localizationisdvr} \end{corollary}

\no
This follows from Proposition \ref{primelocal} {\bf (ii)}.\qed

\ms Let $X= \spec A$ be a normal affine variety, and let $W$ be the
closed subvariety of $X$ of codimension $1$ that corresponds to a
prime ideal $P$ of codimension one.  The local ring $A_P$ is a
 valuation ring.  Let $\vv$ be the corresponding valuation of
the fraction field $K$ of $A$ and let $k$ be a positive integer.
Extending some terminology introduced before, we say that a nonzero
element $\alpha$ of $K$ has a {\it zero of order} $k$ on $W$ if
$\vv(\alpha) = k$, and a {\it pole of order $k$} on $W$ if
$\vv(\alpha) = -k$.


\begin{example}{\bf Example.}\Marginnote{localizepolyring}\;\,
Let $A$ be the polynomial ring $\bbc[x_1,...,x_n]$, and let $P$ be the
principal ideal generated by an irreducible polynomial
$f(x_1,...,x_n)$.  The local ring $A_P$ consists of fractions $g/h$ of
polynomials in which $g$ is arbitrary, and $h$ can be any polynomial
that isn't divisible by $f$.  The valuation $\vv$ associated to this
ring is defined as follows: If $g$ is a polynomial, and $g = f^kg_0$,
where $f$ does not divide $g_0$, then $\vv(g) = k$.  The value of a
fraction $g/h$ is $\vv(g) -
\vv(h)$.\qed\label{localizepolyring} \end{example}


\begin{proposition}{\text{\bf Proposition.}}
\Marginnote{invertjustone}\;\,
Let $S$ be a multiplicative system in a finite-type domain $R$, and
let $A$ and $B$ be finite-type domains that contain $R$ as subring.
Let $R',A',B'$ be the rings of $S$-fractions of $R,A,B$, respectively.

\no {\bf (i)} If some elements $\alpha_1,...,\alpha_k$ of $A$ generate $A$
as $R$-algebra,  they also generate $A'$ as $R'$-algebra.

\no {\bf (ii)} Let $A'\stackrel{\varphi'}{\longrightarrow}B'$ be a
homomorphism.  For suitable $s$ in $S$, there is
a homomorphism $A_s\stackrel{\varphi_s}{\longrightarrow}B_s$ whose
localization is $\varphi'$.  If $\varphi'$ is injective, so is
$\varphi_s$.  If $\varphi'$ is surjective or bijective, there will be
an $s$ such that $\varphi_s$ is surjective or bijective.

\no {\bf (iii)} If $A'$ is contained in $B'$ and if $B'$ is a finite
$A'$-module, then for suitable $s$ in $S$, $A_s$ is contained in
$B_s$, and $B_s$ is a finite $A_s$-module.
\label{invertjustone}\end{proposition}


\begin{proof}  {\bf (ii)} 
We choose generators $\alpha_1,...,\alpha_k$ for the $\bbc$-algebra
$A$.  Let $f=\{f_1,...,f_k\}$ be a set of ideal generators for the
kernel of the map $\bbc[x] \ar A$ that sends $x \squig \alpha$.
Composition of $\varphi'$ with the inclusion of $A$ into $A'$ give us
a map $A \ar B'$.  The elements $\alpha_i$ have images $\beta_i$ in
$B'$, and for suitable $s$, $\beta_i$ are in $B_s$.  There will be a
homomomorphism $A \stackrel\varphi\longrightarrow B_s$ that sends
$\alpha_i \squig\beta_i$ if and only if $f(\beta) = 0$.  Since this is
true in $B'$, it is true in the subring $B_s$.  Then, since $s$ is
invertible in $B_s$, $\varphi$ extends to a map $A_s\ar B_s$. Since
$A_s \subset A'$ and $B_s \subset B'$, injectivity carries over
automatically from $\varphi'$ to $\varphi_s$.

Let $b=\{b_1,...,b_k\}$ be a set that generates the
finite-type algebra $B$.  Then $b$ also generates $B$ as
$A$-algebra and $B'$ as $A'$-algebra.  For surjectivity, we need to
show that if $b$ is contained in the image of $A'$, then for
suitable $s$, it will be contained in the image of $A_s$.  This is
true.

\msno {\bf (iii)} Suppose that $B'$ is a finite $A'$-module, and let
$\beta = \{\beta_1,...\beta_n\}$ be a set that spans $B'$ as
$A'$-module.  The products $\beta_i\beta_j$ are elements of $B'$, so
they can be written as combinations of $\beta$ with $A'$-coefficients,
say
 \begin{equation}
 \beta_i\beta_j = \sum_{i,j,k}\alpha_{ijk} \beta_k.\Marginnote{strconsts}
 	\label{strconsts}
\end{equation}
The elements $\alpha_{ijk}$ will be in a suitable $A_s$, and then the
equations hold in $B_s$.  This tells us that the finite $A_s$-module
generated by $\beta_1,...,\beta_n$ is a subring of $B_s$.  Part {\bf
  (ii)} tells us that,  if we  adjust $s$, the map
from this ring to $B_s$ will be surjective.  \qed\end{proof}


\ms With our chosen presentation of the coordinate algebra, $X$
becomes a closed subvariety of $\bba^n$.  It will have a {\it tangent
  line} at a smooth point $p$.  The tangent vectors are
orthogonal to the gradients of the defining equations at $p$, the rows
of the Jacobian matrix.  They are defined by the
equations
\begin{equation}
\nabla f_i(p) x = 0\Marginnote{tanlineatsmoothpoint}
	\label{tanlineatsmoothpoint}
\end{equation}
Since $J$ has rank $n-1$, the tangent vectors form a space of dimension one.

\ms
Prove this: If $P$ is a prime ideal of $A$ and if $P\cap S$
is empty, the extended ideal $P' = PA'$ is a prime ideal of $A'$, and
its contraction $P'\cap A$ is $P$.  If $P\cap S$ is not empty,
the extended ideal is the unit ideal.

\begin{corollary}{\bf Corollary.}
\Marginnote{idealsofA}\label{idealsofA} Let $X = \spec A$ be a smooth
affine curve.  The nonzero ideals $I$ of $A$ are products of powers of
maximal ideals.  There are distinct points $p_1,...,p_k$ of $X$ and
integers $e_1,...,e_k$ such that, if we denote the maximal ideal of
$A$ at $p_i$ by $\fm_i$ $$I = \fm_1^{e_1}\cdots \fm_k^{e_k}$$
\end{corollary}

\begin{proposition}{\text{\bf Proposition.}}\Marginnote{chainsmax}\;\,
Let $Y \stackrel{u}{\longrightarrow} X$ be an integral morphism of affine
varieties.  Every chain of closed subvarieties of $Y$, lies over a
chain in $X$, and every chain of closed subvarieties of $X$ has chain
in $Y$ lying over it.  \qed \label{chainsmax}\end{proposition}


If (\ref{chntwo}) is a maximal chain in a variety $X$, then
\begin{boldequation}
C_i > C_{i+1} > \cdots > C_k \Marginnote{chaini}
	\label{chaini}
\end{boldequation}
 will be a maximal chain in the variety $C_i$.  So when $X$ has dimension $k$,
the dimension of $C_i$ is $k\!-\!i\!-\!1$.  Similarly, let (\ref{chn})
be a maximal chain of prime ideals in a finite-type domain $A$, let
$\oA= A/P_i$ and let $\oP_j$ denote the image of $P_j$ in $\oA$, for
$j \geq i$.  The Correspondence Theorem implies that 
$$\overline{0} = \oP_i < \oP_{i+1} < \cdots < \oP_k$$ will be a
maximal prime chain in $\oA$, and therefore that the dimension of the
domain $\oA$ is $k\!-\!i\!-\!1$.  

that begin with the chain $P_0 < P_1 < \cdots < P_{i-1}$.

twisted cubic specializes to plane nodal cubic

counting constants.

\msno \begin{thm}
\Marginnote{chainmaximalx}\label{chainmaximalx}
  Verify directly that the
prime chain \ref{primechain} is maximal.\end{thm}



\msno
 \begin{thm}
\Marginnote{dimdim}\label{dimdim} Let $Y\stackrel{u}{\longrightarrow}
X$ be a surjective?? morphism, and let $K$ and $L$ be the function
fields of $X$ and $Y$, respectively.  Show that if $\,\dim Y = \dim
X$, there is a nonempty open subset $X'$ of $X$ such that all fibres
over points of $X'$ have the same order $n$, and that $n =
[L:K]$.\end{thm}

\msno Let $Y^0$ be a projective variety of dimension $n$ and let $f_0$
be an irreducible homogeneous polynomial of degree $d$ that doesn't
vanish identically on $Y^0$.  Let $Y^1$ be the locus of zeros of $f_0$
on $Y^0$.  Prove that $\dim Y^1 = \dim Y^0 -1$ by constructing a
sequence $Y^0 > Y^1 > \cdots > Y^n$ with $n_i =\dim Y^i$ and 
$n_0 >n_1 > \cdots$.  Then use the result of problem xxx.


\msno
 \begin{thm}
\Marginnote{fseries}\label{fseries}
   Prove that the ring $k[[x,y]]$ of formal power
series with coefficients in a field $k$ is a local ring.\end{thm}


\msno \begin{thm}
\Marginnote{limitring}\label{limitring}
 So far as possible, extend Proposition \ref{invertjustone}
to limits of rings.  \end{thm}

\msno \begin{thm}
\Marginnote{moduleoverdvrx}\label{moduleoverdvrx}
  Prove that every finitely
generated, torsion-free module over a  valuation ring is free.\end{thm}

\msno
 \begin{thm}
\Marginnote{dvnormal}\label{dvnormal}
 Prove that a  valuation ring is a unique factorization domain.
\end{thm}

\msno \begin{thm}
\Marginnote{blowuparbsing}\label{blowuparbsing}
Prove that the blowing up process described in Section \ref{nodes}
yields a smooth curve in finitely many steps.  \end{thm}



\msno \begin{thm} \Marginnote{approachpole} \label{approachpole} Let
  $Z$ and $P$ be the zeros and poles of a rational function $\alpha$
  on a normal variety $X$.  Prove that, as a point $p$ of $X$
  approaches a point $p_0$ of the zero locus $Z$, $\alpha$ will tend
  to zero unless $p_0$ is also a point of the polar locus $P$, and
  that $\alpha$ is indeterminate at the points of $Z\cap P$, in the
  sense that it can approach an arbitrary value along a suitable curve
  through $p_0$.\end{thm}

\msno \begin{thm}
\Marginnote{exupper}\label{exupper}
\no Is the constructibility hypothesis in \ref{uppercrit}
necessary?\end{thm}

\msno \begin{thm}
\Marginnote{avoidingprimesx}\label{avoidingprimesx}
Clarify the reasoning
used in Lemma \ref{genlincomb}.\end{thm}


\msno \begin{thm}
\Marginnote{exgkdim}\label{exgkdim}
  Work out GK-dimension.\end{thm}


\msno \begin{thm}
\Marginnote{exprodlocal}\label{exprodlocal}
 product of local rings
\end{thm}


\newpage

\section{Chapter 6 Exercises.}\Marginnote{exerchapsix}\label{exerchapsix}

\bs What are the sections of $\co(nH)$ on an open set $V$ that isn't
contained in any $\bbu^i$.

\bs Let $s$ be an element of a domain $A$, and let $M$ be an
$A$-module.  Prove that the limit of the directed set $M \stackrel s
\rrr M \stackrel s \rrr \cdots$ is isomorphic to the localization
$M_s$.


\bs Let $Z \stackrel j \rrr X$ be the inclusion of an open subvariety
into a variety $X$.  Prove that the functors $\gg_*$ and $\gg^*$
are {\it adjoint}: Homomorphisms of $\co_Z$-modules $\gg^*\cm\ar \cn$
correspond bijectively to homomorphisms of $\co_X$-modules $\cm\ar
\gg_*\cn$.

\bs
Give example of finite $\co$-module $\cm$  on quasiprojective variety
such that $\cm(X)$ is not a finite $\co(X)$ module.

Hint: The reason that this might occur is that there might not be
rational functions that are regular on $X$, though $\cm$ has global
sections.

\bs
Describe the kernel of multiplication by 
a homogeneous polynomial of degree $d$
$$ \cm(k) \stackrel{f}\longrightarrow \cm(k+d)$$

\bs
Prove that the sequence of Example \ref{cokerandimage} is exact.


\bs
Prove Corollary \ref{cohimpsheaf}, that if an $\co$-module has the
coherence property for affine open sets $U$, then it has the sheaf
property for affine open coverings of affine open sets.


\bs
Verify the last assertion of Theorem \ref{onecoverenough}, that $\cm$
is a finite $\co$-module if $\cm(U^i)$ are finite $\co(U^i)$-modules.

\bs Let $X$ be a variety. Prove that every strictly ascending chain of
submodules of a finite ${\co}$-module $\cm$ is finite.

Show that if $\ci$ and $\cj$ are (quasicoherent) ideals of $\co$, so is $\ci \cap \cj$.

\bs
Determine the sections of $\co$ on the complement of a point of
$\bba^2$.


\bs
Let ${\cm}$ be an
${\co}$-module on $\bbp^n$.  Prove that if coordinates $x$ of $\bbp^n$
are in general position, multiplication by $x_i$ defines an injective
map ${\cm}\ar \cm(1)$.

\bs
Let $\cm$ and $\cn$ be $\co$-modules.  Prove that $\Hom_\co(\cm,\cn)$
is a (quasicoherent) ${\co}$-module.


\bs Give an example to show that the sections ${\cm}(U)$ of a finite
${\co}$-module needn't form a finite ${\co}(U)$-module when $U$ isn't
an affine open set.


\bs
Verify the assertions that Theorems \ref{moduleonaffines} and
\ref{onecoverenough} imply for homomorphisms



\bs   Let $U'\subset U$ be affine open sets in a
variety $X$, and let ${\cm}$ be an ${\co}_X$-module.  Say that ${\co}(U)=
A$, ${\co}(U')=A'$, ${\cm}(U) = M$, and ${\cm}(U') = M'$.  Prove that $M' =
M \otimes_AA'$.

\bs
  In the description (\ref{sheafonPone}) of modules over the
projective line, we considered the standard affine open sets $U^0$ and
$U^1$.  Interchanging these open sets changes the variable $t$ to
$t^{-1}$, and it changes the matrix $P$ accordingly.  Does it follow,
when the rank is $1$, that the ${\co}$-modules defined by $t^k$ and by
$t^{-k}$ are isomorphic?

\bs
Determine the limit of the sequence  
$$\bbz \stackrel{2}\longrightarrow \bbz \stackrel{2}\longrightarrow
\bbz \stackrel{2}\longrightarrow \cdots,$$ where $\bbz$ denotes the
additive group of integers, and each map is multiplication by $2$.


\bs Do \ref{jstarjstarO}     for multiplication by $f$.


\newpage

\section{\bf Chapter 7  Exercises.}
\Marginnote{exerchapseven}\label{exerchapseven}

\bs
do genus of curve with nodes and cusps

\bs
 $ H^0(\co_X) = \bbc$.



\bs
Let $M$ be a module over a finite-type domain $A$, and let $\alpha$
be an element of $A$.  Prove that for all but finitely many complex numbers
$c$, scalar multiplication by $s = \alpha-c$ is an injective map $M
\stackrel{s}{\longrightarrow} M$.  

\bs
$H^q(X,{\co}_X(-k))$ The verification of this
makes a good exercise.

\msno  Prove the Birkhoff-Grothendieck Theorem by matrix
manipulation, as outlined in (\ref{qinversmp}).

Before giving the proof we sketch a computational proof that is
similar to Birkhoff's proof.  His proof uses the standard affine cover
$U^0=\spec \bbc[t]$ and $U^1 = \spec \bbc[t^{-1}]$, and the
intersection $U^{01}$ is the spectrum of the Laurent polynomial ring
$\bbc[t,t^{-1}]$.  Let's write $A_0,A_1$, and $A_{01}$ for the rings
$\bbc[t],\bbc[t^{-1}]$, and $\bbc[t,t^{-1}]$, respectively, and let
$M_0$, $M_1$, and $M_{01}$ denote the modules of sections of ${\cm}$
over the corresponding open sets.  We know that $M_0$ and $M_1$ are
free modules, so $M_{01}$ is a free $A_{01}$-module.  Let $\text{\bf
  B}_0$ and $\text{{\bf B}}_1$ be bases for $M_0$ and $M_1$.  Both
sets will be bases of $M_{01}$, so they will be related by an
invertible $A_{01}$-matrix $R$.  We can change the basis $\text{{\bf
    B}}_0$ by an invertible $A_0$-matrix $Q$ and the basis $\text{{\bf
    B}}_1$ by an invertible $A_1$-matrix $P$.  If we do this, $R$ gets
replaced by
\begin{equation}
R'\; =\; Q^{-1}RP \Marginnote{qinversmp} 
	\label{qinversmp}
\end{equation}

\no Here $Q$ and $P$ can be arbitrary elements of $GL_n(A_0)$ and
$GL_n(A_1)$.  The theorem can be proved by showing that for any element
$R$ of $GL_n(A_{01})$, there exist elements $Q$ in $GL_n(A_0)$ and $P$
in $GL_n(A_1)$ such that $Q^{-1}RP$ is diagonal. 


\msno 
Let $X$ and $Y$ be varieties with functions fields $K$, $L$
respectively.  Suppose that $L$ is a finite extension of $K$, of
degree $[L:K] = n$.

\msno {\bf (i)} Show that there an integral morphism
$Y'\stackrel{u'}\rrr X'$, where $Y'$ and $X'$ are nonempty open
subvarieties of $Y$ and $X$, respectively, such that every fibre of
$u'$ consists of exactly $n$ points.

\msno {\bf (ii)} Show that if $K = L$, there are open subsets $Y'$ and $X'$ as ni
    {\bf (i)} such that the morphism $Y' \ar X'$ is an isomorphism.

\msno
  If $D \sim E$, multiplication by $f$ defines
 an isomorphism 
$ {\co}_Y(D) \stackrel{f}{\longrightarrow} {\co}_Y(E)$.

\msno
  Do Euler characteristic of complex.

\msno
 Let $x_0,...,x_n$ be coordinates in projective space $\bbp^n$, and
 let ${\cm}$ be an ${\co}_{\bbp^n}$-module.  Let $M$ be the module of
 sections of ${\cm}$ on the standard affine open $U^0 = \spec
 \bbc[u_1,...,u_n]$, $u_i = x_i/x_0$.  When the coordinates are in
 general position, multiplication by $u_i$ defines an injective map $M
 \ar M$. 

\ms

support

\ms
general position

\ms
dimension zero loci
redundancy in BG theorem

\ms On $\bbp^1$, when is $\bigoplus \co(m_i)$ isomorphic to 
$\bigoplus \co(n_j)$?

\ms
On a smooth curve, $\cm \approx \ct \oplus \cv$.

\newpage


\centerline{\bf Chapter 8 Exercises}


\ms
Lemma:  $f$ irreducible in $\bbc[x]$, $A$ finite-type domain.
Then $f$ irreducible in $A[x]$.  (evaluate at a point)

\ms
proof: $\otimes$ is flat, so compatible with localization.

\ms
Choose $B' = \bbc[x]/(f)$ with same fraction field as $B$.
Replace $B$ by $B'$.  Apply lemma.

\bs Let $A,B$ be $2\times 2$ variable matrices, let $P$ be the
polynomial ring $\bbc[a_{ij}},b_{ij}]$. and let $R$ be the algebra
  $P/(AB=BA)$.  Show that $R$ has a resolution as $P$-module of the
  form $0 \ar P^2 \ar P^3\ar P \ar R \ar 0$.

\ms There are three equations depending only on the $6$ variables
$a_{12},a_{21},b_{12},b_{21},c = a_{11}-a_{22},d=b_{11}-b_{22}$.
There is one relation of degree $1$ in $a_{12},a_{21},c$ and one of
degree $1$ in $b_{12},b_{21},d$.

\bs Let $Y$ be a smooth curve of genus $g$.  Start with a positive
divisor $E$ of degree $2g-1$.  Then $\hh^0(\co(E)) = g$ and
$\hh^1(\co(E)) = 0$.

\ms Subtracting $g-1$ generic points gives divisor $D$ of degree $g$
with $\hh^0(\co(D)) = 1$ and $\hh^1(\co(D)) = 0$.  Let $(1,y)$ be a
basis of $\hh^0(\co(D))$.  This gives a map $Y \ar X=\bbp^1$ of degree
$g$.  Taking direct image, $\co_Y$ becomes an $\co_X$-module of rank
$g$.  The inclusion $\co_X\subset \co_Y$ splits.  So $\co_Y =
\co_X\oplus \CL$ for some locally free modules $\CL$ of rank $g-1$.
We have $\hh^0(\co_Y) =1$ and $\hh^1(\co_Y)=0$, so $\hh^0(\CL) =
\hh^1(\CL) = 0$.  Since $\CL$ is a direct sum of twisting modules,
the only possibility is that $\co_Y = \co_X\oplus \co_X(-1)^{g-1}$.

\bs
hyperelliptic curves





\ms
We can define the {\it degree} $\,\deg \CL$ of an
 invertible $\co$-module $\CL$ on a smooth projective curve to be
 the degree of a divisor $D$ such that $\co(D) \approx \CL$.  With
 this definition of degree, Riemann-Roch for $\CL$ becomes

\begin{equation}
\Marginnote{RRL}\label{RRL}
\chi(\CL) =  \chi(\CO) + \deg \CL
\end{equation}
The equation shows that the degree of $\CL$  is well-defined.


do this

If $\fm_j$
is the maximal ideal at the point $q_j$, the divisor that corresponds to the
fractional ideal $\fm_1^{r_1}\cdots\fm_k^{r_k}$ is the combination
$r_1q_1+\cdots + r_kq_k$.

Let $K$ be the function field of a smooth curve $Y$.  We've noted
before that there is a  constant $\co$-module $K$, defined by $K(Y') =
K$ for every nonempty open subset $Y'$.  A {\it
  fractional ideal} is a finite, nonzero $\co$-submodule
of $K$.  A fractional ideal is like an ideal of $\co$, except that its
sections are fractions.

\ms To describe the fractional ideals, we will need
negative powers of the maximal ideals.  Let $\fm$ be the maximal ideal
of $\co$ at a point $q$ of $Y$, let $\vv$ be the valuation associated
to $q$, and let $k$ be a positive integer.  The sections of the
negative power $\fm^{-k}$ on an open set $Y'$ are the rational
functions $f$ such that $\fm^k f$ is a regular function on $Y'$.  

\begin{proposition}{\bf Proposition.} 
\Marginnote{idealincurve}\label{idealincurve} The fractional ideals
$\ci$ on a smooth curve $Y$ are the products
$\fm_1^{e_1}\cdots\fm_k^{e_k}$ of integer powers of maximal ideals
$\fm_i$.
\end{proposition}

\bs
Prove this proposition.

 Let $Y \stackrel u \rrr X$ be
a finite morphism of curves, and let $K$ and $L$ be the function
fields of $X$ and $Y$, respectively, and suppose $[L:K]=n$.  Then all
fibres have order at most $n$, and all but finitely many fibres of $Y$
over $X$ have order equal to $n$.\bs
no isolated point on a variety, dimension $>0$.

\bs

Count points order 2 on an elliptic curve.  Show if origin is a flex,
the other the flexes of a cubic are the points of order $3$. Therefore
nine points of order $3$.

\bs

\#\#genus of curve with nodes and cusps\#\#

\bs\bsno
{\bf Curves of genus $2$}

\bsno Let $Y$ be a curve of genus $g = \hh^1(Y,\co_Y) = 2$.  We
choose a point $p$ of $Y$ and procede as with curves of genus $1$.
There is no function with a simple pole at $p$ and no other pole.  The
exact sequence
$$0 \ar \co_Y((r-1)p) \ar \co_Y(rp) \ar \epsilon \ar 0,$$
with $r=1$, shows that $\hh^1(Y,\co_Y(p)) = 1$.  So far, so good.
However, setting $r=2$, we have two possibilities:  
Either 


\msno
\sbull $\hh^0(Y,\co_Y(2p)) = 1$ and $H^1(Y,\co_Y(2p)) = 0$, or else 

\msno
\sbull $\hh^0(Y,\co_Y(2p))=2$ and $\hh^1(Y,\co_Y(2p)=1$.

\msno
Suppose we are in the first case.  Then by induction, 
$$\hh^0(Y,\co_Y(rp)) = r-1,$$ 
and $H^1(Y,\co_Y(rp))=0$ for all $r \geq 2$.  Setting $r=3$, we find a
nonconstant function $x$ with a triple pole at $p$, and setting $r=4$,
we find a function $y$ with a pole of order $4$ at $p$.  Then we can
map $Y$ to $\bbp^2$ using the coordinates $(x,y,1)$.  A point $q$
different from $p$ is sent to $(x(q),y(q),1)$, while $p$ is sent to
$(0,1,0)$.  Because $y$ has a four fold pole at $p$ and no other pole,
the line $z=0$ in $\bbp^2$ intersects the image of $Y$ with
multiplicity four at the point $(0,1,0)$ and has no other intersection
with $Y$.  Therefore the image of $Y$ in $\bbp^2$ will be a curve of
degree $4$.

But there is a problem: The genus of a smooth plane curve of degree
four is $3$.  We cannot map $Y$ to a curve of genus $3$.  There is
only one only possibility: The image of $Y$ must be singular.

\msno
{\bf Note:} Since $\hh^0(Y,\co_Y(5p)) = 4$, there is a function $w$
with pole of order $5$ at $p$, and we will have a basis $(1,x,y,w)$
for that space.  Perhaps we should look at the embedding into $\bbp^3$
by the functions $(1,x,y,w)$, but never mind. \qed

\msno Now we consider the second case: $\hh^0(Y,\co_Y(2p))=2$. 
In this case, we will choose a different point $p'$.

Since $\hh^0(Y,\co_Y(2p))=2$, there is a function $f$ whose only pole
is a double pole at $p$.  We use the coordinates $(1,f)$ to map $Y$ to
$\bbp^1$.  Since $f$ has a double pole, it takes on every value twice,
so the map is two to one.  It represents $Y$ as a double covering of
$\bbp^1$.

The genus of a smooth projective curve can be computed in terms
of the topological Euler characteristic $E(Y) = $ (vertices) -(edges)
+ (faces), by the formula $E = 2-2g$.  The Euler characteristic of
$\bbp^1$ is $2$.  Let $B$ denote the number of branch points of the
double covering -- the number of pionts of $\bbp^1$ over which there
is only one point of $Y$.  ($p$ is one of those points.)  Then we will
have $-2=E(Y) = 2 E(\bbp^1) - B = 4-B$.  So $B=6$.  There are six branch
points for the double covering.

%\#\#ugh\#\# 
Now we let $p'$ be a point of $Y$ distinct from the six
branch points, and we show that $\hh^0(Y,\co_Y(2p'))=2$ isn't
possible, and therefore that replacing $p$ by $p'$ puts us back in the
first case.

Assuming that $\hh^1(Y,\co_Y(2p'))=2$, we choose a function $g$ with
double pole at $p'$.  This gives us a second map $(1,g)$ from $Y$ to
$\bbp^1$.  Combining the two maps, we obtain a map $Y @>\varphi>>
\bbp^1\times\bbp^1$, by $((1,f),(1,g))$.  Let $u=x_1/x_0$ and $v=y_1/y_0$. 

Say that $f(p')=a$.  Since $f$ takes every value twice, there is
exactly one other point $q$ with $f(q)=a$, and since $p'$ is not a
pranch point, $q \neq p$.  Let $g(q) = b.$ The map $\varphi$ sends $q$
to the point $((1,a),(1,b))$, and there is no other point of $Y$ with
that image.  So $\varphi$ is injective, at least generically.  The
closure of its image $Z$ will be an irreducible one-dimensional closed
subset of $\bbp^1\times \bbp^1$.  The projection of $Z$ to the first
factor $\bbp^1$ will agree with the map $(1,f)$ of $Y$ to $\bbp^1$, so it
will have degree $2$.  This means that a generic ``vertical'' line
$(x_0,x_1)= \text{constant}$ in $\bbp^1\times\bbp^1$ meets $Z$ in two
points.  Similarly, a generic "horizontal" line $(y_0,y_1)=
\text{constant}$ meets $Z$ in two points.

Since $Z$ is an irreducible closed subset of $\bbp^1\times\bbp^1$, there
will be an irreducible polynomial $p(x_0,x_1,y_0,y_1)$ that vanishes
on $Z$ and is homogeneous in the each set of variables $x$ and
$y$.  And because $Z$ meets a vertical line in two points, $p$ will
have degree $2$ in $x$.  Similarly, $p$ will have degree $2$ in $y$.
One says tht $p$ and $Z$ have {\it bidegree} $2,2$.

Now when we compute the genus of a curve of bidegree $2,2$, we will
find that the genus is $1$.  Since there is no injective map from a
curve of genus $2$ to one of genus $1$, we will have ruled this
possibility out, and replacing $p$ by $p'$ does take us back to the
first case.

Let $X = \bbp^1\times \bbp^1$.  We define a sheaf $\co_X(r,s)$ as follows:
If $U_i$ denote the standard affine open subsets of $\bbp^1$, we have
an affine open set $U_{00}= U_0\times U_0 = \spec \bbc[u,v]$, where $u
= x_1/x_0$ and $v=y_1/y_0$.  The sections of $\co_X(r,s)$ on $U_{00}$
are the ratios $h/x_0^ky_0^\ell$, where $h$ is homogeneous of degree
$r+k$ in $x$ and homogeneous of degree $s+\ell$ in $y$.  We use
analogous notation to define the sections on $U_{ij}$ with $0 \leq
\j,j\leq 1$.  There will be an exact sequence
$$0 \ar \co_X(-2,-2) @> p>> \co_x \ar \co_Z \ar 0.$$
Similarly, with $q = x_0x_1y_0y_1$, there will be an exact sequence
$$0 \ar \co_X(-2,-2)@> q>> \co_X \ar \co_W\ar 0,$$
where $W$ is the locus of zeros of $q$, which is the union of two
vertical lines and two horizontal lines.  Consequently, $\chi(\co_Z) =
\chi(\co_W)$.

The four lines making up $W$ intersect in four points.  When we pull
the intersections apart, we obtain a disjoint union of four cpies of
$\bbp^1$, and we can assemble this information into an exact sequence
which, speaking loosely, has the form
$$0 \ar \co_W \ar (\co_{\bbp^1})^4 \ar (\bbc)^4 \ar 0.$$
Since $\hh^0(\co_{\bbp^1}) = 1$ and $\hh^0(\bbc) =1$, and since
$H^1 =0$ for those sheaves, we find $\chi(\co_W) =0$.  Therefore
$\chi(\co_Z)=0$, which means that $Z$ has genus $\leq 1$, not $2$.  


\bs
Prove the analogue of \ref{tfreelfree} {\bf (i)} for any variety $Y$.


\bs Show that  $\fm^{-1}$ is the dual module $\fm^*$.
\bs
\no
{\bf (ii)} Let $\CL \subset \cm$ be an
inclusion of invertible $\co$-modules.  Then $\cm = \CL(D)$ for some
effective divisor $D$.

\bs


Torsion-free implies torsion-0free on eveyr open set.

\bs

regular function on a projective variety is constant

\bs

properties of $\Hom$ carry over to define $\uHom_\co(\cm,\cn)$.

\bs

prove map of curve $Y$ to $\bbp^1$ is a finite morphism without
appealing to Chevalley's Theorem.

\bs

derive omegafreetwo (ii) from (i) for a simple localization.

\bs

$Y = \spec B$ a smooth aff ine curve, $y \in B$.  At what points does
$dy$ generate $\Omega_Y$?

\bs

Exercise.  a finite $\co$-module on a smooth curve is a direct sum of
a torsion module and a locally free module.

\bs

Do version of \ref{pointsinfibre} for arbitrary dimension.


\bs
As it happens, the genus of a smooth cubic curve in $\bbp^2$ is equal to $1$
(see Section \rec{cohhyper}). 
Using this fact, one can show that $Y$
maps isomorphically to $Y'$.  We leave the verificaiton as an exercise.

\bs\ms
Derive $\hh^0(\co(rp))$ for genus $1$  from Version 1 of the
Riemann-Roch Theorem.

\bs
Which of the following properties are true for all open sets?

\bs construct $Y$ as the normalization of
$X=\bbp^1$ in the function field $L$ of $Y$. 

\bs
$K$ for hyperelliptic curve.

\bs
$X$ has no isolated point in arbitrary dimension

\bs
derive from Version 1 of RR: If $r \geq 1$, then $\dim
H^0(Y,\co_Y(rp)) = r$ and $H^1(Y,\co_Y(rp)) = 0$.


\bs
$$k(X) \stackrel{\varphi}\longrightarrow k(Y)$$


\no {\bf (i)} If $Y$ is smooth and $X$ is projective, there is a
unique morphism $Y \stackrel{u}\longrightarrow X$ that induces
$\varphi$.

\no {\bf (ii)} Suppose that $\varphi$ is an isomorphism, that $Y$ is
smooth, and that $X$ is smooth and projective.  Then $u$ maps $Y$
isomorphically to an open subvariety of $X$.

\no {\bf (iii)} Suppose that $\varphi$ is an isomorphism, that $Y$ is
smooth and projective, and that $X$ is projective. Then $Y$ is the
normalization of $X$.
 

\bsno
\begin{boldequation}\hspace{-9cm}\textbf{curves of genus zero}
\Marginnote{gzero}\label{gzero}\end{boldequation}

\bsno Let $X$ be a smooth projective curve of genus $g=
0$.  So $H^1(X,\co_X)=0$.  Let $p$ be a point of $X$.  The exact sequence
$$0 \ar \co_X \ar \co_X(p) \ar \epsilon \ar 0$$ 
 gives us an exact cohomology sequence 
$$0 \ar H^0(X,\co_X) \ar H^0(X,\co_X(p)) \ar H^0(X,\epsilon) \ar 0$$
 because $H^1(X,\co_X)=0$.  This sequence shows that $\dim
 H^0(X,\co_X(p))=2$.  We choose a basis $(f,1)$ for $H^0(X,\co_X(p))$,
 $1$ being the constant function.  This basis defines a point with
 values in the function field $K$, and therefore a morphism $X
 \stackrel{\varphi}\longrightarrow \bbp^1$ (Proposition \ref{pointsofcurve}).
 Because $f$ has just one pole of order $1$, it takes every value
 exactly once.  Therefore $\varphi$ is bijective.  It is a map of
 degree $1$.  The function fields of $X$ and $\bbp^1$ are isomorphic.
 Then because $\bbp^1$ is a smooth curve, $\varphi$ is an isomorphism.

\begin{corollary}{\bf Corollary.} \label{genuszero}\Marginnote{genuszero}
 Every curve of genus zero is
isomorphic to the projective line $\bbp^1$.  \qed\end{corollary}


\end{document}

